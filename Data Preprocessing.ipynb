{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60265e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#  Data Preprocessing\n",
    "import torch\n",
    "import Bio\n",
    "import pandas as pd\n",
    "\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d526af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate K-Mer from sequence\n",
    "s = \"GTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACT\"\n",
    "\n",
    "# Generate array of k-mer or return original sequence if \n",
    "# from https://github.com/jerryji1993/DNABERT/blob/master/motif/motif_utils.py\n",
    "#\n",
    "# @param sequence : sequence you want to process\n",
    "# @param k : how many length you want in k-mer. If k=-1 then original sequence is returned.\n",
    "# @n_k_mer : how many k-mers are retrieve. If all kmers are required, please put -1.\n",
    "def create_k_mer(sequence, k, n_k_mer):\n",
    "    # Clean sequence from N characters.\n",
    "    sequence = ''.join(c for c in sequence if c not in ['N'])\n",
    "    if k > 0:\n",
    "        arr = [sequence[i:i+k] for i in range(len(sequence)+1-k)]\n",
    "        if n_k_mer > 0:\n",
    "            arr = arr[0:n_k_mer]\n",
    "        kmer = ' '.join(arr)\n",
    "        return kmer\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "kmer = create_k_mer(s, 6, 10)\n",
    "print(kmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine tuning file from fasta file.\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "# Generate file for fine tuning using FASTA file.\n",
    "# @param fasta_file : Original fasta file.\n",
    "# @param label_for_this_file : What label for this fine tuning file.\n",
    "# @param output_file_path : What and where the fine tuning is named and stored. \n",
    "#                           If file path exists, existing file will be removed.\n",
    "# @param n_samples : How many sequence will be put in fine tuning file. \n",
    "#                    If all sequence is to be generated, please put -1.\n",
    "# @param k_mer : Size of k-mer. If k-mer is not required, please put -1.\n",
    "# @param n_k_mer : How many kmers are written to file for each sequence in fasta file. \n",
    "#                  If all kmers are written, please put -1.\n",
    "def generate_sample_fine_tuning_file(fasta_file, label_for_this_file, output_file_path, n_samples, k_mer, n_k_mer):\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    if len(records) >= n_samples:\n",
    "        records = records[0:n_samples]\n",
    "    \n",
    "    if (os.path.exists(output_file_path)):\n",
    "        os.remove(output_file_path)\n",
    "        \n",
    "    output_file = open(output_file_path, 'w+')\n",
    "    for r in records:\n",
    "        output_file.write(create_k_mer(str(r.seq), k_mer, n_k_mer) + '\\t' + str(label_for_this_file) + '\\n')\n",
    "    output_file.close()\n",
    "    return output_file_path\n",
    "\n",
    "# Merge two files together.\n",
    "# @param fp : First file path.\n",
    "# @param gp : Second file path.\n",
    "# @param hp : Third file as result from merging two files together.\n",
    "def merge_file(fp, gp, hp):\n",
    "    data1 = data2 = \"\"\n",
    "    with open(fp) as f:\n",
    "        data1 = f.read()\n",
    "    with open(gp) as g:\n",
    "        data2 = g.read()\n",
    "    \n",
    "    final_data = data1 + data2      \n",
    "    with open (hp, 'w') as h:\n",
    "        h.write(final_data)\n",
    "        h.close()\n",
    "        \n",
    "# Merge files into single file.\n",
    "# @param origin_files : Original files in list.\n",
    "# @param merged_file : Merged file.\n",
    "# @param headers : Header for this file in list. Each header is separated by tabs.\n",
    "def merge_files(origin_files, merged_file_path, headers):\n",
    "    merged_data = \"\"\n",
    "    \n",
    "    for file_path in origin_files:\n",
    "        print('reading file {}'.format(file_path))\n",
    "        with open(file_path, 'r') as of:\n",
    "            d = of.read()\n",
    "            merged_data += d\n",
    "            \n",
    "    merged_file = open(merged_file_path, 'w+')\n",
    "    if (headers):\n",
    "        header = headers[0]\n",
    "        for h in headers[1:]:\n",
    "            header +='\\t' + h\n",
    "        merged_file.write(header + '\\n')\n",
    "    \n",
    "    merged_file.write(merged_data)\n",
    "    merged_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0403f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GUUCUCUAAACGAACUUUAAAAUCUGUGUGGCUGUCACUCGGCUGCAUGCUUAGUGCACU', 'UUCUCUAAACGAACUUUAAAAUCUGUGUGGCUGUCACUCGGCUGCAUGCUUAGUGCACUG', 'UCUCUAAACGAACUUUAAAAUCUGUGUGGCUGUCACUCGGCUGCAUGCUUAGUGCACUGU']\n"
     ]
    }
   ],
   "source": [
    "# Transform DNA into RNA by changing base T into U.\n",
    "# Write the transformed sequence (RNA seq) into file, if necessary.\n",
    "# @param dna_seq : A set of DNA sequence.\n",
    "# @param write_to_file_path : File in which RNA seq is written.\n",
    "# @return : A set of RNA sequence.\n",
    "def transform_DNA_to_RNA(dna_seqs, write_to_file_path):\n",
    "    rna_seqs = [seq.replace('T', 'U') for seq in dna_seqs]\n",
    "    if (write_to_file_path):\n",
    "        print('writing RNA seq at {}'.format(write_to_file_path))\n",
    "        f = open(write_to_file_path, 'w')\n",
    "        for seq in rna_seqs:\n",
    "            f.write(seq + '\\n')\n",
    "    return rna_seqs\n",
    "\n",
    "s = \"GTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACT\"\n",
    "t = \"TTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACTG\"\n",
    "u = \"TCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACTGT\"\n",
    "\n",
    "print(transform_DNA_to_RNA([s,t,u], ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb7cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nucleotide sequences.\n",
    "# B.1.1.7 (Alpha), \n",
    "ALPHA_FASTA_PATH=\"data/sars-cov-2/raw/nucl/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\"\n",
    "# B.1.351 (Beta), \n",
    "BETA_FASTA_PATH=\"data/sars-cov-2/raw/nucl/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\"\n",
    "# B.1.617.2 (Delta), \n",
    "DELTA_FASTA_PATH=\"data/sars-cov-2/raw/nucl/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\"\n",
    "# P.1 (Gamma)\n",
    "\n",
    "# Protein sequences.\n",
    "ALPHA_PROT_FASTA_PATH = \"data/raw/prot/complete-prot-sars_cov_2-B.1.1.7-human_origin.fasta\"\n",
    "BETA_PROT_FASTA_PATH = \"data/raw/prot/complete-prot-sars_cov_2-B.1.351-human_origin.fasta\"\n",
    "DELTA_PROT_FASTA_PATH = \"data/raw/prot/complete-prot-sars_cov_2-B.1.617.2-human_origin.fasta\"\n",
    "\n",
    "ALPHA_CLASS = 1\n",
    "BETA_CLASS = 2\n",
    "DELTA_CLASS = 3\n",
    "\n",
    "K_MER_6 = 6\n",
    "K_MER_5 = 5\n",
    "K_MER_4 = 4\n",
    "K_MER_3 = 3\n",
    "N_K_MER = 100 # How many k-mers are retrieved per sequence.\n",
    "N_SAMPLES = 100 # How many sequences are retrieved.\n",
    "\n",
    "PREFIX = 'sarscov2'\n",
    "DEST_DIR = 'data'\n",
    "DEST_DIR_ALPHA = DEST_DIR + '/alpha'\n",
    "DEST_DIR_BETA = DEST_DIR + '/beta'\n",
    "DEST_DIR_DELTA = DEST_DIR + '/delta'\n",
    "\n",
    "# Wuhan 2020 Isolate\n",
    "WUHAN_FASTA_PATH = \"data/sars-cov-2/wuhan/MN908947.fna\"\n",
    "WUHAN_TEXT_PATH = \"data/sars-cov-2/wuhan/MN908947.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from Bio import SeqIO\n",
    "records = list(SeqIO.parse(WUHAN_FASTA_PATH, \"fasta\"))\n",
    "print(\"len {}\".format(len(str(records[0].seq))))\n",
    "records\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Reads the text file. Since genome is divided into several gene which consists of 70 bases,\n",
    "file is read line by line, creating set of genes.\n",
    "\"\"\"\n",
    "f = open(WUHAN_TEXT_PATH, \"r\")\n",
    "seqs = []\n",
    "for i, line in enumerate(f):\n",
    "    if i > 0:\n",
    "        # Removing newline char.\n",
    "        l = ''.join(c for c in line if c not in ['\\n'])\n",
    "        seqs.append(l)\n",
    "        # print(l)\n",
    "\n",
    "seqs = transform_DNA_to_RNA(seqs, '')\n",
    "print(seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b43b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 29903\n",
      "{'A': 8954, 'T': 9594, 'G': 5863, 'C': 5492}\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "records = SeqIO.read(WUHAN_FASTA_PATH, \"fasta\")\n",
    "print(\"len {}\".format(len(records)))\n",
    "\n",
    "dnaSeq = records.seq\n",
    "nucleotides = {}\n",
    "for c in dnaSeq:\n",
    "    if c in nucleotides:\n",
    "        nucleotides[c] += 1\n",
    "    else:\n",
    "        nucleotides[c] = 1\n",
    "print(nucleotides)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create dataframe.\n",
    "table = pd.DataFrame(data=nucleotides, index=[0]).T.reset_index()\n",
    "table = table.rename(columns={0: 'frequency', 'index': 'nucleotides'})\n",
    "table = table.sort_values(by=['frequency'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f149bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset for prediction.\n",
    "for i in [3, 4, 5, 6]:\n",
    "    ep = generate_sample_fine_tuning_file(ALPHA_FASTA_PATH, 0, 'data/ft/fine_tuning_sample_alpha_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    fp = generate_sample_fine_tuning_file(BETA_FASTA_PATH, 1, 'data/ft/fine_tuning_sample_beta_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    gp = generate_sample_fine_tuning_file(DELTA_FASTA_PATH, 2, 'data/ft/fine_tuning_sample_delta_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782da85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files into single fine tuning file.\n",
    "for i in [3, 4, 5, 6]:\n",
    "    fp = 'data/ft/fine_tuning_sample_alpha_k-mer_'+str(i)+'.txt'\n",
    "    gp = 'data/ft/fine_tuning_sample_beta_k-mer_'+str(i)+'.txt'\n",
    "    hp = 'data/ft/fine_tuning_sample_delta_k-mer_'+str(i)+'.txt'\n",
    "    merge_files([fp, gp, hp], 'data/ft/fine_tuning_sample_k-mer_{}_ALPHA_BETA_DELTA.tsv'.format(str(i)), ['sequence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate protein dataset for prediction.\n",
    "for i in [3,4,5,6]:\n",
    "    ep = generate_sample_fine_tuning_file(ALPHA_PROT_FASTA_PATH, 0, 'data/ft/prot/fine_tuning_prot_sample_alpha_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    fp = generate_sample_fine_tuning_file(BETA_PROT_FASTA_PATH, 1, 'data/ft/prot/fine_tuning_prot_sample_beta_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    gp = generate_sample_fine_tuning_file(DELTA_PROT_FASTA_PATH, 2, 'data/ft/prot/fine_tuning_prot_sample_delta_k-mer_'+str(i)+'.txt', N_SAMPLES, i, N_K_MER)\n",
    "    merge_files([ep, fp, gp], 'data/ft/prot/fine_tuning_sample_prot_k-mer_{}_ALPHA_BETA_DELTA.tsv'.format(str(i)), ['sequence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa61920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the sequence collection into files based on its sequence id in fasta.\n",
    "# Filename = prefix-sequence_id_from_fasta-class-k_mer.txt\n",
    "# @param fasta_file : Fasta file as source.\n",
    "# @param prefix : Filename prefix.\n",
    "# @param class_name : The class for this fasta file in number (0, 1, 2, etc.)\n",
    "# @k_mer_size : Size of k-mer\n",
    "# @dest_dir : Intended file directory.\n",
    "def generate_sequence_file(fasta_file, prefix, class_name, k_mer_size, dest_dir):\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    for record in records:\n",
    "        if not (os.path.exists(dest_dir)):\n",
    "            # os.mkdir(dest_dir)\n",
    "            import pathlib\n",
    "            pathlib.Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "        output_file_name = dest_dir + '/' + prefix + '-' + record.id + str(class_name) + str(k_mer_size) + '.txt'\n",
    "        if (os.path.exists(output_file_name)):\n",
    "            os.remove(output_file_name)\n",
    "        output_file = open(output_file_name, 'w+')\n",
    "        seq = create_k_mer(str(record.seq), k_mer_size, -1)\n",
    "        output_file.write(seq + '\\t' + str(class_name))\n",
    "        output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual sequence.\n",
    "# generate_sequence_file(ALPHA_FASTA_PATH, PREFIX, ALPHA_CLASS, -1, DEST_DIR) # don't do it. source file is too big.\n",
    "generate_sequence_file(BETA_FASTA_PATH, PREFIX, BETA_CLASS, -1, DEST_DIR_BETA)\n",
    "generate_sequence_file(DELTA_FASTA_PATH, PREFIX, DELTA_CLASS, -1, DEST_DIR_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee39d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for predictions.\n",
    "# @param fasta_file : Path to fasta file.\n",
    "# @param output_file_path : What and where the prediction file is named and stored. \n",
    "#                           If file path exists, existing file will be removed.\n",
    "# @seq_index : From where sequence is read.\n",
    "# @n_samples : How many sequences are used to create prediction file.\n",
    "# @k_mer : Size of k-mer.\n",
    "# @n_k_mer : How many kmers are written to file for each sequence in fasta file.\n",
    "def generate_data_to_predict(fasta_file, output_file_path, seq_index, n_samples, k_mer, n_k_mer):\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    if (len(records)) > n_samples:\n",
    "        records = records[seq_index:n_samples]\n",
    "    \n",
    "    if (os.path.exists(output_file_path)):\n",
    "        os.remove(output_file_path)\n",
    "    \n",
    "    output_file = open(output_file_path, 'w+')\n",
    "    for r in records:\n",
    "        output_file.write(create_k_mer(str(r.seq), k_mer, n_k_mer) + '\\n')\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for prediction\n",
    "generate_data_to_predict(ALPHA_FASTA_PATH, 'prediction_sample_alpha_'+str(K_MER)+'.txt', N_SAMPLES, N_SAMPLES, K_MER, N_K_MER)\n",
    "generate_data_to_predict(BETA_FASTA_PATH, 'prediction_sample_alpha_'+str(K_MER)+'.txt', N_SAMPLES, N_SAMPLES, K_MER, N_K_MER)\n",
    "generate_data_to_predict(DELTA_FASTA_PATH, 'prediction_sample_alpha_'+str(K_MER)+'.txt', N_SAMPLES, N_SAMPLES, K_MER, N_K_MER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd2358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
