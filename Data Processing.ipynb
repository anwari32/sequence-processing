{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.1.1.7 (Alpha), \n",
    "ALPHA_FASTA_PATH=\"data/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\"\n",
    "# B.1.351 (Beta), \n",
    "BETA_FASTA_PATH=\"data/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\"\n",
    "# B.1.617.2 (Delta), \n",
    "DELTA_FASTA_PATH=\"data/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\"\n",
    "# and P.1 (Gamma)\n",
    "\n",
    "ALPHA_CLASS = 1\n",
    "BETA_CLASS = 2\n",
    "DELTA_CLASS = 3\n",
    "\n",
    "K_MER_6 = 6\n",
    "K_MER_5 = 5\n",
    "K_MER_4 = 4\n",
    "K_MER_3 = 3\n",
    "K_MERS = [K_MER_3, K_MER_4, K_MER_5, K_MER_6]\n",
    "N_K_MER = 100 # How many k-mers are retrieved per sequence.\n",
    "N_SAMPLES = 100 # How many sequences are retrieved.\n",
    "\n",
    "\"\"\"\n",
    "len ALPHA 169317\n",
    "len BETA 477\n",
    "len DELTA 3848\n",
    "\"\"\"\n",
    "\n",
    "PREFIX = 'sarscov2'\n",
    "DEST_DIR = 'data'\n",
    "DEST_DIR_ALPHA = DEST_DIR + '/alpha'\n",
    "DEST_DIR_BETA = DEST_DIR + '/beta'\n",
    "DEST_DIR_DELTA = DEST_DIR + '/delta'\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "DROSOPHILA_DIR = \"{}/drosophila/ncbi_dataset/data\".format(DATA_DIR)\n",
    "ECOLI_DIR = \"{}/ecoli/ncbi_dataset/data\".format(DATA_DIR)\n",
    "EULEMUR_DIR = \"{}/eulemur/ncbi_dataset/data\".format(DATA_DIR)\n",
    "PAPIO_DIR = \"{}/papio/ncbi_dataset/data\".format(DATA_DIR)\n",
    "SARSCOV2_DIR = \"{}/sarscov2\".format(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60265e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data Preprocessing\n",
    "import Bio\n",
    "from utils import create_k_mer\n",
    "from files import merge_files, generate_sample_fine_tuning_file\n",
    "\n",
    "# Generate K-Mer from sequence\n",
    "s = \"GTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACT\"\n",
    "print(create_k_mer(s, 3, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Raw K-Mer from Fasta files.\n",
    "# generate_sample_fine_tuning_file(ALPHA_FASTA_PATH, ALPHA_CLASS, 'raw_alpha_'+str(K_MER)+'.txt', -1, K_MER, -1)\n",
    "generate_sample_fine_tuning_file(BETA_FASTA_PATH, BETA_CLASS, 'raw_beta_'+str(K_MER)+'.txt', -1, K_MER, -1)\n",
    "generate_sample_fine_tuning_file(DELTA_FASTA_PATH, DELTA_CLASS, 'raw_delta_'+str(K_MER)+'.txt', -1, K_MER, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa61920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the sequence collection into files based on its sequence id in fasta.\n",
    "# Filename = prefix-sequence_id_from_fasta-class-k_mer.txt\n",
    "# @param fasta_file : Fasta file as source.\n",
    "# @param prefix : Filename prefix.\n",
    "# @param class_name : The class for this fasta file in number (0, 1, 2, etc.)\n",
    "# @k_mer_size : Size of k-mer\n",
    "# @dest_dir : Intended file directory.\n",
    "def generate_sequence_file(fasta_file, prefix, class_name, k_mer_size, dest_dir):\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    for record in records:\n",
    "        if not (os.path.exists(dest_dir)):\n",
    "            # os.mkdir(dest_dir)\n",
    "            import pathlib\n",
    "            pathlib.Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "        output_file_name = dest_dir + '/' + prefix + '-' + record.id + str(class_name) + str(k_mer_size) + '.txt'\n",
    "        if (os.path.exists(output_file_name)):\n",
    "            os.remove(output_file_name)\n",
    "        output_file = open(output_file_name, 'w+')\n",
    "        seq = create_k_mer(str(record.seq), k_mer_size, -1)\n",
    "        output_file.write(seq + '\\t' + str(class_name))\n",
    "        output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual sequence.\n",
    "# generate_sequence_file(ALPHA_FASTA_PATH, PREFIX, ALPHA_CLASS, -1, DEST_DIR) # don't do it. source file is too big.\n",
    "generate_sequence_file(BETA_FASTA_PATH, PREFIX, BETA_CLASS, -1, DEST_DIR_BETA)\n",
    "generate_sequence_file(DELTA_FASTA_PATH, PREFIX, DELTA_CLASS, -1, DEST_DIR_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee39d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from utils import create_k_mer\n",
    "import os\n",
    "\n",
    "# Generate data for predictions.\n",
    "# @param fasta_file : Path to fasta file.\n",
    "# @param output_file_path : What and where the prediction file is named and stored. \n",
    "#                           If file path exists, existing file will be removed.\n",
    "# @seq_index : From where sequence is read.\n",
    "# @n_samples : How many sequences are used to create prediction file.\n",
    "# @k_mer : Size of k-mer.\n",
    "# @n_k_mer : How many kmers are written to file for each sequence in fasta file.\n",
    "# @label : Label of this prediction.\n",
    "def generate_data_to_predict(fasta_file, output_file_path, seq_index, n_samples, k_mer, n_k_mer, label):\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    print('reading source file {}'.format(fasta_file))\n",
    "    if (len(records)) > n_samples:\n",
    "        records = records[seq_index:n_samples]\n",
    "    \n",
    "    print('writing {} records at target file {}'.format(len(records), output_file_path))\n",
    "    if (os.path.exists(output_file_path)):\n",
    "        print(\"File exists at {} -> removing existing\".format(output_file_path))\n",
    "        os.remove(output_file_path)\n",
    "    \n",
    "    output_file = open(output_file_path, 'w+')\n",
    "    output_file.write('sequence' + '\\t' + 'label' + '\\n')\n",
    "    for r in records:\n",
    "        output_file.write(create_k_mer(str(r.seq), k_mer, n_k_mer) + '\\t' + str(label) + '\\n')\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809b1fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-alpha-3.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-beta-3.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-delta-3.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-alpha-3.txt\n",
      "File exists at data/sarscov2/ft/dev-alpha-3.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-beta-3.txt\n",
      "File exists at data/sarscov2/ft/dev-beta-3.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-delta-3.txt\n",
      "File exists at data/sarscov2/ft/dev-delta-3.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-alpha-4.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-beta-4.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-delta-4.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-alpha-4.txt\n",
      "File exists at data/sarscov2/ft/dev-alpha-4.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-beta-4.txt\n",
      "File exists at data/sarscov2/ft/dev-beta-4.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-delta-4.txt\n",
      "File exists at data/sarscov2/ft/dev-delta-4.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-alpha-5.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-beta-5.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-delta-5.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-alpha-5.txt\n",
      "File exists at data/sarscov2/ft/dev-alpha-5.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-beta-5.txt\n",
      "File exists at data/sarscov2/ft/dev-beta-5.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-delta-5.txt\n",
      "File exists at data/sarscov2/ft/dev-delta-5.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-alpha-6.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-beta-6.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 400 records at target file data/sarscov2/ft/train-delta-6.txt\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-alpha-6.txt\n",
      "File exists at data/sarscov2/ft/dev-alpha-6.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-beta-6.txt\n",
      "File exists at data/sarscov2/ft/dev-beta-6.txt -> removing existing\n",
      "reading source file data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\n",
      "writing 51 records at target file data/sarscov2/ft/dev-delta-6.txt\n",
      "File exists at data/sarscov2/ft/dev-delta-6.txt -> removing existing\n"
     ]
    }
   ],
   "source": [
    "# Dataset COVID19\n",
    "# Generate data for fine tuning\n",
    "ALPHA_PATH = \"data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.1.7-human_origin.fasta\"\n",
    "BETA_PATH = \"data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.351-human_origin.fasta\"\n",
    "DELTA_PATH = \"data/sarscov2/raw/complete-nucl-sars_cov_2-B.1.617.2-human_origin.fasta\"\n",
    "K_MERS = [3,4,5,6]\n",
    "N_K_MER = 100 # How many k-mers are retrieved per sequence.\n",
    "N_SAMPLES = 100 # How many sequences are retrieved.\n",
    "\n",
    "for k in K_MERS:\n",
    "    # Generate fine tuning data\n",
    "    generate_data_to_predict(ALPHA_PATH, 'data/sarscov2/ft/train-alpha-{}.txt'.format(k), 0, 4*N_SAMPLES, k, N_K_MER, 0)\n",
    "    generate_data_to_predict(BETA_PATH, 'data/sarscov2/ft/train-beta-{}.txt'.format(k), 0, 4*N_SAMPLES, k, N_K_MER, 1)\n",
    "    generate_data_to_predict(DELTA_PATH, 'data/sarscov2/ft/train-delta-{}.txt'.format(k), 0, 4*N_SAMPLES, k, N_K_MER, 2)\n",
    "    \n",
    "    # Generate test data\n",
    "    generate_data_to_predict(ALPHA_PATH, 'data/sarscov2/ft/dev-alpha-{}.txt'.format(k), 400, 451, k, N_K_MER, 0)\n",
    "    generate_data_to_predict(BETA_PATH, 'data/sarscov2/ft/dev-beta-{}.txt'.format(k), 400, 451, k, N_K_MER, 1)\n",
    "    generate_data_to_predict(DELTA_PATH, 'data/sarscov2/ft/dev-delta-{}.txt'.format(k), 400, 451, k, N_K_MER, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb715c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169317\n",
      "477\n",
      "3848\n"
     ]
    }
   ],
   "source": [
    "records = list(SeqIO.parse(ALPHA_PATH, 'fasta'))\n",
    "print(len(records))\n",
    "records = list(SeqIO.parse(BETA_PATH, 'fasta'))\n",
    "print(len(records))\n",
    "records = list(SeqIO.parse(DELTA_PATH, 'fasta'))\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae7b834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file data/sarscov2/ft/train-alpha-3.txt\n",
      "reading file data/sarscov2/ft/train-beta-3.txt\n",
      "reading file data/sarscov2/ft/train-delta-3.txt\n",
      "reading file data/sarscov2/ft/dev-alpha-3.txt\n",
      "reading file data/sarscov2/ft/dev-beta-3.txt\n",
      "reading file data/sarscov2/ft/dev-delta-3.txt\n",
      "reading file data/sarscov2/ft/train-alpha-4.txt\n",
      "reading file data/sarscov2/ft/train-beta-4.txt\n",
      "reading file data/sarscov2/ft/train-delta-4.txt\n",
      "reading file data/sarscov2/ft/dev-alpha-4.txt\n",
      "reading file data/sarscov2/ft/dev-beta-4.txt\n",
      "reading file data/sarscov2/ft/dev-delta-4.txt\n",
      "reading file data/sarscov2/ft/train-alpha-5.txt\n",
      "reading file data/sarscov2/ft/train-beta-5.txt\n",
      "reading file data/sarscov2/ft/train-delta-5.txt\n",
      "reading file data/sarscov2/ft/dev-alpha-5.txt\n",
      "reading file data/sarscov2/ft/dev-beta-5.txt\n",
      "reading file data/sarscov2/ft/dev-delta-5.txt\n",
      "reading file data/sarscov2/ft/train-alpha-6.txt\n",
      "reading file data/sarscov2/ft/train-beta-6.txt\n",
      "reading file data/sarscov2/ft/train-delta-6.txt\n",
      "reading file data/sarscov2/ft/dev-alpha-6.txt\n",
      "reading file data/sarscov2/ft/dev-beta-6.txt\n",
      "reading file data/sarscov2/ft/dev-delta-6.txt\n"
     ]
    }
   ],
   "source": [
    "from files import merge_files\n",
    "\n",
    "for k in K_MERS:\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/sarscov2/ft/train-alpha-{}.txt\".format(k),\n",
    "            \"data/sarscov2/ft/train-beta-{}.txt\".format(k),\n",
    "            \"data/sarscov2/ft/train-delta-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/sarscov2/ft/train-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/sarscov2/ft/dev-alpha-{}.txt\".format(k),\n",
    "            \"data/sarscov2/ft/dev-beta-{}.txt\".format(k),\n",
    "            \"data/sarscov2/ft/dev-delta-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/sarscov2/ft/dev-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8fd2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3065\n",
      "26533\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "human_TATA_promotor_file = \"data/homo-sapiens/human_TATA_hg38.fa\"\n",
    "human_nonTATA_promotor_file = \"data/homo-sapiens/human_nonTATA_hg38.fa\"\n",
    "\n",
    "# Dataset Human Genome Promotor\n",
    "human_TATA_records = list(SeqIO.parse(human_TATA_promotor_file, 'fasta'))\n",
    "human_nonTATA_records = list(SeqIO.parse(human_nonTATA_promotor_file, 'fasta'))\n",
    "print(len(human_TATA_records))\n",
    "print(len(human_nonTATA_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ece03f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-TATA-3.txt\n",
      "File exists at data/homo-sapiens/ft/train-TATA-3.txt -> removing existing\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-nonTATA-3.txt\n",
      "File exists at data/homo-sapiens/ft/train-nonTATA-3.txt -> removing existing\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-TATA-3.txt\n",
      "File exists at data/homo-sapiens/ft/dev-TATA-3.txt -> removing existing\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonTATA-3.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-TATA-4.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-nonTATA-4.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-TATA-4.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonTATA-4.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-TATA-5.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-nonTATA-5.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-TATA-5.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonTATA-5.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-TATA-6.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 3000 records at target file data/homo-sapiens/ft/train-nonTATA-6.txt\n",
      "reading source file data/homo-sapiens/ft/human_TATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-TATA-6.txt\n",
      "reading source file data/homo-sapiens/ft/human_nonTATA_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonTATA-6.txt\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 3000\n",
    "LABEL_NON_TATA = 0\n",
    "LABEL_TATA = 1\n",
    "K_MERS = [3,4,5,6]\n",
    "\n",
    "for k in K_MERS:\n",
    "    # Generate fine tuning data.\n",
    "    generate_data_to_predict(human_TATA_promotor_file, 'data/homo-sapiens/ft/train-TATA-{}.txt'.format(k), 0, N_SAMPLES, k, N_K_MER, LABEL_TATA)\n",
    "    generate_data_to_predict(human_nonTATA_promotor_file, 'data/homo-sapiens/ft/train-nonTATA-{}.txt'.format(k), 0, N_SAMPLES, k, N_K_MER, LABEL_NON_TATA)\n",
    "    \n",
    "    # Generate test data.\n",
    "    generate_data_to_predict(human_TATA_promotor_file, 'data/homo-sapiens/ft/dev-TATA-{}.txt'.format(k), N_SAMPLES, N_SAMPLES+50, k, N_K_MER, LABEL_TATA)\n",
    "    generate_data_to_predict(human_nonTATA_promotor_file, 'data/homo-sapiens/ft/dev-nonTATA-{}.txt'.format(k), N_SAMPLES, N_SAMPLES+50, k, N_K_MER, LABEL_NON_TATA)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b076cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file data/homo-sapiens/ft/train-TATA-3.txt\n",
      "reading file data/homo-sapiens/ft/train-nonTATA-3.txt\n",
      "reading file data/homo-sapiens/ft/dev-TATA-3.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonTATA-3.txt\n",
      "reading file data/homo-sapiens/ft/train-TATA-4.txt\n",
      "reading file data/homo-sapiens/ft/train-nonTATA-4.txt\n",
      "reading file data/homo-sapiens/ft/dev-TATA-4.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonTATA-4.txt\n",
      "reading file data/homo-sapiens/ft/train-TATA-5.txt\n",
      "reading file data/homo-sapiens/ft/train-nonTATA-5.txt\n",
      "reading file data/homo-sapiens/ft/dev-TATA-5.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonTATA-5.txt\n",
      "reading file data/homo-sapiens/ft/train-TATA-6.txt\n",
      "reading file data/homo-sapiens/ft/train-nonTATA-6.txt\n",
      "reading file data/homo-sapiens/ft/dev-TATA-6.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonTATA-6.txt\n"
     ]
    }
   ],
   "source": [
    "from files import merge_files\n",
    "\n",
    "for k in K_MERS:\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/homo-sapiens/ft/train-TATA-{}.txt\".format(k),\n",
    "            \"data/homo-sapiens/ft/train-nonTATA-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/homo-sapiens/ft/train-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/homo-sapiens/ft/dev-TATA-{}.txt\".format(k),\n",
    "            \"data/homo-sapiens/ft/dev-nonTATA-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/homo-sapiens/ft/dev-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e3933c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4804\n",
      "24794\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "human_CCAAT_promotor_file = \"data/homo-sapiens/human_CCAAT_hg38.fa\"\n",
    "human_nonCCAAT_promotor_file = \"data/homo-sapiens/human_nonCCAAT_hg38.fa\"\n",
    "\n",
    "# Dataset Human Genome Promotor\n",
    "human_CCAAT_records = list(SeqIO.parse(human_CCAAT_promotor_file, 'fasta'))\n",
    "human_nonCCAAT_records = list(SeqIO.parse(human_nonCCAAT_promotor_file, 'fasta'))\n",
    "print(len(human_CCAAT_records))\n",
    "print(len(human_nonCCAAT_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a917ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-CCAAT-3.txt\n",
      "File exists at data/homo-sapiens/ft/train-CCAAT-3.txt -> removing existing\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-nonCCAAT-3.txt\n",
      "File exists at data/homo-sapiens/ft/train-nonCCAAT-3.txt -> removing existing\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-CCAAT-3.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonCCAAT-3.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-CCAAT-4.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-nonCCAAT-4.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-CCAAT-4.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonCCAAT-4.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-CCAAT-5.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-nonCCAAT-5.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-CCAAT-5.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonCCAAT-5.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-CCAAT-6.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 4500 records at target file data/homo-sapiens/ft/train-nonCCAAT-6.txt\n",
      "reading source file data/homo-sapiens/human_CCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-CCAAT-6.txt\n",
      "reading source file data/homo-sapiens/human_nonCCAAT_hg38.fa\n",
      "writing 50 records at target file data/homo-sapiens/ft/dev-nonCCAAT-6.txt\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 4500\n",
    "LABEL_NON_CCAAT = 0\n",
    "LABEL_CCAAT = 1\n",
    "K_MERS = [3,4,5,6]\n",
    "\n",
    "for k in K_MERS:\n",
    "    # Generate fine tuning data.\n",
    "    generate_data_to_predict(human_CCAAT_promotor_file, 'data/homo-sapiens/ft/train-CCAAT-{}.txt'.format(k), 0, N_SAMPLES, k, N_K_MER, LABEL_TATA)\n",
    "    generate_data_to_predict(human_nonCCAAT_promotor_file, 'data/homo-sapiens/ft/train-nonCCAAT-{}.txt'.format(k), 0, N_SAMPLES, k, N_K_MER, LABEL_NON_TATA)\n",
    "    \n",
    "    # Generate test data.\n",
    "    generate_data_to_predict(human_CCAAT_promotor_file, 'data/homo-sapiens/ft/dev-CCAAT-{}.txt'.format(k), N_SAMPLES, N_SAMPLES+50, k, N_K_MER, LABEL_TATA)\n",
    "    generate_data_to_predict(human_nonCCAAT_promotor_file, 'data/homo-sapiens/ft/dev-nonCCAAT-{}.txt'.format(k), N_SAMPLES, N_SAMPLES+50, k, N_K_MER, LABEL_NON_TATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "059ed268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file data/homo-sapiens/ft/train-CCAAT-3.txt\n",
      "reading file data/homo-sapiens/ft/train-nonCCAAT-3.txt\n",
      "reading file data/homo-sapiens/ft/dev-CCAAT-3.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonCCAAT-3.txt\n",
      "reading file data/homo-sapiens/ft/train-CCAAT-4.txt\n",
      "reading file data/homo-sapiens/ft/train-nonCCAAT-4.txt\n",
      "reading file data/homo-sapiens/ft/dev-CCAAT-4.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonCCAAT-4.txt\n",
      "reading file data/homo-sapiens/ft/train-CCAAT-5.txt\n",
      "reading file data/homo-sapiens/ft/train-nonCCAAT-5.txt\n",
      "reading file data/homo-sapiens/ft/dev-CCAAT-5.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonCCAAT-5.txt\n",
      "reading file data/homo-sapiens/ft/train-CCAAT-6.txt\n",
      "reading file data/homo-sapiens/ft/train-nonCCAAT-6.txt\n",
      "reading file data/homo-sapiens/ft/dev-CCAAT-6.txt\n",
      "reading file data/homo-sapiens/ft/dev-nonCCAAT-6.txt\n"
     ]
    }
   ],
   "source": [
    "from files import merge_files\n",
    "\n",
    "for k in K_MERS:\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/homo-sapiens/ft/train-CCAAT-{}.txt\".format(k),\n",
    "            \"data/homo-sapiens/ft/train-nonCCAAT-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/homo-sapiens/ft/ccaat-promoter/train-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )\n",
    "    merge_files(\n",
    "        [\n",
    "            \"data/homo-sapiens/ft/dev-CCAAT-{}.txt\".format(k),\n",
    "            \"data/homo-sapiens/ft/dev-nonCCAAT-{}.txt\".format(k)\n",
    "        ],\n",
    "        'data/homo-sapiens/ft/ccaat-promoter/dev-{}.tsv'.format(k),\n",
    "        ['sequence', 'label']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7676945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of tata ccaat records : 672\n",
      "len of tata non-ccaat records : 2393\n",
      "len of non tata ccaat records : 4132\n",
      "len of non tata non ccaat records : 22401\n"
     ]
    }
   ],
   "source": [
    "TATA_CCAAT_FILE = \"data/homo-sapiens/human_TATA_CCAAT_hg38.fa\"\n",
    "TATA_nonCCAAT_FILE = \"data/homo-sapiens/human_TATA_nonCCAAT_hg38.fa\"\n",
    "nonTATA_CCAAT_FILE = \"data/homo-sapiens/human_nonTATA_CCAAT_hg38.fa\"\n",
    "nonTATA_nonCCAAT_FILE = \"data/homo-sapiens/human_nonTATA_nonCCAAT_hg38.fa\"\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "tata_ccaat_records = list(SeqIO.parse(TATA_CCAAT_FILE, 'fasta'))\n",
    "tata_nonccaat_records = list(SeqIO.parse(TATA_nonCCAAT_FILE, 'fasta'))\n",
    "nontata_ccaat_records = list(SeqIO.parse(nonTATA_CCAAT_FILE, 'fasta'))\n",
    "nontata_nonccaat_records = list(SeqIO.parse(nonTATA_nonCCAAT_FILE, 'fasta'))\n",
    "\n",
    "print('len of tata ccaat records : {}'.format(len(tata_ccaat_records))) # 672\n",
    "print('len of tata non-ccaat records : {}'.format(len(tata_nonccaat_records))) # 2393\n",
    "print('len of non tata ccaat records : {}'.format(len(nontata_ccaat_records))) # 4132\n",
    "print('len of non tata non ccaat records : {}'.format(len(nontata_nonccaat_records))) # 22401\n",
    "\n",
    "N_SAMPLES = 4500\n",
    "LABEL_NON_CCAAT = 0\n",
    "LABEL_CCAAT = 1\n",
    "K_MERS = [3,4,5,6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8b8365",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/deepromoter/human_tata_positive.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5124/531832308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Begin process positive tata.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_dataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_tata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeqIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fasta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/deepromoter/human_tata_positive.txt'"
     ]
    }
   ],
   "source": [
    "# Generate TATA positive-dataset.\n",
    "human_tata_ccaat = \"data/homo-sapiens/human_TATA_CCAAT_hg38.fa\"\n",
    "human_tata_nonccaat = \"data/homo-sapiens/human_TATA_nonCCAAT_hg38.fa\"\n",
    "human_tata = \"data/homo-sapiens/human_TATA_hg38.fa\"\n",
    "\n",
    "human_nontata_ccaat = \"data/homo-sapiens/human_nonTATA_CCAAT_hg38.fa\"\n",
    "human_nontata_nonccaat = \"data/homo-sapiens/human_nonTATA_nonCCAAT_hg38.fa\"\n",
    "human_nontata = \"data/homo-sapiens/human_nonTATA_hg38.fa\"\n",
    "\n",
    "positive_tata = [human_tata_ccaat, human_tata_nonccaat, human_tata]\n",
    "negative_tata = [human_nontata_ccaat, human_nontata_nonccaat, human_nontata]\n",
    "\n",
    "positive_label = \"1\"\n",
    "negative_label = \"0\"\n",
    "\n",
    "# This data is generated for DeePromoter so generate 300bp only for each sequence.\n",
    "# Data is in FASTA format so use SeqIO from Bio\n",
    "positive_dataset_path = \"/deepromoter/human_tata_positive.txt\"\n",
    "negative_dataset_path = \"/deepromoter/human_tata_negative.txt\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(positive_dataset_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(negative_dataset_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Begin process positive tata.\n",
    "file = open(positive_dataset_path, 'w+')\n",
    "for p in positive_tata:\n",
    "    records = list(SeqIO.parse(p, \"fasta\"))\n",
    "    records = records[0:100] # Get only first 100 records.\n",
    "    for r in records:\n",
    "        sequence = str(r.seq)[0:300] # Retrieve only first 300 bp.\n",
    "        file.write(sequence + '\\n')\n",
    "        \n",
    "file.close()\n",
    "\n",
    "# Begin process negative tata.\n",
    "file = open(negative_dataset_path, 'w+')\n",
    "for p in negative_tata:\n",
    "    records = list(SeqIO.parse(p, 'fasta'))\n",
    "    records = records[0:100]\n",
    "    for r in records:\n",
    "        sequence = str(r.seq)[0:300] # Retrieve only first 300 bp.\n",
    "        file.write(sequence + '\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35089a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
