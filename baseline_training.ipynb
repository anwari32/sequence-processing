{"cells":[{"cell_type":"markdown","metadata":{"id":"bNkZ0FzTquu7"},"source":["Baseline Seqlab KMER uses Untari et. al. paradigm."]},{"cell_type":"markdown","metadata":{"id":"RGxaCOTJLsbc"},"source":["# Libraries"]},{"cell_type":"markdown","metadata":{"id":"1IgYGX7dLoHJ"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4969,"status":"ok","timestamp":1666343630812,"user":{"displayName":"23520050 Muhammad Anwari Leksono","userId":"10216529767611655188"},"user_tz":-420},"id":"Wn4UrrdlLwQw"},"outputs":[],"source":["# Import Lib\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import time\n","import keras\n","import keras.utils\n","import tensorflow as tf\n","from keras.layers import Embedding, Dense, Flatten, Dropout, SpatialDropout1D, TimeDistributed, LSTM, GRU, Bidirectional\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv1D\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score\n","from keras import Input, Model\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from collections import Counter\n","from sklearn.metrics import roc_curve, roc_auc_score, auc\n","from sklearn.model_selection import KFold\n","from imblearn.under_sampling import RandomUnderSampler\n","from collections import Counter\n","import os"]},{"cell_type":"markdown","metadata":{"id":"vvqeUsUbL7jV"},"source":["# Hyperparameter and Paths"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666330720102,"user":{"displayName":"23520050 Muhammad Anwari Leksono","userId":"10216529767611655188"},"user_tz":-420},"id":"kaaJ_i9sL8vE"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","\n","num_classes = 2\n","vocab_size = 5\n","embedding_dim = 4\n","window_size = 150\n","units = 256\n","dropout = 0.2\n","numlayer = 2\n","metrics = [\n","    'accuracy', \n","    tf.keras.metrics.Precision(),\n","    tf.keras.metrics.Recall()\n","]\n","\n","data_dir = os.path.join(\"workspace\", \"baseline\")\n","work_dir = os.path.join(\"run\", \"baseline\")\n","training_data_file = \"gene_index.01_train_validation_ss_all_pos_train.csv\"\n","validation_data_file = \"gene_index.01_train_validation_ss_all_pos_validation.csv\"\n","test_data_file = \"gene_index.01_test_ss_all_pos.csv\""]},{"cell_type":"markdown","metadata":{"id":"yhe-PsfwLvkz"},"source":["# Dictionary"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666330720103,"user":{"displayName":"23520050 Muhammad Anwari Leksono","userId":"10216529767611655188"},"user_tz":-420},"id":"JU3mCs7WhtHp","outputId":"6b54ff50-259d-46c9-e496-3ba96eb34286"},"outputs":[],"source":["def compute_f1_score(precision, recall):\n","  f1_score = (2 * precision * recall) / (precision + recall)\n","  return f1_score\n","\n","metrics = [\n","  'accuracy', \n","  tf.keras.metrics.Precision(name=\"precision\"),\n","  tf.keras.metrics.Recall(name=\"recall\"),\n","]\n","\n","# Nucleotide order: T, C, A, G\n","nucleotide_dict = {\n","    \"T\": 1,\n","    \"C\": 2,\n","    \"A\": 3,\n","    \"G\": 4, \n","    \"N\": 0\n","}\n","\n","exon_intron_dict = {\n","    \"i\": 0,\n","    \"E\": 1,\n","    \"N\": -100,\n","}\n","\n","embedding_matrix = np.array([[0, 0, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n","vocab_size = 4 + 1\n","embedding_dim = embedding_matrix.shape[1]\n","\n","def convert_label(y, num_classes):\n","  if y in [0, 1]:\n","    return tf.keras.utils.to_categorical(y, num_classes)\n","  else:\n","    return [0, 0]\n","\n","def preprocessing(data_path):\n","  encoded_sequences = []\n","  encoded_labels = []\n","  df = pd.read_csv(data_path)\n","  for i, r in df.iterrows():\n","    sequence = r[\"sequence\"]\n","    label = r[\"label\"]\n","\n","    # padding sequence.\n","    encoded_sequence = [nucleotide_dict[a] for a in list(sequence)]\n","    if len(encoded_sequence) < 150:\n","      delta = 150 - len(encoded_sequence)\n","      for j in range(delta):\n","        encoded_sequence.append(0)\n","\n","    # padding label.\n","    encoded_label = [exon_intron_dict[a] for a in list(label)]\n","    if len(encoded_label) < 150:\n","      delta = 150 - len(encoded_label)\n","      for j in range(delta):\n","        encoded_label.append(-100)\n","\n","    encoded_sequences.append(\n","        encoded_sequence\n","    )\n","    encoded_labels.append(\n","        encoded_label\n","    )\n","  return encoded_sequences, encoded_labels\n"]},{"cell_type":"markdown","metadata":{"id":"Kr3CGMExLycC"},"source":["# Model BiLSTM"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":6570,"status":"ok","timestamp":1666330772688,"user":{"displayName":"23520050 Muhammad Anwari Leksono","userId":"10216529767611655188"},"user_tz":-420},"id":"_07slEYWLY8p","outputId":"d5d37edf-2c76-4e71-b742-f4c02363a2f1"},"outputs":[],"source":["def model_bilstm():\n","  # Architecture:\n","  input = Input(shape=(window_size,)) # Input layer\n","  model = Embedding(vocab_size, \n","                    embedding_dim, \n","                    weights=[embedding_matrix],\n","                    input_length = window_size, \n","                    trainable=False)(input)\n","  model = Bidirectional(LSTM(units, return_sequences=True))(model)\n","  if dropout>0:\n","    model = Dropout(dropout)(model)\n","  if numlayer==2:\n","    model = Bidirectional(LSTM(units, return_sequences=True))(model)\n","    if dropout>0:\n","      model = Dropout(dropout)(model)\n","  out = TimeDistributed(Dense(num_classes, activation=\"softmax\"))(model)  # TimeDistributed wrapper layer, return sequences. Fully connected layer. \n","  model = Model(input, out)\n","  opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n","  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n","  return model\n"]},{"cell_type":"markdown","metadata":{"id":"oJ2Rfmz9Mh8n"},"source":["# Model BiGRU"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1551,"status":"ok","timestamp":1666336980759,"user":{"displayName":"23520050 Muhammad Anwari Leksono","userId":"10216529767611655188"},"user_tz":-420},"id":"cTt9_KpUMWbR","outputId":"2cac66da-2d18-4003-d21a-7af52e2c8feb"},"outputs":[],"source":["def model_bigru():\n","  # Architecture:\n","  input = Input(shape=(window_size,)) # Input layer\n","  model = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n","                          input_length = window_size, trainable=False)(input)\n","  model = Bidirectional(GRU(units, return_sequences=True))(model)\n","  if dropout>0:\n","    model = Dropout(dropout)(model)\n","  if numlayer==2:\n","    model = Bidirectional(GRU(units, return_sequences=True))(model)\n","    if dropout>0:\n","      model = Dropout(dropout)(model)\n","  out = TimeDistributed(Dense(num_classes, activation=\"softmax\"))(model)  # TimeDistributed wrapper layer, return sequences. Fully connected layer. \n","  model = Model(input, out)\n","  opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n","  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n","  return model\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing:   0%|          | 0/1 [19:33<?, ?it/s]\n"]},{"ename":"ValueError","evalue":"The first argument to `Layer.call` must always be passed.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn [13], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test)\n\u001b[0;32m     25\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[convert_label(_y, num_classes) \u001b[38;5;28;01mfor\u001b[39;00m _y \u001b[38;5;129;01min\u001b[39;00m y] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y_test])\n\u001b[1;32m---> 27\u001b[0m model_bilstm \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_bilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m model_bigru \u001b[38;5;241m=\u001b[39m model_bigru()\n\u001b[0;32m     29\u001b[0m model_collection \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilstm\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_bilstm), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigru\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_bigru)]\n","File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\keras\\utils\\layer_utils.py:812\u001b[0m, in \u001b[0;36mCallFunctionSpec.split_out_first_arg\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    810\u001b[0m     inputs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_arg_names[\u001b[39m0\u001b[39m])\n\u001b[0;32m    811\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe first argument to `Layer.call` must always be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    814\u001b[0m     )\n\u001b[0;32m    815\u001b[0m \u001b[39mreturn\u001b[39;00m inputs, args, kwargs\n","\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."]}],"source":["from tqdm import tqdm\n","\n","scenarios = [\"stride1\"] #, \"ss1\"]\n","\n","for s in tqdm(scenarios, total=1, desc=\"Processing\"):\n","    cur_data_dir = os.path.join(data_dir, s)\n","    training_data_path = os.path.join(cur_data_dir, training_data_file)\n","    validation_data_path = os.path.join(cur_data_dir, validation_data_file)\n","    test_data_path = os.path.join(cur_data_dir, test_data_file)\n","\n","    model_dir = os.path.join(work_dir, s, \"model\")\n","    log_dir = os.path.join(work_dir, s, \"log\")\n","\n","    for p in [model_dir, log_dir]:\n","        os.makedirs(p, exist_ok=True)\n","\n","    X_train, Y_train = preprocessing(training_data_path)\n","    X_train = np.array(X_train)\n","    Y_train = np.array([[convert_label(_y, num_classes) for _y in y] for y in Y_train])\n","    X_val, Y_val = preprocessing(validation_data_path)\n","    X_val = np.array(X_val)\n","    Y_val = np.array([[convert_label(_y, num_classes) for _y in y] for y in Y_val])\n","    X_test, Y_test = preprocessing(test_data_path)\n","    X_test = np.array(X_test)\n","    Y_test = np.array([[convert_label(_y, num_classes) for _y in y] for y in Y_test])\n","\n","    model_bilstm = model_bilstm()\n","    model_bigru = model_bigru()\n","    model_collection = [(\"bilstm\", model_bilstm), (\"bigru\", model_bigru)]\n","\n","    for model_name, model in model_collection:\n","        train_history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=48)\n","        model.save(\n","            os.path.join(model_dir, f\"model_{model_name}.h5\")\n","        )\n","        # put history into single data map.\n","        history_keys = (train_history.history.keys())\n","        print(f\"training and validation history {history_keys}\")\n","        data = {}\n","        for k in history_keys:\n","            data[k] = train_history.history[k]\n","        \n","        # compute f1 score.\n","        train_f1_score = []\n","        val_f1_score = []\n","\n","        for p, r in zip(data.get(\"precision\"), data.get(\"recall\")):\n","            train_f1_score.append(\n","                compute_f1_score(p, r)\n","            )\n","\n","        for p, r in zip(data.get(\"val_precision\"), data.get(\"val_recall\")):\n","            val_f1_score.append(\n","                compute_f1_score(p, r)\n","            )\n","        \n","        data[\"f1_score\"] = train_f1_score\n","        data[\"val_f1_score\"] = val_f1_score\n","\n","        training_validation_result_df = pd.DataFrame(data=data)\n","        training_validation_result_df.to_csv(\n","            os.path.join(log_dir, f\"training_validation_log.arch_{model_name}.csv\"), \n","            index=False)\n","\n","    "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPPA7YJjS8ksc1/YMgIpV9t","collapsed_sections":["Kr3CGMExLycC"],"mount_file_id":"1wkv0UskCpGZWVQviHnLKhUTkYuFxCEFG","provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 ('sequence-processing-310')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"95adb5e5f98c5e0ba07577f17d74d9d3cc9cb557759904522f47cd47fc4449cf"}}},"nbformat":4,"nbformat_minor":0}
