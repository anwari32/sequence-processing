{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iiE cols ['sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iiE', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iiE__MIN', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iiE__MAX'] => sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iiE\n",
      "(2770,) [0.         0.         0.46728972 ... 0.95522388 1.         1.        ] \n",
      "\n",
      "iiE cols ['sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iEE', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iEE__MIN', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iEE__MAX'] => sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-iEE\n",
      "(2770,) [0.         0.         0.5        ... 0.81012658 0.97247706 1.        ] \n",
      "\n",
      "iiE cols ['sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-EEi', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-EEi__MIN', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-EEi__MAX'] => sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-EEi\n",
      "(2770,) [0.66666667 0.98461538 0.73170732 ... 1.         0.96969697 0.60465116] \n",
      "\n",
      "iiE cols ['sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-Eii', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-Eii__MIN', 'sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-Eii__MAX'] => sso01-adamw-lr5e-5-base-291mo307 - validation/f1_score-Eii\n",
      "(2770,) [0.54237288 0.91428571 0.71111111 ... 1.         1.         0.78787879] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = [\"sso01-adamw-lr5e-5-base-291mo307.csv\", \"sso01-adamw-lr2e-5-base-2fg7kdwu.csv\"]\n",
    "paths = [os.path.join(\"error_analysis\", f) for f in files]\n",
    "\n",
    "path = os.path.join(\"error_analysis\", \"sso01-adamw-lr5e-5-base-291mo307.csv\")\n",
    "df = pd.read_csv(path)\n",
    "columns = df.columns\n",
    "\n",
    "iiE_cols = [c for c in columns if c.find(\"iiE\") > -1]\n",
    "iiE_column = [c for c in iiE_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "print(f\"iiE cols {iiE_cols} => {iiE_column[0]}\")\n",
    "iiE_f1_scores = np.array(df[iiE_column[0]].values)\n",
    "print(f\"{iiE_f1_scores.shape} {iiE_f1_scores} \\n\")\n",
    "\n",
    "iEE_cols = [c for c in columns if c.find(\"iEE\") > -1]\n",
    "iEE_column = [c for c in iEE_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "print(f\"iiE cols {iEE_cols} => {iEE_column[0]}\")\n",
    "iEE_f1_scores = np.array(df[iEE_column[0]].values)\n",
    "print(f\"{iEE_f1_scores.shape} {iEE_f1_scores} \\n\")\n",
    "\n",
    "EEi_cols = [c for c in columns if c.find(\"EEi\") > -1]\n",
    "EEi_column = [c for c in EEi_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "print(f\"iiE cols {EEi_cols} => {EEi_column[0]}\")\n",
    "EEi_f1_scores = np.array(df[EEi_column[0]].values)\n",
    "print(f\"{EEi_f1_scores.shape} {EEi_f1_scores} \\n\")\n",
    "\n",
    "Eii_cols = [c for c in columns if c.find(\"Eii\") > -1]\n",
    "Eii_column = [c for c in Eii_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "print(f\"iiE cols {Eii_cols} => {Eii_column[0]}\")\n",
    "Eii_f1_scores = np.array(df[Eii_column[0]].values)\n",
    "print(f\"{Eii_f1_scores.shape} {Eii_f1_scores} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation {'iiE': 0.28834109888911924, 'iEE': 0.28834109888911924, 'EEi': 0.28636939129836486, 'Eii': 0.2869499663471598}\n",
      "standard deviation {'iiE': 0.24259854567947808, 'iEE': 0.24259854567947808, 'EEi': 0.29022705545997424, 'Eii': 0.28068057307115307}\n"
     ]
    }
   ],
   "source": [
    "for p in paths:\n",
    "    df = pd.read_csv(p)\n",
    "    columns = df.columns\n",
    "\n",
    "    iiE_cols = [c for c in columns if c.find(\"iiE\") > -1]\n",
    "    iiE_column = [c for c in iiE_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "    # print(f\"iiE cols {iiE_cols} => {iiE_column[0]}\")\n",
    "    iiE_f1_scores = np.array(df[iiE_column[0]].values)\n",
    "    # print(f\"{iiE_f1_scores.shape} {iiE_f1_scores} \\n\")\n",
    "\n",
    "    iEE_cols = [c for c in columns if c.find(\"iEE\") > -1]\n",
    "    iEE_column = [c for c in iEE_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "    # print(f\"iiE cols {iEE_cols} => {iEE_column[0]}\")\n",
    "    iEE_f1_scores = np.array(df[iEE_column[0]].values)\n",
    "    # print(f\"{iEE_f1_scores.shape} {iEE_f1_scores} \\n\")\n",
    "\n",
    "    EEi_cols = [c for c in columns if c.find(\"EEi\") > -1]\n",
    "    EEi_column = [c for c in EEi_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "    # print(f\"iiE cols {EEi_cols} => {EEi_column[0]}\")\n",
    "    EEi_f1_scores = np.array(df[EEi_column[0]].values)\n",
    "    # print(f\"{EEi_f1_scores.shape} {EEi_f1_scores} \\n\")\n",
    "\n",
    "    Eii_cols = [c for c in columns if c.find(\"Eii\") > -1]\n",
    "    Eii_column = [c for c in Eii_cols if c.find(\"MIN\") == -1 and c.find(\"MAX\") == -1]\n",
    "    # print(f\"iiE cols {Eii_cols} => {Eii_column[0]}\")\n",
    "    Eii_f1_scores = np.array(df[Eii_column[0]].values)\n",
    "    # print(f\"{Eii_f1_scores.shape} {Eii_f1_scores} \\n\")\n",
    "\n",
    "    ss_tokens_stdev = {\n",
    "        \"iiE\": np.std(iiE_f1_scores),\n",
    "        \"iEE\": np.std(iiE_f1_scores),\n",
    "        \"EEi\": np.std(EEi_f1_scores),\n",
    "        \"Eii\": np.std(Eii_f1_scores)\n",
    "    }\n",
    "\n",
    "    print(f\"standard deviation {ss_tokens_stdev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 70868/70868 [00:17<00:00, 4097.87it/s]\n",
      "Processing: 100%|██████████| 17717/17717 [00:06<00:00, 2930.84it/s]\n",
      "Processing: 100%|██████████| 6961/6961 [00:02<00:00, 2668.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import Bio\n",
    "from Bio.Blast import NCBIWWW\n",
    "import pandas as pd\n",
    "from data_preparation import merge_kmer\n",
    "from tqdm import tqdm\n",
    "\n",
    "training_data_path = os.path.join(\"workspace\", \"seqlab-latest\", \"gene_index.01_train_validation_ss_all_pos_train.csv\")\n",
    "validation_data_path = os.path.join(\"workspace\", \"seqlab-latest\", \"gene_index.01_train_validation_ss_all_pos_validation.csv\")\n",
    "test_data_path = os.path.join(\"workspace\", \"seqlab-latest\", \"gene_index.01_test_ss_all_pos.csv\")\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "validation_data = pd.read_csv(validation_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "training_sequences = []\n",
    "training_labels = []\n",
    "validation_sequences = []\n",
    "validation_labels = []\n",
    "test_sequences = []\n",
    "test_labels = []\n",
    "\n",
    "target_dir = os.path.join(\"error_analysis\", \"data-comparison\")\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "for d, t in zip([training_data, validation_data, test_data], [\"training_data.csv\", \"validation_data.csv\", \"test_data.csv\"]):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i, r in tqdm(d.iterrows(), total=d.shape[0], desc=\"Processing\"):\n",
    "        sequence = r[\"sequence\"].split(\" \")\n",
    "        sequence = merge_kmer(sequence)\n",
    "        sequences.append(sequence)\n",
    "        label = r[\"label\"].split(\" \")\n",
    "        label = merge_kmer(label)\n",
    "        labels.append(label)\n",
    "\n",
    "    target_path = os.path.join(target_dir, t)\n",
    "    ndf = pd.DataFrame(data={\"sequence\": sequences, \"label\": labels})\n",
    "    ndf.to_csv(target_path, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Bio\n",
    "from Bio.Blast import NCBIWWW\n",
    "import pandas as pd\n",
    "from data_preparation import merge_kmer\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_prediction_data = os.path.join(\"prediction\", \"error_analysis_log_sorted.csv\")\n",
    "target_dir = os.path.join(\"error_analysis\", \"data-comparison\")\n",
    "original_sequences = test_prediction_data[\"original_sequence\"]\n",
    "average_f1s = test_prediction_data[\"average f1\"]\n",
    "\n",
    "ndf = pd.DataFrame(data={\n",
    "    \"sequence\": original_sequences,\n",
    "    \"average_f1\": average_f1s\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Alignment****\n",
      "sequence: seq2 seq2 <unknown description>\n",
      "length: 61\n",
      "e value: 8.08221e-44\n",
      "303.0\n",
      "FQTWEEFSRAAEKLYLADPMKVRVVLKYRHVDGNLCIKVTDDLVCLVYRTDQAQDVKKIEKF\n",
      "FQTWEEFSRA EKLYLADPMKVRVVL+YRHVDGNLCIKVTDDL+CLVYRTDQAQDVKKIEKF\n",
      "FQTWEEFSRA-EKLYLADPMKVRVVLRYRHVDGNLCIKVTDDLICLVYRTDQAQDVKKIEKF\n"
     ]
    }
   ],
   "source": [
    "from Bio.Blast.Applications import NcbiblastpCommandline\n",
    "from io import StringIO\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Create two sequence files\n",
    "seq1 = SeqRecord(Seq(\"FQTWEEFSRAAEKLYLADPMKVRVVLKYRHVDGNLCIKVTDDLVCLVYRTDQAQDVKKIEKF\"),\n",
    "                   id=\"seq1\")\n",
    "seq2 = SeqRecord(Seq(\"FQTWEEFSRAEKLYLADPMKVRVVLRYRHVDGNLCIKVTDDLICLVYRTDQAQDVKKIEKF\"),\n",
    "                   id=\"seq2\")\n",
    "SeqIO.write(seq1, \"seq1.fasta\", \"fasta\")\n",
    "SeqIO.write(seq2, \"seq2.fasta\", \"fasta\")\n",
    "\n",
    "# Run BLAST and parse the output as XML\n",
    "output = NcbiblastpCommandline(query=\"seq1.fasta\", subject=\"seq2.fasta\", outfmt=5)()[0]\n",
    "blast_result_record = NCBIXML.read(StringIO(output))\n",
    "\n",
    "# Print some information on the result\n",
    "for alignment in blast_result_record.alignments:\n",
    "    for hsp in alignment.hsps:\n",
    "        print('****Alignment****')\n",
    "        print('sequence:', alignment.title)\n",
    "        print('length:', alignment.length)\n",
    "        print('e value:', hsp.expect)\n",
    "        print('e value:', hsp.score)\n",
    "        print(hsp.query)\n",
    "        print(hsp.match)\n",
    "        print(hsp.sbjct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NcbiblastnCommandline in module Bio.Blast.Applications:\n",
      "\n",
      "class NcbiblastnCommandline(_NcbiblastMain2SeqCommandline)\n",
      " |  NcbiblastnCommandline(cmd='blastn', **kwargs)\n",
      " |  \n",
      " |  Wrapper for the NCBI BLAST+ program blastn (for nucleotides).\n",
      " |  \n",
      " |  With the release of BLAST+ (BLAST rewritten in C++ instead of C), the NCBI\n",
      " |  replaced the old blastall tool with separate tools for each of the searches.\n",
      " |  This wrapper therefore replaces BlastallCommandline with option -p blastn.\n",
      " |  \n",
      " |  For example, to run a search against the \"nt\" nucleotide database using the\n",
      " |  FASTA nucleotide file \"m_code.fasta\" as the query, with an expectation value\n",
      " |  cut off of 0.001, saving the output to a file in XML format:\n",
      " |  \n",
      " |  >>> from Bio.Blast.Applications import NcbiblastnCommandline\n",
      " |  >>> cline = NcbiblastnCommandline(query=\"m_cold.fasta\", db=\"nt\", strand=\"plus\",\n",
      " |  ...                               evalue=0.001, out=\"m_cold.xml\", outfmt=5)\n",
      " |  >>> cline\n",
      " |  NcbiblastnCommandline(cmd='blastn', out='m_cold.xml', outfmt=5, query='m_cold.fasta', db='nt', evalue=0.001, strand='plus')\n",
      " |  >>> print(cline)\n",
      " |  blastn -out m_cold.xml -outfmt 5 -query m_cold.fasta -db nt -evalue 0.001 -strand plus\n",
      " |  \n",
      " |  You would typically run the command line with cline() or via the Python\n",
      " |  subprocess module, as described in the Biopython tutorial.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NcbiblastnCommandline\n",
      " |      _NcbiblastMain2SeqCommandline\n",
      " |      _Ncbiblast2SeqCommandline\n",
      " |      _NcbiblastCommandline\n",
      " |      _NcbibaseblastCommandline\n",
      " |      Bio.Application.AbstractCommandline\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, cmd='blastn', **kwargs)\n",
      " |      Initialize the class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Bio.Application.AbstractCommandline:\n",
      " |  \n",
      " |  __call__(self, stdin=None, stdout=True, stderr=True, cwd=None, env=None)\n",
      " |      Execute command, wait for it to finish, return (stdout, stderr).\n",
      " |      \n",
      " |      Runs the command line tool and waits for it to finish. If it returns\n",
      " |      a non-zero error level, an exception is raised. Otherwise two strings\n",
      " |      are returned containing stdout and stderr.\n",
      " |      \n",
      " |      The optional stdin argument should be a string of data which will be\n",
      " |      passed to the tool as standard input.\n",
      " |      \n",
      " |      The optional stdout and stderr argument may be filenames (string),\n",
      " |      but otherwise are treated as a booleans, and control if the output\n",
      " |      should be captured as strings (True, default), or ignored by sending\n",
      " |      it to /dev/null to avoid wasting memory (False). If sent to a file\n",
      " |      or ignored, then empty string(s) are returned.\n",
      " |      \n",
      " |      The optional cwd argument is a string giving the working directory\n",
      " |      to run the command from. See Python's subprocess module documentation\n",
      " |      for more details.\n",
      " |      \n",
      " |      The optional env argument is a dictionary setting the environment\n",
      " |      variables to be used in the new process. By default the current\n",
      " |      process' environment variables are used. See Python's subprocess\n",
      " |      module documentation for more details.\n",
      " |      \n",
      " |      Default example usage::\n",
      " |      \n",
      " |          from Bio.Emboss.Applications import WaterCommandline\n",
      " |          water_cmd = WaterCommandline(gapopen=10, gapextend=0.5,\n",
      " |                                       stdout=True, auto=True,\n",
      " |                                       asequence=\"a.fasta\", bsequence=\"b.fasta\")\n",
      " |          print(\"About to run: %s\" % water_cmd)\n",
      " |          std_output, err_output = water_cmd()\n",
      " |      \n",
      " |      This functionality is similar to subprocess.check_output(). In general\n",
      " |      if you require more control over running the command, use subprocess\n",
      " |      directly.\n",
      " |      \n",
      " |      When the program called returns a non-zero error level, a custom\n",
      " |      ApplicationError exception is raised. This includes any stdout and\n",
      " |      stderr strings captured as attributes of the exception object, since\n",
      " |      they may be useful for diagnosing what went wrong.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a representation of the command line object for debugging.\n",
      " |      \n",
      " |      e.g.\n",
      " |      \n",
      " |      >>> from Bio.Emboss.Applications import WaterCommandline\n",
      " |      >>> cline = WaterCommandline(gapopen=10, gapextend=0.5)\n",
      " |      >>> cline.asequence = \"asis:ACCCGGGCGCGGT\"\n",
      " |      >>> cline.bsequence = \"asis:ACCCGAGCGCGGT\"\n",
      " |      >>> cline.outfile = \"temp_water.txt\"\n",
      " |      >>> print(cline)\n",
      " |      water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5\n",
      " |      >>> cline\n",
      " |      WaterCommandline(cmd='water', outfile='temp_water.txt', asequence='asis:ACCCGGGCGCGGT', bsequence='asis:ACCCGAGCGCGGT', gapopen=10, gapextend=0.5)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Set attribute name to value (PRIVATE).\n",
      " |      \n",
      " |      This code implements a workaround for a user interface issue.\n",
      " |      Without this __setattr__ attribute-based assignment of parameters\n",
      " |      will silently accept invalid parameters, leading to known instances\n",
      " |      of the user assuming that parameters for the application are set,\n",
      " |      when they are not.\n",
      " |      \n",
      " |      >>> from Bio.Emboss.Applications import WaterCommandline\n",
      " |      >>> cline = WaterCommandline(gapopen=10, gapextend=0.5, stdout=True)\n",
      " |      >>> cline.asequence = \"a.fasta\"\n",
      " |      >>> cline.bsequence = \"b.fasta\"\n",
      " |      >>> cline.csequence = \"c.fasta\"\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Option name csequence was not found.\n",
      " |      >>> print(cline)\n",
      " |      water -stdout -asequence=a.fasta -bsequence=b.fasta -gapopen=10 -gapextend=0.5\n",
      " |      \n",
      " |      This workaround uses a whitelist of object attributes, and sets the\n",
      " |      object attribute list as normal, for these.  Other attributes are\n",
      " |      assumed to be parameters, and passed to the self.set_parameter method\n",
      " |      for validation and assignment.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Make the commandline string with the currently set options.\n",
      " |      \n",
      " |      e.g.\n",
      " |      \n",
      " |      >>> from Bio.Emboss.Applications import WaterCommandline\n",
      " |      >>> cline = WaterCommandline(gapopen=10, gapextend=0.5)\n",
      " |      >>> cline.asequence = \"asis:ACCCGGGCGCGGT\"\n",
      " |      >>> cline.bsequence = \"asis:ACCCGAGCGCGGT\"\n",
      " |      >>> cline.outfile = \"temp_water.txt\"\n",
      " |      >>> print(cline)\n",
      " |      water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5\n",
      " |      >>> str(cline)\n",
      " |      'water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5'\n",
      " |  \n",
      " |  set_parameter(self, name, value=None)\n",
      " |      Set a commandline option for a program (OBSOLETE).\n",
      " |      \n",
      " |      Every parameter is available via a property and as a named\n",
      " |      keyword when creating the instance. Using either of these is\n",
      " |      preferred to this legacy set_parameter method which is now\n",
      " |      OBSOLETE, and likely to be DEPRECATED and later REMOVED in\n",
      " |      future releases.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Bio.Application.AbstractCommandline:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from Bio.Application.AbstractCommandline:\n",
      " |  \n",
      " |  parameters = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "help(NcbiblastnCommandline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('', 'Smith-Waterman local alignment of sequences\\n')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio.Emboss.Applications import WaterCommandline\n",
    "cline = WaterCommandline(gapopen=10, gapextend=0.5)\n",
    "cline.asequence = \"asis:ACCCGGGCGCGGT\"\n",
    "cline.bsequence = \"asis:ACCCGAGCGCGGT\"\n",
    "cline.outfile = \"temp_water.txt\"\n",
    "print(cline)\n",
    "# water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5\n",
    "cline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio.Emboss.Applications import WaterCommandline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "result_path = os.path.join(\"error-analysis\", \"alignment\", \"water\")\n",
    "data_dir = os.path.join(\"error-analysis\", \"data-comparison\")\n",
    "test_data = os.path.join(data_dir, \"test_data.csv\")\n",
    "validation_data = os.path.join(data_dir, \"validation_data.csv\")\n",
    "training_data = os.path.join(data_dir, \"training_data.csv\")\n",
    "water_output_dir = os.path.join(\"error-analysis\", \"water\")\n",
    "if not os.path.exists(water_output_dir):\n",
    "    os.makedirs(water_output_dir, exist_ok=True)\n",
    "\n",
    "test_df = pd.read_csv(test_data)\n",
    "training_df = pd.read_csv(training_data)\n",
    "for i, r in test_df.iterrows():\n",
    "    test_seq = r[\"sequence\"]\n",
    "    for j, s in training_df.iterrows():\n",
    "        training_seq = s[\"sequence\"]\n",
    "        cline = WaterCommandline(gapopen=10, gapextend=0.5)\n",
    "        cline.asequence = f\"asis:{test_seq}\"\n",
    "        cline.bsequence = f\"asis:{training_seq}\"\n",
    "        cline.outfile = os.path.join(water_output_dir, f\"water[{i}][{j}].txt\")\n",
    "        cline()\n",
    "        # print(cline)\n",
    "        # water -outfile=temp_water.txt -asequence=asis:ACCCGGGCGCGGT -bsequence=asis:ACCCGAGCGCGGT -gapopen=10 -gapextend=0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity score: 0.441\n",
      "similarity score: 0.441\n",
      "water score: 386.5\n"
     ]
    }
   ],
   "source": [
    "from run_water_algorithm import parse_score_line\n",
    "import os\n",
    "\n",
    "def parse_identity_or_similarity_line(line):\n",
    "    val = line.split(\":\")[1].strip()\n",
    "    vals = val.split(\" \")\n",
    "    vals = vals[0].split(\"/\")\n",
    "    upper_val = float(vals[0])\n",
    "    lower_val = float(vals[1])\n",
    "    score = round(upper_val/lower_val, 3)\n",
    "    return score\n",
    "\n",
    "temp_output = os.path.join(\"error-analysis\", \"alignment\", \"water\", \"water[0][0].txt\")\n",
    "output = open(temp_output, \"r\").readlines()\n",
    "identity_score = parse_identity_or_similarity_line(output[23])\n",
    "similarity_score = parse_identity_or_similarity_line(output[24])\n",
    "water_score = parse_score_line(output[26])\n",
    "\n",
    "print(f\"identity score: {identity_score}\")\n",
    "print(f\"similarity score: {similarity_score}\")\n",
    "print(f\"water score: {water_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 12.0, 12.0, 12.0]\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "import numpy as np\n",
    "\n",
    "a = \"ACCCGGGCGCGGT\"\n",
    "b = \"ACCCGAGCGCGGT\"\n",
    "alignments = pairwise2.align.localxx(a, b)\n",
    "scores = [a.score for a in alignments]\n",
    "max_score = np.max(scores)\n",
    "print(scores)\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio import pairwise2\n",
    "\n",
    "training_data = pd.read_csv(os.path.join(\"error_analysis\", \"data-comparison\", \"training_data.csv\"))\n",
    "validation_data = pd.read_csv(os.path.join(\"error_analysis\", \"data-comparison\", \"validation_data.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(\"error_analysis\", \"data-comparison\", \"test_data.csv\"))\n",
    "workdir = os.path.join(\"error_analysis\", \"data-comparison\")\n",
    "test_prediction_data = pd.read_csv(os.path.join(\"prediction\", \"error_analysis_log_sorted.csv\"))\n",
    "\n",
    "test_similarity_scores = []\n",
    "for i, r in tqdm(test_prediction_data.iterrows(), total=test_data.shape[0], desc=\"Processing\"):\n",
    "    e_values = []\n",
    "    for j, s in training_data.iterrows():\n",
    "        query = r[\"original_sequence\"]\n",
    "        subject = s[\"sequence\"]\n",
    "        alignments = pairwise2.align.localxx(query, subject)\n",
    "        alignment_score = np.max([a.score for a in alignments])\n",
    "        e_values.append(alignment_score)\n",
    "\n",
    "    e_values_str = [str(a) for a in e_values]\n",
    "    e_values_str = \" \".join(e_values_str)\n",
    "    test_similarity_scores.append(e_values_str)\n",
    "    \n",
    "ndf = pd.DataFrame(data={\n",
    "    \"sequence\": test_prediction_data[\"original_sequence\"],\n",
    "    \"average_f1\": test_prediction_data[\"average f1\"],\n",
    "    \"similarity_score\": test_similarity_scores,\n",
    "})\n",
    "ndf.to_csv(\n",
    "    os.path.join(workdir, \"test_v_train_comparison.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125559\n",
      "TabularMSA[DNA]\n",
      "-----------------------------------------------------------------------\n",
      "Stats:\n",
      "    sequence count: 2\n",
      "    position count: 16384\n",
      "-----------------------------------------------------------------------\n",
      "TCATTGTGACCTGGGAGCCCTGCATGATGAAGG ... ATAACTGTAACTTTATTTATTTGTTTGTTTCTT\n",
      "TCATTGTGACCTGGGAGCCCTGCATGATGAAGG ... ATAACTGTAACTTTATTTATTTGTTTGTTTCTT\n",
      "32767\n",
      "[(0, 16383), (0, 16383)]\n"
     ]
    }
   ],
   "source": [
    "from skbio.alignment import local_pairwise_align_ssw\n",
    "from skbio.sequence import DNA\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "gene_path = os.path.join(\"data\", \"gene_dir\", \"chr8\", \"LOC101929492.csv\")\n",
    "gene_df = pd.read_csv(gene_path)\n",
    "\n",
    "sequence = gene_df.iloc[0, 0]\n",
    "\n",
    "alignment, score, start_end_positions = local_pairwise_align_ssw(\n",
    "    DNA(sequence), \n",
    "    DNA(sequence)\n",
    ")\n",
    "\n",
    "print(len(sequence))\n",
    "print(alignment)\n",
    "print(score)\n",
    "print(start_end_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deep-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb381ed8bacaf36aa3bfaca5a0502d4671ddf79cb6e63c342c2d7fda9a71fcc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
