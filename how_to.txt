HOW TO RUN MULTITASK TRAINING WITH SAMPLE TRAINING DATA with N_SAMPLE = 5, on CPU
$ python .\run_train_mtl.py -p pretrained\3-new-12w-0 -t workspace\train.sample.csv -e 5 -b 2 --device=cpu --learning_rate=4e-4 --epsilon=1e-6 --warm_up=10 --log=logs\sample_log\2022-02-27.e5.b2.loss_sum.txt --limit_train=5 --loss_strategy=sum --save_model_path=result\2022-02-27\ --beta1=0.9 --beta2=0.98

HOW TO EVAL MULTITASK WITH SAMPLE VALIDATION DATA, on CPU
$ python .\run_eval_mtl.py --pretrained=result\sample\epoch-4 --eval_data=workspace\validation.sample.csv --batch_size=2 --device=cpu --loss_strategy=sum --log="logs\eval\2022-02-27.txt"

HOW TO RUN MULTITASK TRAINING WITH TRAINING DATA train.1300.kmer.all.expanded.csv, on GPU:2
$ python .\run_train_mtl.py -p pretrained\3-new-12w-0 -t workspace\train.1300.kmer.all.expanded.csv -e 10 -b 2000 --device=cuda:2 --learning_rate=4e-4 --epsilon=1e-6 --warm_up=10000 --log=logs\2022-02-27\2022-02-27.e10.b2000.loss_sum.txt --limit_train=0 --loss_strategy=sum --save_model_path=result\2022-02-27\ --beta1=0.9 --beta2=0.98