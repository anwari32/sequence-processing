{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenv\\deep-learning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Extracting motif: 100%|██████████| 70868/70868 [03:07<00:00, 378.03it/s]\n",
      "Extracting motif: 100%|██████████| 17717/17717 [00:45<00:00, 389.88it/s]\n",
      "Extracting motif: 100%|██████████| 6961/6961 [00:17<00:00, 388.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# motif analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.motif import donor_pattern, acceptor_pattern, default_window_size\n",
    "from utils.utils import kmer, merge_kmer\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_data = os.path.join(\"workspace\", \"seqlab-latest\", \"train.csv\")\n",
    "validation_data = os.path.join(\"workspace\", \"seqlab-latest\", \"validation.csv\")\n",
    "test_data = os.path.join(\"workspace\", \"seqlab-latest\", \"test.csv\")\n",
    "paths = [train_data, validation_data, test_data]\n",
    "\n",
    "is_exists = all([os.path.exists(p) for p in paths])\n",
    "if not is_exists:\n",
    "    raise FileNotFoundError()\n",
    "\n",
    "for p in paths:\n",
    "    df = pd.read_csv(p)\n",
    "    dest_filename = \".\".join(os.path.basename(p).split(\".\")[0:-1])\n",
    "    donor_sequences, donor_targets, donor_sequence_tokens, donor_target_tokens = [], [], [], []\n",
    "    acceptor_sequences, acceptor_targets, acceptor_sequence_tokens, acceptor_target_tokens = [], [], [], []\n",
    "    for i, r in tqdm(df.iterrows(), total=df.shape[0], desc=\"Extracting motif\"):\n",
    "        sequence_tokens = r[\"sequence\"].split(\" \")\n",
    "        target_tokens = r[\"label\"].split(\" \")\n",
    "\n",
    "        arr_s = kmer(sequence_tokens, default_window_size)\n",
    "        arr_t = kmer(target_tokens, default_window_size)\n",
    "\n",
    "        for i, j in zip(arr_s, arr_t):\n",
    "            _j = kmer(j, 2, 1)\n",
    "            if donor_pattern in _j:\n",
    "                donor_sequences.append(merge_kmer(i))\n",
    "                donor_targets.append(merge_kmer(j))\n",
    "                donor_sequence_tokens.append(\" \".join(i))\n",
    "                donor_target_tokens.append(\" \".join(j))\n",
    "            if acceptor_pattern in _j:\n",
    "                acceptor_sequences.append(merge_kmer(i))\n",
    "                acceptor_targets.append(merge_kmer(j))\n",
    "                acceptor_sequence_tokens.append(\" \".join(i))\n",
    "                acceptor_target_tokens.append(\" \".join(j))\n",
    "    \n",
    "    pd.DataFrame(data={\n",
    "        \"sequence\": donor_sequences,\n",
    "        \"target\": donor_targets,\n",
    "        \"sequence_tokens\": donor_sequence_tokens,\n",
    "        \"target_tokens\": donor_target_tokens\n",
    "    }).to_csv(os.path.join(\"motif_analysis\", \"seqlab-latest\", f\"{dest_filename}.donor.csv\"), index=False)\n",
    "    pd.DataFrame(data={\n",
    "        \"sequence\": acceptor_sequences,\n",
    "        \"target\": acceptor_targets,\n",
    "        \"sequence_tokens\": acceptor_sequence_tokens,\n",
    "        \"target_tokens\": acceptor_target_tokens\n",
    "    }).to_csv(os.path.join(\"motif_analysis\", \"seqlab-latest\", f\"{dest_filename}.acceptor.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting unique motif: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract acceptor unique motif.\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "names = [\"train\", \"validation\", \"test\"]\n",
    "acceptors = [f\"{p}.donor.csv\" for p in names]\n",
    "acceptors = [os.path.join(\"motif_analysis\", \"seqlab-latest\", p) for p in acceptors]\n",
    "for p in tqdm(acceptors, total=len(acceptors), desc=\"Extracting unique motif\"):\n",
    "    df = pd.read_csv(p)\n",
    "    udf = df.drop_duplicates(subset=[\"sequence\", \"target\"])\n",
    "\n",
    "    dest_name = os.path.basename(p).split(\".\")[0:-1]\n",
    "    dest_name = f\"{'.'.join(dest_name)}.unique.csv\"\n",
    "    dest_file = os.path.join(\"motif_analysis\", \"seqlab-latest\", dest_name)\n",
    "    udf.to_csv(dest_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-reference training and test data to see if their acceptor motifs are intersected.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "for p in [\"donor\", \"acceptor\"]:\n",
    "    dir_path = os.path.join(\"motif_analysis\", \"seqlab-latest\")\n",
    "    test_path = os.path.join(dir_path, f\"test.{p}.unique.csv\")\n",
    "    validation_path = os.path.join(dir_path, f\"validation.{p}.unique.csv\")\n",
    "    train_path = os.path.join(dir_path, f\"train.{p}.unique.csv\")\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    validation_df = pd.read_csv(validation_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    def check(row, dataframe):\n",
    "        seq = row[\"sequence\"]\n",
    "        count = dataframe[dataframe[\"sequence\"] == seq].shape[0]\n",
    "        if count > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test_df[\"is_motif_in_train_data\"] = test_df.apply(lambda x: check(x, train_df), axis=1)\n",
    "    test_df.to_csv(\n",
    "        test_path, \n",
    "        index=False\n",
    "    )\n",
    "    validation_df[\"is_motif_in_train_data\"] = validation_df.apply(lambda x: check(x, train_df), axis=1)\n",
    "    validation_df.to_csv(\n",
    "        validation_path,\n",
    "        index=False\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequence-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14ae8cb2141f3f34f4e0523006ff2d6cb0f7956c0f094e5497e312072e4d0d3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
