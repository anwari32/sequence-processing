{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check if CUDA is supported.\n",
    "\"\"\"\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.device('cuda:0')\n",
    "torch.cuda.get_device_name(0)\n",
    "_device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_preparation import kmer\n",
    "\n",
    "def get_sequences(csv_path, n_sample=10, random_state=1337):\n",
    "    r\"\"\"\n",
    "    Get sequence from certain CSV. CSV has header such as 'sequence', 'label_prom', 'label_ss', 'label_polya'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if (n_sample > 0):\n",
    "        df = df.sample(n=n_sample, random_state=random_state)\n",
    "    sequence = list(df['sequence'])\n",
    "    label_prom = list(df['label_prom'])\n",
    "    label_ss = list(df['label_ss'])\n",
    "    label_polya = list(df['label_polya'])\n",
    "\n",
    "    return sequence, label_prom, label_ss, label_polya\n",
    "\n",
    "import torch\n",
    "def preprocessing(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Preprocessing for pretrained BERT.\n",
    "    @param  data (string): string containing kmers separated by spaces.\n",
    "    @param  tokenizer (Tokenizer): tokenizer initialized from pretrained values.\n",
    "    @return input_ids (torch.Tensor): tensor of token ids to be fed to model.\n",
    "    @return attention_masks (torch.Tensor): tensor of indices (a bunch of 'indexes') specifiying which token needs to be attended by model.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    _count = 0\n",
    "    _len_data = len(data)\n",
    "    for sequence in data:\n",
    "        \"\"\"\n",
    "        Sequence is 512 characters long.\n",
    "        \"\"\"\n",
    "        _count += 1\n",
    "        if _count < _len_data:\n",
    "            print(\"Seq length = {} [{}/{}]\".format(len(sequence.split(' ')), _count, _len_data), end='\\r')\n",
    "        else:\n",
    "            print(\"Seq length = {} [{}/{}]\".format(len(sequence.split(' ')), _count, _len_data))\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sequence,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert input_ids and attention_masks to tensor.\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\"\"\"\n",
    "Initialize tokenizer using BertTokenizer with pretrained weights from DNABert.\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./pretrained/3-new-12w-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and storing split to ./workspace/train.csv\n",
      "Splitting and storing split to ./workspace/validation.csv\n",
      "Splitting source ./dataset/full/train.csv: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split dataset into two parts: train and validation.\n",
    "\"\"\"\n",
    "from data_dir import workspace_dir, dataset_full_dir\n",
    "from data_preparation import split_and_store_csv\n",
    "_src_csv = \"{}/train.csv\".format(dataset_full_dir)\n",
    "_fractions = [0.9, 0.1]\n",
    "_store_paths = [\n",
    "    \"{}/{}\".format(workspace_dir, 'train.csv'),\n",
    "    \"{}/{}\".format(workspace_dir, 'validation.csv'),\n",
    "]\n",
    "print(\"Splitting source {}: {}\".format(_src_csv, split_and_store_csv(_src_csv, fractions=_fractions, store_paths=_store_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq length = 510 [500000/500000]\n",
      "Seq length = 510 [100/100]\n",
      "# of training data: 500000\n",
      "# of training data: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from data_dir import workspace_dir\n",
    "\n",
    "train_seq, train_label_prom, train_label_ss, train_label_polya = get_sequences('{}/train.csv'.format(workspace_dir), n_sample=500000)\n",
    "validation_seq, val_label_prom, val_label_ss, val_label_polya = get_sequences('{}/validation.csv'.format(workspace_dir), n_sample=100)\n",
    "\n",
    "\"\"\"\n",
    "Create dataloader.\n",
    "\"\"\"\n",
    "BATCH_SIZE = 2\n",
    "EPOCH_SIZE = 4\n",
    "\n",
    "_device = torch.device('cuda:0')\n",
    "train_label_prom = torch.tensor(train_label_prom, device=_device)\n",
    "train_label_ss = torch.tensor(train_label_ss, device=_device)\n",
    "train_label_polya = torch.tensor(train_label_polya, device=_device)\n",
    "\n",
    "train_inputs_ids, train_masks = preprocessing(train_seq, tokenizer)\n",
    "train_data = TensorDataset(train_inputs_ids, train_masks, train_label_prom, train_label_ss, train_label_polya)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_label_prom = torch.tensor(val_label_prom, device=_device)\n",
    "val_label_ss = torch.tensor(val_label_ss, device=_device)\n",
    "val_label_polya = torch.tensor(val_label_polya, device=_device)\n",
    "\n",
    "val_input_ids, val_masks = preprocessing(validation_seq, tokenizer)\n",
    "val_data = TensorDataset(val_input_ids, val_masks, val_label_prom, val_label_ss, val_label_polya)\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "print('# of training data: {}'.format(len(train_seq)))  \n",
    "print('# of training data: {}'.format(len(validation_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "\n",
    "from multitask_learning import PolyAHead, PromoterHead, SpliceSiteHead, MTModel\n",
    "from transformers import BertForMaskedLM\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "\n",
    "polya_head = PolyAHead()\n",
    "promoter_head = PromoterHead()\n",
    "splice_head = SpliceSiteHead()\n",
    "\n",
    "dnabert_3_pretrained = pretrained_3kmer_dir\n",
    "shared_parameter = BertForMaskedLM.from_pretrained(dnabert_3_pretrained).bert\n",
    "\n",
    "model = MTModel(shared_parameters=shared_parameter, promoter_head=promoter_head, polya_head=polya_head, splice_site_head=splice_head)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "from data_preparation import kmer\n",
    "\n",
    "_now = datetime.datetime.now()\n",
    "\n",
    "_log_file = os.path.join('logs', 'notebooks', '2022-02.24.csv')\n",
    "os.makedirs(_log_file, exist_ok=True)\n",
    "\n",
    "seqs = [\"ATGC\" * 128, \"GATC\" * 128, \"CCAT\" * 128]\n",
    "seqs = [' '.join(kmer(s, 3)) for s in seqs]\n",
    "prom_labels = [1, 0, 0]\n",
    "ss_labels = [0, 1, 0]\n",
    "polya_labels = [0, 0, 1]\n",
    "\n",
    "def _format_prom_label(label):\n",
    "    return [label]\n",
    "\n",
    "def _format_other_label(label):\n",
    "    return label\n",
    "\n",
    "\"\"\"\n",
    "Initialize BERT tokenizer.\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_3kmer_dir)\n",
    "\n",
    "arr_input_ids = []\n",
    "arr_attention_mask = []\n",
    "arr_prom_label = []\n",
    "arr_ss_label = []\n",
    "arr_polya_label = []\n",
    "for i in range(len(seqs)):\n",
    "    s = seqs[i]\n",
    "    prom = prom_labels[i]\n",
    "    ss = ss_labels[i]\n",
    "    polya = polya_labels[i]\n",
    "\n",
    "    encoded = tokenizer.encode_plus(text=s, padding=\"max_length\", return_attention_mask=True)\n",
    "    arr_input_ids.append(encoded.get('input_ids'))\n",
    "    arr_attention_mask.append(encoded.get('attention_mask'))\n",
    "    arr_prom_label.append(_format_prom_label(prom))\n",
    "    arr_ss_label.append(_format_other_label(ss))\n",
    "    arr_polya_label.append(_format_other_label(polya))\n",
    "#endfor\n",
    "arr_input_ids = torch.tensor(arr_input_ids)\n",
    "arr_attention_mask = torch.tensor(arr_attention_mask)\n",
    "prom_labels = torch.tensor(arr_prom_label)\n",
    "ss_labels = torch.tensor(arr_ss_label)\n",
    "polya_labels = torch.tensor(arr_polya_label)\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(arr_input_ids, arr_attention_mask, prom_labels, ss_labels, polya_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 512, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mw:\\Research\\sequence-processing\\multitask_learning.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/multitask_learning.ipynb#ch0000007?line=15'>16</a>\u001b[0m pred_ss \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/multitask_learning.ipynb#ch0000007?line=16'>17</a>\u001b[0m pred_polya \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mpolya\u001b[39m\u001b[39m'\u001b[39m]    \n\u001b[1;32m---> <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/multitask_learning.ipynb#ch0000007?line=17'>18</a>\u001b[0m loss_prom \u001b[39m=\u001b[39m binary_crossentropy_function(pred_prom, label_prom\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/multitask_learning.ipynb#ch0000007?line=18'>19</a>\u001b[0m loss_ss \u001b[39m=\u001b[39m crossentropy_function(pred_ss, label_ss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/multitask_learning.ipynb#ch0000007?line=19'>20</a>\u001b[0m loss_polya \u001b[39m=\u001b[39m crossentropy_function(pred_polya, label_polya)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:603\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=601'>602</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=602'>603</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\functional.py:2906\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2903'>2904</a>\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2904'>2905</a>\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[1;32m-> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2905'>2906</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2906'>2907</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2907'>2908</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2908'>2909</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2910'>2911</a>\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2911'>2912</a>\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 512, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss, BCELoss\n",
    "\n",
    "crossentropy_function = CrossEntropyLoss()\n",
    "binary_crossentropy_function = BCELoss()\n",
    "model.zero_grad()\n",
    "count_prom_correct = 0\n",
    "count_ss_correct = 0\n",
    "count_polya_correct = 0\n",
    "for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    in_ids, attn_mask, label_prom, label_ss, label_polya = tuple(t for t in batch)\n",
    "    output = model(in_ids, attn_mask)\n",
    "    pred_prom = output['prom']\n",
    "    pred_ss = output['ss']\n",
    "    pred_polya = output['polya']    \n",
    "    loss_prom = binary_crossentropy_function(pred_prom, label_prom.float())\n",
    "    loss_ss = crossentropy_function(pred_ss, label_ss)\n",
    "    loss_polya = crossentropy_function(pred_polya, label_polya)\n",
    "    #print(pred_prom, label_prom, loss_prom)\n",
    "    #print(pred_ss, label_ss, loss_ss)\n",
    "    #print(pred_polya, label_polya, loss_polya)\n",
    "    sum_loss = loss_prom + loss_ss + loss_polya\n",
    "    \n",
    "    predicted_prom = torch.round(pred_prom).item()\n",
    "    actual_prom = label_prom.float().item()\n",
    "    if (predicted_prom == actual_prom):\n",
    "        count_prom_correct += 1\n",
    "    print(pred_prom, label_prom, predicted_prom)\n",
    "\n",
    "    predicted_ss, predicted_ss_index = torch.max(pred_ss, 1)\n",
    "    predicted_ss = predicted_ss.item()\n",
    "    predicted_ss_index = predicted_ss_index.item()\n",
    "    # print(pred_ss, label_ss, predicted_ss, predicted_ss_index)\n",
    "    if (predicted_ss_index == label_ss):\n",
    "        count_ss_correct += 1\n",
    "    #print(sum_loss, sum_loss/3)\n",
    "\n",
    "    predicted_polya, predicted_polya_index = torch.max(pred_polya, 1)\n",
    "    predicted_polya = predicted_polya.item()\n",
    "    predicted_polya_index = predicted_polya_index.item()\n",
    "    if (predicted_polya_index == label_polya):\n",
    "        count_polya_correct += 1\n",
    "\n",
    "print('accuracy prom: {}'.format(count_prom_correct / len(dataloader) * 100))\n",
    "print('accuracy ss: {}'.format(count_ss_correct / len(dataloader) * 100))\n",
    "print('accuracy polya: {}'.format(count_polya_correct / len(dataloader) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2780, 0.3072, 0.4147], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [3], target: [1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11760/260450222.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch (got input: [3], target: [1])"
     ]
    }
   ],
   "source": [
    "from torch import tensor, nn\n",
    "\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "activation_fn = nn.Softmax(dim=0)\n",
    "\n",
    "pred = tensor([0.1, 0.2, 0.5], dtype=float)\n",
    "pred = activation_fn(pred)\n",
    "print(pred)\n",
    "target = tensor([0])\n",
    "loss = loss_fn(pred, target)\n",
    "loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2231)\n",
      "tensor(1.6204)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCELoss, CrossEntropyLoss\n",
    "from torch import tensor\n",
    "prom_pred = tensor([[0.2]])\n",
    "prom_target = tensor([[0.]])\n",
    "other_pred = tensor([[0.1, 1.5]])\n",
    "other_target = tensor([0])\n",
    "bce = BCELoss()\n",
    "cross = CrossEntropyLoss()\n",
    "print(bce(prom_pred, prom_target))\n",
    "print(cross(other_pred, other_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "from data_preparation import kmer\n",
    "from transformers import BertTokenizer\n",
    "from torch \n",
    "from data_dir import pretrained_3kmer_dir\n",
    "\n",
    "_now = datetime.datetime.now()\n",
    "\n",
    "_log_file = os.path.join('logs', 'notebooks', '2022-02.24.csv')\n",
    "os.makedirs(_log_file, exist_ok=True)\n",
    "\n",
    "seqs = [\"ATGC\" * 128, \"GATC\" * 128, \"CCAT\" * 128]\n",
    "seqs = [' '.join(kmer(s, 3)) for s in seqs]\n",
    "prom_labels = [1, 0, 0]\n",
    "ss_labels = [0, 1, 0]\n",
    "polya_labels = [0, 0, 1]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_3kmer_dir)\n",
    "encoded = tokenizer(seqs[0], seqs[1])\n",
    "print(encoded)\n",
    "print(tokenizer.convert_ids_to_tokens(encoded['input_ids']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multitask_learning import init_model_mtl\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "\n",
    "model = init_model_mtl(pretrained_3kmer_dir)\n",
    "preds = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage 0.1\n",
      "percentile 0.2\n"
     ]
    }
   ],
   "source": [
    "tuples = ('0.1', 0.2)\n",
    "titles = ['percentage', 'percentile']\n",
    "\n",
    "for a, b in zip(titles, tuples):\n",
    "    print(a, b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7170ee380771f2003055f3cee3e2e4dd0d81d1dac73a8c82197236b1572f37c2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
