{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create k-mer from sequence.\n",
    "@param  sequence: a string.\n",
    "@param  size_k: size of k in k-mer.\n",
    "\"\"\"\n",
    "def create_kmer(sequence, size_k):\n",
    "    \"\"\"\n",
    "    Remove 'N' if found in sequence and leave only A, T, G, and C in sequence.\n",
    "    \"\"\"\n",
    "    kmers = ''.join([s if s not in ['N', 'n'] else '' for s in sequence])\n",
    "    kmers = [kmers[i:i+size_k] for i in range(len(kmers)+1-size_k)]\n",
    "    return ' '.join([k for k in kmers])\n",
    "\n",
    "import pandas as pd\n",
    "from data_preparation import kmer\n",
    "\n",
    "def get_sequences(csv_path, n_sample=10, random_state=1337):\n",
    "    r\"\"\"\n",
    "    Get sequence from certain CSV. CSV has header such as 'sequence', 'label_prom', 'label_ss', 'label_polya' XXX.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if (n_sample > 0):\n",
    "        df = df.sample(n=n_sample, random_state=random_state)\n",
    "    sequence = list(df['sequence'])\n",
    "    label_prom = list(df['label_prom'])\n",
    "    label_ss = list(df['label_ss'])\n",
    "    label_polya = list(df['label_polya'])\n",
    "\n",
    "    return sequence, label_prom, label_ss, label_polya\n",
    "\n",
    "import torch\n",
    "def preprocessing(data, tokenizer, size_k=3, max_length=512):\n",
    "    \"\"\"\n",
    "    Preprocessing for pretrained BERT.\n",
    "    @param  data (np.array): array of texts to be processed.\n",
    "    @param  tokenizer (Tokenizer): tokenizer initialized from pretrained values.\n",
    "    @return input_ids (torch.Tensor): tensor of token ids to be fed to model.\n",
    "    @return attention_masks (torch.Tensor): tensor of indices (a bunch of 'indexes') specifiying which token needs to be attended by model.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sequence in data:\n",
    "        if len(sequence) > max_length:\n",
    "            sequence = sequence[0:512]\n",
    "        t = kmer(sequence, size_k=size_k)\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=t,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert input_ids and attention_masks to tensor.\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\"\"\"\n",
    "Initialize tokenizer using BertTokenizer with pretrained weights from DNABert.\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./pretrained/3-new-12w-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data: 640\n",
      "# of validation data: 80\n",
      "# of testing data: 80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "sequences, label_prom, label_ss, label_polya = get_sequences('./sample/training_sample.csv', n_sample=-1)\n",
    "val_seq, val_label_prom, val_label_ss, val_label_polya = get_sequences('./sample/testing_sample.csv', n_sample=-1)\n",
    "\n",
    "test_seq, test_label_prom, test_label_ss, test_label_polya = get_sequences('./sample/testing_sample.csv', n_sample=-1)\n",
    "\n",
    "\"\"\"\n",
    "Create dataloader.\n",
    "\"\"\"\n",
    "BATCH_SIZE = 1\n",
    "EPOCH_SIZE = 4\n",
    "\n",
    "train_label_prom = torch.tensor(label_prom)\n",
    "train_label_ss = torch.tensor(label_ss)\n",
    "train_label_polya = torch.tensor(label_polya)\n",
    "\n",
    "val_label_prom = torch.tensor(val_label_prom)\n",
    "val_label_ss = torch.tensor(val_label_ss)\n",
    "val_label_polya = torch.tensor(val_label_polya)\n",
    "\n",
    "test_label_prom = torch.tensor(test_label_prom)\n",
    "test_label_ss = torch.tensor(test_label_ss)\n",
    "test_label_polya = torch.tensor(test_label_polya)\n",
    "\n",
    "train_inputs_ids, train_masks = preprocessing(sequences, tokenizer)\n",
    "train_data = TensorDataset(train_inputs_ids, train_masks, train_label_prom, train_label_ss, train_label_polya)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_input_ids, val_masks = preprocessing(val_seq, tokenizer)\n",
    "val_data = TensorDataset(val_input_ids, val_masks, val_label_prom, val_label_ss, val_label_polya)\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_input_ids, test_masks = preprocessing(test_seq, tokenizer)\n",
    "test_data = TensorDataset(test_input_ids, test_masks, test_label_prom, test_label_ss, test_label_polya)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "print('# of training data: {}'.format(len(sequences)))\n",
    "print(('# of validation data: {}'.format(len(val_seq))))\n",
    "print(('# of testing data: {}'.format(len(test_seq))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "\n",
    "model.to(_device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "training_steps = len(train_dataloader) * EPOCH_SIZE\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=training_steps)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "def evaluate(model, dataloader, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    val_prom_acc = []\n",
    "    val_prom_loss = []\n",
    "    val_ss_acc = []\n",
    "    val_ss_loss = []\n",
    "    val_polya_acc = []\n",
    "    val_polya_loss = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids, b_attn_masks, b_label_prom, b_label_ss, b_label_polya = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits.\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_masks)\n",
    "\n",
    "            prom_logits = logits['prom']\n",
    "            ss_logits = logits['ss']\n",
    "            polya_logits = logits['polya']\n",
    "\n",
    "            # Compute loss.\n",
    "            prom_loss = loss_fn(prom_logits, b_label_prom)\n",
    "            ss_loss = loss_fn(ss_logits, b_label_ss)\n",
    "            polya_loss = loss_fn(polya_logits, b_label_polya)\n",
    "            val_prom_loss.append(prom_loss)\n",
    "            val_ss_loss.append(ss_loss)\n",
    "            val_polya_loss.append(polya_loss)\n",
    "\n",
    "            # Prediction.\n",
    "            preds_prom = torch.argmax(prom_logits, dim=1).flatten()\n",
    "            preds_ss = torch.argmax(ss_logits, dim=1).flatten()\n",
    "            preds_polya = torch.argmax(polya_logits, dim=1).flatten()\n",
    "\n",
    "            # Accuracy\n",
    "            prom_acc = (preds_prom == b_label_prom).cpu().numpy().mean() * 100\n",
    "            ss_acc = (preds_ss == b_label_ss).cpu().numpy().mean() * 100\n",
    "            polya_acc = (preds_polya == b_label_polya).cpu().numpy().mean() * 100\n",
    "            val_prom_acc.append(prom_acc)\n",
    "            val_ss_acc.append(ss_acc)\n",
    "            val_polya_acc.append(polya_acc)\n",
    "\n",
    "    # Compute average acc and loss.\n",
    "    avg_prom_acc = np.mean(val_prom_acc)\n",
    "    avg_ss_acc = np.mean(val_ss_acc)\n",
    "    avg_polya_acc = np.mean(val_polya_acc)\n",
    "    avg_prom_loss = np.mean(val_prom_loss)\n",
    "    avg_ss_loss = np.mean(val_ss_loss)\n",
    "    avg_polya_loss = np.mean(val_polya_loss)\n",
    "\n",
    "    return avg_prom_acc, avg_ss_acc, avg_polya_acc, avg_prom_loss, avg_ss_loss, avg_polya_loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, scheduler, batch_size, epoch_size, device='cpu', eval=False, val_dataloader=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    batch_counts = 0\n",
    "    batch_loss = 0\n",
    "    batch_loss_prom, batch_loss_ss, batch_loss_polya = 0, 0, 0\n",
    "    total_loss = 0\n",
    "    total_loss_prom, total_loss_ss, total_loss_polya = 0, 0, 0\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            batch_counts += 1\n",
    "            batch_loss \n",
    "\n",
    "            # Load batch to device.\n",
    "            b_input_ids, b_attn_masks, b_labels_prom, b_labels_ss, b_labels_polya = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients.\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Perform forward pass.\n",
    "            outputs = model(b_input_ids, b_attn_masks)\n",
    "\n",
    "            # Compute error.\n",
    "            loss_prom = loss_fn(outputs['prom'], b_labels_prom)\n",
    "            loss_ss = loss_fn(outputs['ss'], b_labels_ss)\n",
    "            loss_polya = loss_fn(outputs['polya'], b_labels_polya)\n",
    "\n",
    "            # Following MTDNN (Liu et. al., 2019), loss is summed.\n",
    "            loss = loss_prom + loss_ss + loss_polya\n",
    "\n",
    "            # Compute this batch error.\n",
    "            batch_loss_prom += loss_prom\n",
    "            batch_loss_ss += loss_ss\n",
    "            batch_loss_polya += loss_polya\n",
    "            batch_loss += loss\n",
    "\n",
    "            # Backpropagation.\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters and learning rate.\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print training process.\n",
    "            if (step % batch_size == 0 and step != 0) or (step == len(dataloader) - 1):\n",
    "                print('batch loss {}, batch loss prom: {}, batch loss ss: {}, batch loss polya: {}'.format(batch_loss, batch_loss_prom, batch_loss_ss, batch_loss_polya))\n",
    "                batch_loss = 0\n",
    "                batch_loss_prom = 0\n",
    "                batch_loss_ss = 0\n",
    "                batch_loss_polya = 0\n",
    "                batch_counts = 0\n",
    "        # endfor batch.\n",
    "\n",
    "        # Evaluate.\n",
    "        if eval:\n",
    "            pa, ssa, pola, pl, ssl, poll = evaluate(model, val_dataloader)\n",
    "            print('-----')\n",
    "            print('prom acc: {}, prom loss: {}'.format(pa, pl))\n",
    "            print('ss acc: {}, ss loss: {}'.format(ssa, ssl))\n",
    "            print('polya acc: {}, polya loss: {}'.format(pola, poll))\n",
    "            print('-----')\n",
    "    # endfor epoch.\n",
    "        \n",
    "def test(dataloader, model, loss_fn, optimizer, batch_size, device=\"cpu\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # Set model on evaluation model.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            test_loss /= num_batches\n",
    "            correct /= size\n",
    "            print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}% \\n Avg Loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.0923478826880455, batch loss prom: 0.015425542369484901, batch loss ss: 0.06967712938785553, batch loss polya: 0.007245213259011507\n",
      "batch loss 0.032309390604496, batch loss prom: 0.010534040629863739, batch loss ss: 0.021281111985445023, batch loss polya: 0.0004942387458868325\n",
      "batch loss 0.01371399313211441, batch loss prom: 0.004375289659947157, batch loss ss: 0.0032876271288841963, batch loss polya: 0.006051077041774988\n",
      "batch loss 0.022069502621889114, batch loss prom: 0.01163435634225607, batch loss ss: 0.004250302445143461, batch loss polya: 0.006184843368828297\n",
      "batch loss 0.711395263671875, batch loss prom: 0.005767726805061102, batch loss ss: 0.704287588596344, batch loss polya: 0.0013399679446592927\n",
      "batch loss 4.128385543823242, batch loss prom: 0.8188514709472656, batch loss ss: 3.3033692836761475, batch loss polya: 0.006164702586829662\n",
      "batch loss 1.7927719354629517, batch loss prom: 1.65945303440094, batch loss ss: 0.13291916251182556, batch loss polya: 0.0003997480380348861\n",
      "batch loss 0.3559124767780304, batch loss prom: 0.33243095874786377, batch loss ss: 0.018440591171383858, batch loss polya: 0.005040912423282862\n",
      "batch loss 3.5998775959014893, batch loss prom: 0.00615190714597702, batch loss ss: 3.5933620929718018, batch loss polya: 0.00036352223833091557\n",
      "batch loss 0.01254630833864212, batch loss prom: 0.0012837749673053622, batch loss ss: 0.000719645875506103, batch loss polya: 0.010542887263000011\n",
      "batch loss 0.19419005513191223, batch loss prom: 0.029341859742999077, batch loss ss: 0.16352465748786926, batch loss polya: 0.0013235389487817883\n",
      "batch loss 0.01711052656173706, batch loss prom: 0.0025738703552633524, batch loss ss: 0.0007008241955190897, batch loss polya: 0.013835831545293331\n",
      "batch loss 0.05088849738240242, batch loss prom: 0.003168208058923483, batch loss ss: 0.045486658811569214, batch loss polya: 0.002233631443232298\n",
      "batch loss 0.10692545026540756, batch loss prom: 0.03718896210193634, batch loss ss: 0.06715845316648483, batch loss polya: 0.0025780319701880217\n",
      "batch loss 0.09424792975187302, batch loss prom: 0.002737942850217223, batch loss ss: 0.09003157913684845, batch loss polya: 0.0014784131199121475\n",
      "batch loss 0.012649443000555038, batch loss prom: 0.0013275867095217109, batch loss ss: 0.0008896207436919212, batch loss polya: 0.010432235896587372\n",
      "batch loss 0.013972222805023193, batch loss prom: 0.0035479236394166946, batch loss ss: 0.009335319511592388, batch loss polya: 0.0010889797704294324\n",
      "batch loss 0.09160282462835312, batch loss prom: 0.0023252135142683983, batch loss ss: 0.06687751412391663, batch loss polya: 0.02240009792149067\n",
      "batch loss 0.12455872446298599, batch loss prom: 0.011036188341677189, batch loss ss: 0.11148030310869217, batch loss polya: 0.002042233245447278\n",
      "batch loss 1.4006099700927734, batch loss prom: 0.1590929925441742, batch loss ss: 1.2405645847320557, batch loss polya: 0.000952386180870235\n",
      "batch loss 0.01490778662264347, batch loss prom: 0.003147293347865343, batch loss ss: 0.010462908074259758, batch loss polya: 0.0012975853169336915\n",
      "batch loss 2.2562689781188965, batch loss prom: 0.06707507371902466, batch loss ss: 2.188000440597534, batch loss polya: 0.001193526084534824\n",
      "batch loss 0.07877305150032043, batch loss prom: 0.014569912105798721, batch loss ss: 0.06389240175485611, batch loss polya: 0.000310730334604159\n",
      "batch loss 2.614872694015503, batch loss prom: 0.1304560899734497, batch loss ss: 2.482557535171509, batch loss polya: 0.0018588898237794638\n",
      "batch loss 0.01877850666642189, batch loss prom: 0.0038536349311470985, batch loss ss: 0.0020477056968957186, batch loss polya: 0.012877166271209717\n",
      "batch loss 0.9593763947486877, batch loss prom: 0.7874200344085693, batch loss ss: 0.17122124135494232, batch loss polya: 0.0007351318490691483\n",
      "batch loss 0.5245556831359863, batch loss prom: 0.43947699666023254, batch loss ss: 0.07811497896909714, batch loss polya: 0.006963745225220919\n",
      "batch loss 0.011144251562654972, batch loss prom: 0.0010827876394614577, batch loss ss: 0.0010938619961962104, batch loss polya: 0.00896760169416666\n",
      "batch loss 0.3412054479122162, batch loss prom: 0.011166106909513474, batch loss ss: 0.32948946952819824, batch loss polya: 0.0005498804384842515\n",
      "batch loss 0.29944783449172974, batch loss prom: 0.25181618332862854, batch loss ss: 0.04403418302536011, batch loss polya: 0.00359745672903955\n",
      "batch loss 0.26135656237602234, batch loss prom: 0.10702290385961533, batch loss ss: 0.1537843644618988, batch loss polya: 0.0005492847412824631\n",
      "batch loss 0.6331547498703003, batch loss prom: 0.16249506175518036, batch loss ss: 0.4704222083091736, batch loss polya: 0.0002374367177253589\n",
      "batch loss 0.6839077472686768, batch loss prom: 0.5086265802383423, batch loss ss: 0.17508719861507416, batch loss polya: 0.00019393471302464604\n",
      "batch loss 0.012190894223749638, batch loss prom: 0.002024388173595071, batch loss ss: 0.0007401349139399827, batch loss polya: 0.009426371194422245\n",
      "batch loss 0.011321939527988434, batch loss prom: 0.0014291321858763695, batch loss ss: 0.0007773000397719443, batch loss polya: 0.009115507826209068\n",
      "batch loss 1.5357666015625, batch loss prom: 1.5037922859191895, batch loss ss: 0.029739655554294586, batch loss polya: 0.0022347019985318184\n",
      "batch loss 0.15196534991264343, batch loss prom: 0.026846619322896004, batch loss ss: 0.12411442399024963, batch loss polya: 0.0010043105576187372\n",
      "batch loss 0.011630463413894176, batch loss prom: 0.004998093470931053, batch loss ss: 0.005948103964328766, batch loss polya: 0.0006842655711807311\n",
      "batch loss 1.9963257312774658, batch loss prom: 1.8138715028762817, batch loss ss: 0.18209806084632874, batch loss polya: 0.000356253091013059\n",
      "batch loss 0.01359619665890932, batch loss prom: 0.001835091970860958, batch loss ss: 0.0011849532602354884, batch loss polya: 0.010576151311397552\n",
      "batch loss 0.2694016098976135, batch loss prom: 0.2458900809288025, batch loss ss: 0.019440123811364174, batch loss polya: 0.004071400035172701\n",
      "batch loss 0.21949517726898193, batch loss prom: 0.04358759894967079, batch loss ss: 0.1744159609079361, batch loss polya: 0.0014916256768628955\n",
      "batch loss 0.3387744128704071, batch loss prom: 0.04241644963622093, batch loss ss: 0.2960421144962311, batch loss polya: 0.00031585473334416747\n",
      "batch loss 0.012233223766088486, batch loss prom: 0.0016351675149053335, batch loss ss: 0.001281870063394308, batch loss polya: 0.009316186420619488\n",
      "batch loss 1.9451282024383545, batch loss prom: 0.09691379964351654, batch loss ss: 1.8480466604232788, batch loss polya: 0.0001677133986959234\n",
      "batch loss 0.032110363245010376, batch loss prom: 0.02114211395382881, batch loss ss: 0.01060174684971571, batch loss polya: 0.0003665013937279582\n",
      "batch loss 0.06654263287782669, batch loss prom: 0.045202188193798065, batch loss ss: 0.02080521732568741, batch loss polya: 0.0005352256703190506\n",
      "batch loss 4.034709930419922, batch loss prom: 1.1862584352493286, batch loss ss: 2.8472237586975098, batch loss polya: 0.0012280549854040146\n",
      "batch loss 0.18448662757873535, batch loss prom: 0.07267328351736069, batch loss ss: 0.11169663816690445, batch loss polya: 0.00011669908417388797\n",
      "batch loss 0.008837942034006119, batch loss prom: 0.0015437601832672954, batch loss ss: 0.0011086276499554515, batch loss polya: 0.006185554433614016\n",
      "batch loss 0.5022276639938354, batch loss prom: 0.15463221073150635, batch loss ss: 0.3468749523162842, batch loss polya: 0.0007204797584563494\n",
      "batch loss 0.37464597821235657, batch loss prom: 0.10767306387424469, batch loss ss: 0.26675158739089966, batch loss polya: 0.0002213471452705562\n",
      "batch loss 0.007811305113136768, batch loss prom: 0.0012019798159599304, batch loss ss: 0.0009604846709407866, batch loss polya: 0.005648840684443712\n",
      "batch loss 0.006993689574301243, batch loss prom: 0.001409014337696135, batch loss ss: 0.000971917703282088, batch loss polya: 0.004612757824361324\n",
      "batch loss 0.41172271966934204, batch loss prom: 0.12811173498630524, batch loss ss: 0.2834390699863434, batch loss polya: 0.00017188502533826977\n",
      "batch loss 1.3631809949874878, batch loss prom: 0.91754549741745, batch loss ss: 0.4443577527999878, batch loss polya: 0.001277822069823742\n",
      "batch loss 0.19425395131111145, batch loss prom: 0.030412551015615463, batch loss ss: 0.16342413425445557, batch loss polya: 0.0004172646440565586\n",
      "batch loss 0.635230541229248, batch loss prom: 0.19079889357089996, batch loss ss: 0.4440869688987732, batch loss polya: 0.0003446938644628972\n",
      "batch loss 0.1738383173942566, batch loss prom: 0.012404199689626694, batch loss ss: 0.16082870960235596, batch loss polya: 0.0006053998949937522\n",
      "batch loss 0.007090431172400713, batch loss prom: 0.0016509962733834982, batch loss ss: 0.0007508557755500078, batch loss polya: 0.004688579123467207\n",
      "batch loss 0.28399211168289185, batch loss prom: 0.003973922226577997, batch loss ss: 0.27951523661613464, batch loss polya: 0.0005029367166571319\n",
      "batch loss 0.012790124863386154, batch loss prom: 0.0071755084209144115, batch loss ss: 0.005068548489362001, batch loss polya: 0.0005460678366944194\n",
      "batch loss 0.48216596245765686, batch loss prom: 0.4254089593887329, batch loss ss: 0.055955883115530014, batch loss polya: 0.0008011230966076255\n",
      "batch loss 0.007198705337941647, batch loss prom: 0.0014578201808035374, batch loss ss: 0.0009576263837516308, batch loss polya: 0.004783258773386478\n",
      "batch loss 0.6796427965164185, batch loss prom: 0.12676475942134857, batch loss ss: 0.5526511669158936, batch loss polya: 0.00022682955022901297\n",
      "batch loss 0.15170088410377502, batch loss prom: 0.017666013911366463, batch loss ss: 0.13037541508674622, batch loss polya: 0.0036594585981220007\n",
      "batch loss 0.4496106207370758, batch loss prom: 0.02087024785578251, batch loss ss: 0.42753565311431885, batch loss polya: 0.0012047183699905872\n",
      "batch loss 0.005988217890262604, batch loss prom: 0.0012267453130334616, batch loss ss: 0.0008661571191623807, batch loss polya: 0.0038953155744820833\n",
      "batch loss 0.8140574097633362, batch loss prom: 0.5209708213806152, batch loss ss: 0.29280397295951843, batch loss polya: 0.0002826052950695157\n",
      "batch loss 0.7200394868850708, batch loss prom: 0.5538878440856934, batch loss ss: 0.16352415084838867, batch loss polya: 0.0026274940464645624\n",
      "batch loss 0.2694978713989258, batch loss prom: 0.15110504627227783, batch loss ss: 0.11680515110492706, batch loss polya: 0.001587679609656334\n",
      "batch loss 0.006854137405753136, batch loss prom: 0.0010879080509766936, batch loss ss: 0.0007420408655889332, batch loss polya: 0.0050241886638104916\n",
      "batch loss 0.4535376727581024, batch loss prom: 0.42817312479019165, batch loss ss: 0.0241934135556221, batch loss polya: 0.0011711412807926536\n",
      "batch loss 0.005914865992963314, batch loss prom: 0.0009884715545922518, batch loss ss: 0.0012455570977181196, batch loss polya: 0.0036808375734835863\n",
      "batch loss 0.4629790782928467, batch loss prom: 0.10313550382852554, batch loss ss: 0.3584783673286438, batch loss polya: 0.0013652060879394412\n",
      "batch loss 0.013885082677006721, batch loss prom: 0.007079397793859243, batch loss ss: 0.0036548261996358633, batch loss polya: 0.003150858450680971\n",
      "batch loss 1.1745474338531494, batch loss prom: 1.1459803581237793, batch loss ss: 0.028332481160759926, batch loss polya: 0.00023457636416424066\n",
      "batch loss 0.1236102283000946, batch loss prom: 0.008908054791390896, batch loss ss: 0.1136997640132904, batch loss polya: 0.0010024051880463958\n",
      "batch loss 0.7140775322914124, batch loss prom: 0.07060128450393677, batch loss ss: 0.6430887579917908, batch loss polya: 0.00038747431244701147\n",
      "batch loss 0.14967240393161774, batch loss prom: 0.02294607274234295, batch loss ss: 0.12561626732349396, batch loss polya: 0.0011100566480308771\n",
      "batch loss 0.006648958660662174, batch loss prom: 0.0014153235824778676, batch loss ss: 0.0008054111385717988, batch loss polya: 0.004428223706781864\n",
      "batch loss 0.37246984243392944, batch loss prom: 0.3424215018749237, batch loss ss: 0.028809094801545143, batch loss polya: 0.0012392468051984906\n",
      "batch loss 0.09028676897287369, batch loss prom: 0.046518705785274506, batch loss ss: 0.041705965995788574, batch loss polya: 0.002062100451439619\n",
      "batch loss 0.024448983371257782, batch loss prom: 0.010862387716770172, batch loss ss: 0.01240938063710928, batch loss polya: 0.001177213853225112\n",
      "batch loss 0.08728712797164917, batch loss prom: 0.01233849860727787, batch loss ss: 0.07376403361558914, batch loss polya: 0.0011845960980281234\n",
      "batch loss 0.04305898770689964, batch loss prom: 0.018020713701844215, batch loss ss: 0.02339358627796173, batch loss polya: 0.0016446886584162712\n",
      "batch loss 0.11957205832004547, batch loss prom: 0.02305476740002632, batch loss ss: 0.09626244753599167, batch loss polya: 0.0002548369811847806\n",
      "batch loss 0.24924983084201813, batch loss prom: 0.020977182313799858, batch loss ss: 0.2279539257287979, batch loss polya: 0.00031871485407464206\n",
      "batch loss 0.4779066741466522, batch loss prom: 0.05508844926953316, batch loss ss: 0.42106083035469055, batch loss polya: 0.0017573880031704903\n",
      "batch loss 0.14989632368087769, batch loss prom: 0.023615753278136253, batch loss ss: 0.12600131332874298, batch loss polya: 0.00027926836628466845\n",
      "batch loss 0.005262764170765877, batch loss prom: 0.0009887097403407097, batch loss ss: 0.0007446615491062403, batch loss polya: 0.003529392648488283\n",
      "batch loss 0.0070960381999611855, batch loss prom: 0.0012825843878090382, batch loss ss: 0.0012436520773917437, batch loss polya: 0.004569801967591047\n",
      "batch loss 1.8785070180892944, batch loss prom: 1.822776436805725, batch loss ss: 0.05407899245619774, batch loss polya: 0.0016515913885086775\n",
      "batch loss 0.2191898673772812, batch loss prom: 0.18735374510288239, batch loss ss: 0.03143969923257828, batch loss polya: 0.00039641151670366526\n",
      "batch loss 0.2291012853384018, batch loss prom: 0.019076921045780182, batch loss ss: 0.20853358507156372, batch loss polya: 0.0014907924924045801\n",
      "batch loss 0.005498005077242851, batch loss prom: 0.0008530553313903511, batch loss ss: 0.0008983152220025659, batch loss polya: 0.003746634814888239\n",
      "batch loss 0.08226802200078964, batch loss prom: 0.011438856832683086, batch loss ss: 0.07037353515625, batch loss polya: 0.00045563330058939755\n",
      "batch loss 0.035663213580846786, batch loss prom: 0.009476794861257076, batch loss ss: 0.023548223078250885, batch loss polya: 0.0026381947100162506\n",
      "batch loss 0.06369708478450775, batch loss prom: 0.0548006035387516, batch loss ss: 0.008718520402908325, batch loss polya: 0.00017796363681554794\n",
      "batch loss 0.9296208620071411, batch loss prom: 0.15513864159584045, batch loss ss: 0.774391233921051, batch loss polya: 9.095255518332124e-05\n",
      "batch loss 0.13978779315948486, batch loss prom: 0.004422764293849468, batch loss ss: 0.13431188464164734, batch loss polya: 0.0010531361913308501\n",
      "batch loss 0.25655508041381836, batch loss prom: 0.23477795720100403, batch loss ss: 0.0214015394449234, batch loss polya: 0.00037555795279331505\n",
      "batch loss 0.009115306660532951, batch loss prom: 0.0036220441106706858, batch loss ss: 0.001135776867158711, batch loss polya: 0.00435748603194952\n",
      "batch loss 0.21292074024677277, batch loss prom: 0.009352562017738819, batch loss ss: 0.2025725543498993, batch loss polya: 0.0009956170106306672\n",
      "batch loss 0.16405628621578217, batch loss prom: 0.06009547412395477, batch loss ss: 0.1023733839392662, batch loss polya: 0.0015874415403231978\n",
      "batch loss 0.16464735567569733, batch loss prom: 0.0455532930791378, batch loss ss: 0.11858242750167847, batch loss polya: 0.0005116345710121095\n",
      "batch loss 2.52040696144104, batch loss prom: 0.016960926353931427, batch loss ss: 2.5033175945281982, batch loss polya: 0.0001284993631998077\n",
      "batch loss 4.14885950088501, batch loss prom: 0.07300855964422226, batch loss ss: 4.075750350952148, batch loss polya: 0.00010048838157672435\n",
      "batch loss 0.03420112282037735, batch loss prom: 0.004675527568906546, batch loss ss: 0.027768919244408607, batch loss polya: 0.0017566739115864038\n",
      "batch loss 0.05770568177103996, batch loss prom: 0.012277621775865555, batch loss ss: 0.0425422377884388, batch loss polya: 0.002885822905227542\n",
      "batch loss 0.27887627482414246, batch loss prom: 0.0304042249917984, batch loss ss: 0.24828192591667175, batch loss polya: 0.00019012074335478246\n",
      "batch loss 0.7140704393386841, batch loss prom: 0.005199481267482042, batch loss ss: 0.7084860801696777, batch loss polya: 0.00038485272671096027\n",
      "batch loss 0.09550759196281433, batch loss prom: 0.044045135378837585, batch loss ss: 0.051227644085884094, batch loss polya: 0.0002348147245356813\n",
      "batch loss 0.00570481875911355, batch loss prom: 0.0010489681735634804, batch loss ss: 0.0015265013789758086, batch loss polya: 0.0031293490901589394\n",
      "batch loss 0.09990178793668747, batch loss prom: 0.0033595096319913864, batch loss ss: 0.09612298756837845, batch loss polya: 0.00041929035796783864\n",
      "batch loss 0.0530473031103611, batch loss prom: 0.001794396317563951, batch loss ss: 0.04983055964112282, batch loss polya: 0.0014223469188436866\n",
      "batch loss 0.07212415337562561, batch loss prom: 0.017297714948654175, batch loss ss: 0.05384010821580887, batch loss polya: 0.0009863278828561306\n",
      "batch loss 4.968164443969727, batch loss prom: 3.161339282989502, batch loss ss: 1.8065191507339478, batch loss polya: 0.00030620177858509123\n",
      "batch loss 0.004955661948770285, batch loss prom: 0.0011256556026637554, batch loss ss: 0.0010845737997442484, batch loss polya: 0.002745432546362281\n",
      "batch loss 2.5864455699920654, batch loss prom: 0.0035415091551840305, batch loss ss: 2.581587314605713, batch loss polya: 0.0013168720761314034\n",
      "batch loss 1.6471738815307617, batch loss prom: 0.008888441137969494, batch loss ss: 1.6381754875183105, batch loss polya: 0.00010990492592100054\n",
      "batch loss 0.2214941829442978, batch loss prom: 0.0017498909728601575, batch loss ss: 0.21958516538143158, batch loss polya: 0.0001591317413840443\n",
      "batch loss 0.09143409132957458, batch loss prom: 0.0036061275750398636, batch loss ss: 0.08507492393255234, batch loss polya: 0.002753040986135602\n",
      "batch loss 0.005269075743854046, batch loss prom: 0.0012274596374481916, batch loss ss: 0.0007215518853627145, batch loss polya: 0.003320063930004835\n",
      "batch loss 0.6241517066955566, batch loss prom: 0.44072216749191284, batch loss ss: 0.18316493928432465, batch loss polya: 0.0002646096108946949\n",
      "batch loss 0.10280361026525497, batch loss prom: 0.01224005687981844, batch loss ss: 0.09029834717512131, batch loss polya: 0.00026520551182329655\n",
      "batch loss 0.004901317413896322, batch loss prom: 0.001190906623378396, batch loss ss: 0.0008839037618599832, batch loss polya: 0.002826506970450282\n",
      "batch loss 0.005058955866843462, batch loss prom: 0.0013888961402699351, batch loss ss: 0.000856747676152736, batch loss polya: 0.00281331199221313\n",
      "batch loss 0.005544077605009079, batch loss prom: 0.0016656348016113043, batch loss ss: 0.0008112476789392531, batch loss polya: 0.003067195415496826\n",
      "batch loss 0.841381311416626, batch loss prom: 0.033044714480638504, batch loss ss: 0.808224081993103, batch loss polya: 0.00011252723925281316\n",
      "batch loss 0.6009917259216309, batch loss prom: 0.38913771510124207, batch loss ss: 0.2117311954498291, batch loss polya: 0.0001227780303452164\n",
      "batch loss 0.0048204208724200726, batch loss prom: 0.0012472239322960377, batch loss ss: 0.0005887205479666591, batch loss polya: 0.0029844765085726976\n",
      "batch loss 0.7593531012535095, batch loss prom: 0.5326807498931885, batch loss ss: 0.22532042860984802, batch loss polya: 0.0013518728082999587\n",
      "batch loss 0.1445508748292923, batch loss prom: 0.008426232263445854, batch loss ss: 0.13606885075569153, batch loss polya: 5.578839045483619e-05\n",
      "batch loss 0.0062881517224013805, batch loss prom: 0.001544950413517654, batch loss ss: 0.0010846928926184773, batch loss polya: 0.0036585084162652493\n",
      "batch loss 1.220049500465393, batch loss prom: 0.0452268011868, batch loss ss: 1.17471182346344, batch loss polya: 0.00011085849109804258\n",
      "batch loss 0.3266583979129791, batch loss prom: 0.297639936208725, batch loss ss: 0.02767801471054554, batch loss polya: 0.0013404440833255649\n",
      "batch loss 0.3654923141002655, batch loss prom: 0.0033432324416935444, batch loss ss: 0.361177533864975, batch loss polya: 0.0009715604246594012\n",
      "batch loss 0.0049750241450965405, batch loss prom: 0.002135260496288538, batch loss ss: 0.00036113892565481365, batch loss polya: 0.0024786246940493584\n",
      "batch loss 0.019003085792064667, batch loss prom: 0.0019502682844176888, batch loss ss: 0.008497155271470547, batch loss polya: 0.00855566281825304\n",
      "batch loss 0.2822592854499817, batch loss prom: 0.026248309761285782, batch loss ss: 0.2556896507740021, batch loss polya: 0.000321336614433676\n",
      "batch loss 0.20570899546146393, batch loss prom: 0.19513148069381714, batch loss ss: 0.010114368051290512, batch loss polya: 0.0004631400224752724\n",
      "batch loss 0.11081580072641373, batch loss prom: 0.09305232018232346, batch loss ss: 0.017227062955498695, batch loss polya: 0.0005364171229302883\n",
      "batch loss 0.0038600442931056023, batch loss prom: 0.0011891205795109272, batch loss ss: 0.0005875291535630822, batch loss polya: 0.0020833946764469147\n",
      "batch loss 0.00864784698933363, batch loss prom: 0.002139780670404434, batch loss ss: 0.001320562674663961, batch loss polya: 0.005187503527849913\n",
      "batch loss 2.2587413787841797, batch loss prom: 0.09122980386018753, batch loss ss: 2.167417287826538, batch loss polya: 9.42901024245657e-05\n",
      "batch loss 1.4892369508743286, batch loss prom: 0.028885535895824432, batch loss ss: 1.460235834121704, batch loss polya: 0.00011562632425921038\n",
      "batch loss 1.5176196098327637, batch loss prom: 0.0028335205279290676, batch loss ss: 1.5143685340881348, batch loss polya: 0.00041762212640605867\n",
      "batch loss 0.0041853077709674835, batch loss prom: 0.0012663925299420953, batch loss ss: 0.0005806190893054008, batch loss polya: 0.0023382960353046656\n",
      "batch loss 0.00453790370374918, batch loss prom: 0.0011874537449330091, batch loss ss: 0.0005398723296821117, batch loss polya: 0.0028105778619647026\n",
      "batch loss 0.5168946385383606, batch loss prom: 0.0026830171700567007, batch loss ss: 0.5137739777565002, batch loss polya: 0.00043764073052443564\n",
      "batch loss 0.009960377588868141, batch loss prom: 0.0026594768278300762, batch loss ss: 0.00393497571349144, batch loss polya: 0.003365925280377269\n",
      "batch loss 0.004041935317218304, batch loss prom: 0.0009006972541101277, batch loss ss: 0.0007482351502403617, batch loss polya: 0.0023930028546601534\n",
      "batch loss 1.2715243101119995, batch loss prom: 0.0018328310688957572, batch loss ss: 1.2677351236343384, batch loss polya: 0.001956336200237274\n",
      "batch loss 0.004895766731351614, batch loss prom: 0.0012943708570674062, batch loss ss: 0.0009497660794295371, batch loss polya: 0.00265162973664701\n",
      "batch loss 0.28878411650657654, batch loss prom: 0.0112879928201437, batch loss ss: 0.2773517668247223, batch loss polya: 0.00014435203047469258\n",
      "batch loss 0.8071215748786926, batch loss prom: 0.7223443984985352, batch loss ss: 0.08442983776330948, batch loss polya: 0.00034731553751043975\n",
      "batch loss 0.24080178141593933, batch loss prom: 0.13453468680381775, batch loss ss: 0.10586448013782501, batch loss polya: 0.00040260792593471706\n",
      "batch loss 0.07330585271120071, batch loss prom: 0.008721711114048958, batch loss ss: 0.06454349309206009, batch loss polya: 4.0649541915627196e-05\n",
      "batch loss 0.49123039841651917, batch loss prom: 0.3328494429588318, batch loss ss: 0.15815509855747223, batch loss polya: 0.00022587609419133514\n",
      "batch loss 0.38598963618278503, batch loss prom: 0.3273140490055084, batch loss ss: 0.05792747437953949, batch loss polya: 0.0007481159991584718\n",
      "batch loss 0.25244736671447754, batch loss prom: 0.2238500714302063, batch loss ss: 0.026030559092760086, batch loss polya: 0.002566736191511154\n",
      "batch loss 1.7666720151901245, batch loss prom: 1.6661921739578247, batch loss ss: 0.10018328577280045, batch loss polya: 0.0002965487365145236\n",
      "batch loss 1.4717668294906616, batch loss prom: 0.0028770267963409424, batch loss ss: 1.4687237739562988, batch loss polya: 0.00016604475968051702\n",
      "batch loss 0.18390418589115143, batch loss prom: 0.04039706289768219, batch loss ss: 0.14327779412269592, batch loss polya: 0.00022933237778488547\n",
      "batch loss 0.10281407833099365, batch loss prom: 0.020745787769556046, batch loss ss: 0.08173075318336487, batch loss polya: 0.0003375437227077782\n",
      "batch loss 0.08569562435150146, batch loss prom: 0.016544997692108154, batch loss ss: 0.06859288364648819, batch loss polya: 0.0005577438860200346\n",
      "batch loss 0.004111993592232466, batch loss prom: 0.0008561521535739303, batch loss ss: 0.0013237770181149244, batch loss polya: 0.0019320646533742547\n",
      "batch loss 0.0963815376162529, batch loss prom: 0.015396312810480595, batch loss ss: 0.08073718100786209, batch loss polya: 0.000248043768806383\n",
      "batch loss 0.004043710418045521, batch loss prom: 0.0010085977846756577, batch loss ss: 0.0011243456974625587, batch loss polya: 0.001910767168737948\n",
      "batch loss 1.2978659868240356, batch loss prom: 0.0036599335726350546, batch loss ss: 1.2940335273742676, batch loss polya: 0.00017248096992261708\n",
      "batch loss 0.13022994995117188, batch loss prom: 0.06031625717878342, batch loss ss: 0.06981761753559113, batch loss polya: 9.60780744208023e-05\n",
      "batch loss 0.28778260946273804, batch loss prom: 0.25506144762039185, batch loss ss: 0.03234761953353882, batch loss polya: 0.00037353215157054365\n",
      "batch loss 0.793184757232666, batch loss prom: 0.09951658546924591, batch loss ss: 0.6935504078865051, batch loss polya: 0.00011777184408856556\n",
      "batch loss 0.3458678424358368, batch loss prom: 0.014143586158752441, batch loss ss: 0.3316706120967865, batch loss polya: 5.364274329622276e-05\n",
      "batch loss 0.003935541026294231, batch loss prom: 0.0010920758359134197, batch loss ss: 0.000896052282769233, batch loss polya: 0.0019474128494039178\n",
      "batch loss 0.005518057849258184, batch loss prom: 0.0009748950251378119, batch loss ss: 0.0012444854946807027, batch loss polya: 0.003298677271232009\n",
      "batch loss 0.0039419070817530155, batch loss prom: 0.0011456600623205304, batch loss ss: 0.0009134411229752004, batch loss polya: 0.0018828060710802674\n",
      "batch loss 0.2018880844116211, batch loss prom: 0.06989743560552597, batch loss ss: 0.13095274567604065, batch loss polya: 0.0010378933511674404\n",
      "batch loss 0.004838722757995129, batch loss prom: 0.0009814451914280653, batch loss ss: 0.0013737775152549148, batch loss polya: 0.0024835001677274704\n",
      "batch loss 0.003776806639507413, batch loss prom: 0.0010132422903552651, batch loss ss: 0.0011335145682096481, batch loss polya: 0.0016300498973578215\n",
      "batch loss 0.004570981487631798, batch loss prom: 0.0011607821797952056, batch loss ss: 0.0010352734243497252, batch loss polya: 0.0023749261163175106\n",
      "batch loss 0.3331892192363739, batch loss prom: 0.006450782995671034, batch loss ss: 0.3266497552394867, batch loss polya: 8.868777513271198e-05\n",
      "batch loss 0.17580844461917877, batch loss prom: 0.004027708433568478, batch loss ss: 0.1716945469379425, batch loss polya: 8.618460560683161e-05\n",
      "batch loss 3.4263815879821777, batch loss prom: 2.333719491958618, batch loss ss: 1.0924570560455322, batch loss polya: 0.000205018965061754\n",
      "batch loss 0.003438712563365698, batch loss prom: 0.0008796160109341145, batch loss ss: 0.00126079679466784, batch loss polya: 0.0012982996413484216\n",
      "batch loss 2.7592852115631104, batch loss prom: 0.01126642245799303, batch loss ss: 2.7479968070983887, batch loss polya: 2.1934269170742482e-05\n",
      "batch loss 1.564606785774231, batch loss prom: 1.548924446105957, batch loss ss: 0.014021224342286587, batch loss polya: 0.0016611122991889715\n",
      "batch loss 0.8641316890716553, batch loss prom: 0.8539094924926758, batch loss ss: 0.009888354688882828, batch loss polya: 0.00033384948619641364\n",
      "batch loss 0.27387070655822754, batch loss prom: 0.2301882654428482, batch loss ss: 0.036266691982746124, batch loss polya: 0.007415744010359049\n",
      "batch loss 0.012283578515052795, batch loss prom: 0.0024148847442120314, batch loss ss: 0.009679526090621948, batch loss polya: 0.00018916724366135895\n",
      "batch loss 0.48208341002464294, batch loss prom: 0.4591355621814728, batch loss ss: 0.02277502976357937, batch loss polya: 0.0001728385395836085\n",
      "batch loss 0.22219818830490112, batch loss prom: 0.19914759695529938, batch loss ss: 0.022962849587202072, batch loss polya: 8.77341881277971e-05\n",
      "batch loss 0.6775407195091248, batch loss prom: 0.5105739831924438, batch loss ss: 0.16660557687282562, batch loss polya: 0.00036113892565481365\n",
      "batch loss 0.22832000255584717, batch loss prom: 0.11020682007074356, batch loss ss: 0.11555085331201553, batch loss polya: 0.0025623366236686707\n",
      "batch loss 0.008787299506366253, batch loss prom: 0.0016480210470035672, batch loss ss: 0.006601312197744846, batch loss polya: 0.0005379660287871957\n",
      "batch loss 0.0034630117006599903, batch loss prom: 0.0010417040903121233, batch loss ss: 0.0008170842193067074, batch loss polya: 0.0016042232746258378\n",
      "batch loss 0.015409781597554684, batch loss prom: 0.0021695189643651247, batch loss ss: 0.012106509879231453, batch loss polya: 0.0011337526375427842\n",
      "batch loss 1.8246270418167114, batch loss prom: 0.18913163244724274, batch loss ss: 1.6354687213897705, batch loss polya: 2.6702524337451905e-05\n",
      "batch loss 0.9887483716011047, batch loss prom: 0.9793539047241211, batch loss ss: 0.009119996801018715, batch loss polya: 0.00027450130437500775\n",
      "batch loss 1.82681143283844, batch loss prom: 0.002251710742712021, batch loss ss: 1.8241612911224365, batch loss polya: 0.00039843725971877575\n",
      "batch loss 1.5539789199829102, batch loss prom: 0.0023544705472886562, batch loss ss: 1.5515574216842651, batch loss polya: 6.69933797325939e-05\n",
      "batch loss 0.0040674167685210705, batch loss prom: 0.0008971241768449545, batch loss ss: 0.0011530425399541855, batch loss polya: 0.0020172500517219305\n",
      "batch loss 1.8007926940917969, batch loss prom: 1.7837363481521606, batch loss ss: 0.015926413238048553, batch loss polya: 0.0011299422476440668\n",
      "batch loss 0.5604907274246216, batch loss prom: 0.07984674721956253, batch loss ss: 0.4805377721786499, batch loss polya: 0.0001062098381225951\n",
      "batch loss 0.005453163757920265, batch loss prom: 0.001016457681544125, batch loss ss: 0.0010798105504363775, batch loss polya: 0.0033568956423550844\n",
      "batch loss 1.082228183746338, batch loss prom: 0.9059609174728394, batch loss ss: 0.17617268860340118, batch loss polya: 9.452849917579442e-05\n",
      "batch loss 0.004163111560046673, batch loss prom: 0.0013048476539552212, batch loss ss: 0.0014477020595222712, batch loss polya: 0.0014105618465691805\n",
      "batch loss 0.5753761529922485, batch loss prom: 0.009151417762041092, batch loss ss: 0.5661984086036682, batch loss polya: 2.634490556374658e-05\n",
      "batch loss 0.0036319014616310596, batch loss prom: 0.0007247682078741491, batch loss ss: 0.0018712644232437015, batch loss polya: 0.00103586888872087\n",
      "batch loss 0.5407669544219971, batch loss prom: 0.40437397360801697, batch loss ss: 0.13627409934997559, batch loss polya: 0.00011884459672728553\n",
      "batch loss 0.17351263761520386, batch loss prom: 0.05092361941933632, batch loss ss: 0.12246909737586975, batch loss polya: 0.00011991735664196312\n",
      "batch loss 0.12917360663414001, batch loss prom: 0.055801667273044586, batch loss ss: 0.07320911437273026, batch loss polya: 0.00016282663273159415\n",
      "batch loss 0.018252773210406303, batch loss prom: 0.0017652419628575444, batch loss ss: 0.00988941639661789, batch loss polya: 0.006598114967346191\n",
      "batch loss 0.004731026943773031, batch loss prom: 0.0009410720085725188, batch loss ss: 0.002430819906294346, batch loss polya: 0.001359134796075523\n",
      "batch loss 0.10409097373485565, batch loss prom: 0.023189889267086983, batch loss ss: 0.08075279742479324, batch loss polya: 0.00014828535495325923\n",
      "batch loss 0.8290653824806213, batch loss prom: 0.03584342077374458, batch loss ss: 0.7931772470474243, batch loss polya: 4.470248313737102e-05\n",
      "batch loss 0.8136239051818848, batch loss prom: 0.7795710563659668, batch loss ss: 0.0335049070417881, batch loss polya: 0.0005479741375893354\n",
      "batch loss 0.004005527123808861, batch loss prom: 0.0008958140970207751, batch loss ss: 0.0019839382730424404, batch loss polya: 0.0011257746955379844\n",
      "batch loss 0.3141527771949768, batch loss prom: 0.253304123878479, batch loss ss: 0.06076474487781525, batch loss polya: 8.391981828026474e-05\n",
      "batch loss 0.003568612737581134, batch loss prom: 0.0008615119731985033, batch loss ss: 0.0016653967322781682, batch loss polya: 0.0010417040903121233\n",
      "batch loss 0.16648796200752258, batch loss prom: 0.0013040142366662621, batch loss ss: 0.1650872677564621, batch loss polya: 9.667406266089529e-05\n",
      "batch loss 0.10957828164100647, batch loss prom: 0.014792638830840588, batch loss ss: 0.09441139549016953, batch loss polya: 0.00037424711626954377\n",
      "batch loss 1.4934968948364258, batch loss prom: 0.007338354364037514, batch loss ss: 1.4861191511154175, batch loss polya: 3.93382906622719e-05\n",
      "batch loss 1.3949005603790283, batch loss prom: 0.017377031967043877, batch loss ss: 1.3774993419647217, batch loss polya: 2.4199192921514623e-05\n",
      "batch loss 0.064669668674469, batch loss prom: 0.003650906728580594, batch loss ss: 0.057830944657325745, batch loss polya: 0.0031878151930868626\n",
      "batch loss 0.7823077440261841, batch loss prom: 0.014774080365896225, batch loss ss: 0.7674638032913208, batch loss polya: 6.985420623095706e-05\n",
      "batch loss 2.220210313796997, batch loss prom: 0.04010026156902313, batch loss ss: 2.1800215244293213, batch loss polya: 8.844937838148326e-05\n",
      "batch loss 1.7947088479995728, batch loss prom: 0.09579277783632278, batch loss ss: 1.6988718509674072, batch loss polya: 4.4225667807040736e-05\n",
      "batch loss 0.32740047574043274, batch loss prom: 0.09699515998363495, batch loss ss: 0.2303624004125595, batch loss polya: 4.2914423829643056e-05\n",
      "batch loss 0.2405620813369751, batch loss prom: 0.06861414015293121, batch loss ss: 0.17184744775295258, batch loss polya: 0.00010048838157672435\n",
      "batch loss 0.003291785717010498, batch loss prom: 0.0012846082681789994, batch loss ss: 0.0011247029760852456, batch loss polya: 0.0008824745309539139\n",
      "batch loss 0.0031461790204048157, batch loss prom: 0.0010012142593041062, batch loss ss: 0.0011693552369251847, batch loss polya: 0.0009756095823831856\n",
      "batch loss 0.7966467142105103, batch loss prom: 0.02410043776035309, batch loss ss: 0.7725014686584473, batch loss polya: 4.482168878894299e-05\n",
      "batch loss 0.0035425275564193726, batch loss prom: 0.0008806879632174969, batch loss ss: 0.0016770598012953997, batch loss polya: 0.0009847796754911542\n",
      "batch loss 0.30472102761268616, batch loss prom: 0.00839171465486288, batch loss ss: 0.29621702432632446, batch loss polya: 0.00011228884250158444\n",
      "batch loss 0.10075219720602036, batch loss prom: 0.003564553800970316, batch loss ss: 0.09714401513338089, batch loss polya: 4.362964682513848e-05\n",
      "batch loss 0.002838193904608488, batch loss prom: 0.0006816447712481022, batch loss ss: 0.0013863962376490235, batch loss polya: 0.0007701530121266842\n",
      "batch loss 0.003649106016382575, batch loss prom: 0.0008355463505722582, batch loss ss: 0.00195693108253181, batch loss polya: 0.000856628583278507\n",
      "batch loss 0.0032408605329692364, batch loss prom: 0.0008793777669779956, batch loss ss: 0.0014787701657041907, batch loss polya: 0.0008827127167023718\n",
      "batch loss 0.0032415343448519707, batch loss prom: 0.0007221474661491811, batch loss ss: 0.0015119798481464386, batch loss polya: 0.00100740697234869\n",
      "batch loss 0.0029421912040561438, batch loss prom: 0.0007160721579566598, batch loss ss: 0.0013722298899665475, batch loss polya: 0.0008538890979252756\n",
      "batch loss 0.5710672736167908, batch loss prom: 0.12058534473180771, batch loss ss: 0.45041006803512573, batch loss polya: 7.188061863416806e-05\n",
      "batch loss 0.3309773802757263, batch loss prom: 0.04223727434873581, batch loss ss: 0.2886194586753845, batch loss polya: 0.00012063252506777644\n",
      "batch loss 0.16256001591682434, batch loss prom: 0.07479486614465714, batch loss ss: 0.08768158406019211, batch loss polya: 8.356221951544285e-05\n",
      "batch loss 0.363583505153656, batch loss prom: 0.019827619194984436, batch loss ss: 0.34370794892311096, batch loss polya: 4.792098479811102e-05\n",
      "batch loss 1.0776211023330688, batch loss prom: 1.055621862411499, batch loss ss: 0.020977415144443512, batch loss polya: 0.0010218166280537844\n",
      "batch loss 0.00300947530195117, batch loss prom: 0.0007493072189390659, batch loss ss: 0.001401514746248722, batch loss polya: 0.0008586533949710429\n",
      "batch loss 0.3253045976161957, batch loss prom: 0.3087300956249237, batch loss ss: 0.015607471577823162, batch loss polya: 0.00096703483723104\n",
      "batch loss 0.00298762577585876, batch loss prom: 0.000788139586802572, batch loss ss: 0.001262820791453123, batch loss polya: 0.0009366653976030648\n",
      "batch loss 0.0033398009836673737, batch loss prom: 0.0008948612376116216, batch loss ss: 0.0015345951542258263, batch loss polya: 0.000910344475414604\n",
      "batch loss 0.32414597272872925, batch loss prom: 0.3098386824131012, batch loss ss: 0.013881566002964973, batch loss polya: 0.00042572495294734836\n",
      "batch loss 2.8777055740356445, batch loss prom: 0.021284030750393867, batch loss ss: 2.856368064880371, batch loss polya: 5.352353764465079e-05\n",
      "batch loss 0.0029475917108356953, batch loss prom: 0.0008657997823320329, batch loss ss: 0.0013017522869631648, batch loss polya: 0.0007800396997481585\n",
      "batch loss 0.8585968613624573, batch loss prom: 0.07040642201900482, batch loss ss: 0.7881506085395813, batch loss polya: 3.981510963058099e-05\n",
      "batch loss 1.6834728717803955, batch loss prom: 1.3752729892730713, batch loss ss: 0.308150053024292, batch loss polya: 4.9828242481453344e-05\n",
      "batch loss 0.845818042755127, batch loss prom: 0.04870973527431488, batch loss ss: 0.7969788312911987, batch loss polya: 0.0001294529065489769\n",
      "batch loss 0.6670784950256348, batch loss prom: 0.06914035975933075, batch loss ss: 0.5978915095329285, batch loss polya: 4.660974445869215e-05\n",
      "batch loss 0.06326102465391159, batch loss prom: 0.001800346071831882, batch loss ss: 0.06049424037337303, batch loss polya: 0.0009664393728598952\n",
      "batch loss 0.47670242190361023, batch loss prom: 0.46207085251808167, batch loss ss: 0.014284735545516014, batch loss polya: 0.00034683887497521937\n",
      "batch loss 0.12241091579198837, batch loss prom: 0.0030753957107663155, batch loss ss: 0.11913538724184036, batch loss polya: 0.00020013237372040749\n",
      "batch loss 1.2041875123977661, batch loss prom: 0.8485130071640015, batch loss ss: 0.3556167185306549, batch loss polya: 5.781483559985645e-05\n",
      "batch loss 1.7814198732376099, batch loss prom: 1.601151466369629, batch loss ss: 0.18024718761444092, batch loss polya: 2.1219027985353023e-05\n",
      "batch loss 0.004608802031725645, batch loss prom: 0.0008902162662707269, batch loss ss: 0.002719991374760866, batch loss polya: 0.000998594332486391\n",
      "batch loss 0.39773526787757874, batch loss prom: 0.0439964234828949, batch loss ss: 0.3536779284477234, batch loss polya: 6.09140915912576e-05\n",
      "batch loss 0.33377981185913086, batch loss prom: 0.16632166504859924, batch loss ss: 0.16734299063682556, batch loss polya: 0.00011514954530866817\n",
      "batch loss 0.4002518057823181, batch loss prom: 0.333625465631485, batch loss ss: 0.0664849653840065, batch loss polya: 0.00014137222024146467\n",
      "batch loss 0.25045275688171387, batch loss prom: 0.20159868896007538, batch loss ss: 0.04801507294178009, batch loss polya: 0.0008390005677938461\n",
      "batch loss 0.003440053202211857, batch loss prom: 0.0011338717304170132, batch loss ss: 0.001529357978142798, batch loss polya: 0.0007768235518597066\n",
      "batch loss 0.7966709136962891, batch loss prom: 0.11839510500431061, batch loss ss: 0.6782273054122925, batch loss polya: 4.851700214203447e-05\n",
      "batch loss 0.28555938601493835, batch loss prom: 0.04250796511769295, batch loss ss: 0.24299216270446777, batch loss polya: 5.924526340095326e-05\n",
      "batch loss 1.2341002225875854, batch loss prom: 1.1569546461105347, batch loss ss: 0.07660471647977829, batch loss polya: 0.0005408254801295698\n",
      "batch loss 0.761445164680481, batch loss prom: 0.003952430561184883, batch loss ss: 0.7572121620178223, batch loss polya: 0.0002805792901199311\n",
      "batch loss 0.6362923383712769, batch loss prom: 0.6178421378135681, batch loss ss: 0.018332917243242264, batch loss polya: 0.00011729506513802335\n",
      "batch loss 1.4896749258041382, batch loss prom: 0.01567905955016613, batch loss ss: 1.4738719463348389, batch loss polya: 0.00012396997772157192\n",
      "batch loss 1.7892950773239136, batch loss prom: 1.7734376192092896, batch loss ss: 0.01444678008556366, batch loss polya: 0.0014106809394434094\n",
      "batch loss 0.002749828854575753, batch loss prom: 0.0004981707315891981, batch loss ss: 0.0014855550834909081, batch loss polya: 0.000766102981287986\n",
      "batch loss 1.1498324871063232, batch loss prom: 0.44718027114868164, batch loss ss: 0.702415943145752, batch loss polya: 0.00023624490131624043\n",
      "batch loss 0.0038657255936414003, batch loss prom: 0.0006521005416288972, batch loss ss: 0.0022513538133352995, batch loss polya: 0.0009622710640542209\n",
      "batch loss 0.26747071743011475, batch loss prom: 0.23982886970043182, batch loss ss: 0.027508936822414398, batch loss polya: 0.00013290952483657748\n",
      "batch loss 0.003140029264613986, batch loss prom: 0.0011614966206252575, batch loss ss: 0.0012684165267273784, batch loss polya: 0.0007101159426383674\n",
      "batch loss 0.8217210173606873, batch loss prom: 0.040805935859680176, batch loss ss: 0.7808758616447449, batch loss polya: 3.9219088648678735e-05\n",
      "batch loss 1.518584966659546, batch loss prom: 0.6331194043159485, batch loss ss: 0.8853910565376282, batch loss polya: 7.450303382938728e-05\n",
      "batch loss 0.9202909469604492, batch loss prom: 0.0020568659529089928, batch loss ss: 0.918033242225647, batch loss polya: 0.0002008474839385599\n",
      "batch loss 0.39107760787010193, batch loss prom: 0.33790382742881775, batch loss ss: 0.053136229515075684, batch loss polya: 3.755022044060752e-05\n",
      "batch loss 0.025924179702997208, batch loss prom: 0.0035024271346628666, batch loss ss: 0.006218489725142717, batch loss polya: 0.0162032637745142\n",
      "batch loss 2.1171681880950928, batch loss prom: 0.005660694558173418, batch loss ss: 2.1112864017486572, batch loss polya: 0.00022110878489911556\n",
      "batch loss 0.14160098135471344, batch loss prom: 0.0071652112528681755, batch loss ss: 0.13428498804569244, batch loss polya: 0.00015078838623594493\n",
      "batch loss 0.4917646646499634, batch loss prom: 0.02768937684595585, batch loss ss: 0.46406635642051697, batch loss polya: 8.940656698541716e-06\n",
      "batch loss 0.5799561142921448, batch loss prom: 0.4912005662918091, batch loss ss: 0.08855743706226349, batch loss polya: 0.00019810620869975537\n",
      "batch loss 0.7965352535247803, batch loss prom: 0.1619080752134323, batch loss ss: 0.6346067786216736, batch loss polya: 2.038458114839159e-05\n",
      "batch loss 0.0031984257511794567, batch loss prom: 0.0007677706307731569, batch loss ss: 0.001791897346265614, batch loss polya: 0.0006387577159330249\n",
      "batch loss 0.3345893919467926, batch loss prom: 0.016341425478458405, batch loss ss: 0.3182275891304016, batch loss polya: 2.038458114839159e-05\n",
      "batch loss 1.6016396284103394, batch loss prom: 0.01866760663688183, batch loss ss: 1.5828583240509033, batch loss polya: 0.0001137191939051263\n",
      "batch loss 0.12184219062328339, batch loss prom: 0.004514027386903763, batch loss ss: 0.11687228828668594, batch loss polya: 0.0004558716027531773\n",
      "batch loss 1.2179405689239502, batch loss prom: 1.1993353366851807, batch loss ss: 0.014791347086429596, batch loss polya: 0.0038138525560498238\n",
      "batch loss 0.27923303842544556, batch loss prom: 0.010665321722626686, batch loss ss: 0.2685145437717438, batch loss polya: 5.3165931603871286e-05\n",
      "batch loss 0.7600456476211548, batch loss prom: 0.32151779532432556, batch loss ss: 0.43807029724121094, batch loss polya: 0.00045753977610729635\n",
      "batch loss 0.2653571367263794, batch loss prom: 0.03418460488319397, batch loss ss: 0.2295173853635788, batch loss polya: 0.0016551617300137877\n",
      "batch loss 0.028325077146291733, batch loss prom: 0.013139214366674423, batch loss ss: 0.014582131057977676, batch loss polya: 0.0006037319544702768\n",
      "batch loss 0.016144631430506706, batch loss prom: 0.0008095800876617432, batch loss ss: 0.014570734463632107, batch loss polya: 0.0007643162389285862\n",
      "batch loss 1.516046404838562, batch loss prom: 1.502624750137329, batch loss ss: 0.012805023230612278, batch loss polya: 0.0006167178507894278\n",
      "batch loss 0.3349337875843048, batch loss prom: 0.002148464322090149, batch loss ss: 0.3325711488723755, batch loss polya: 0.00021419614495243877\n",
      "batch loss 0.020382072776556015, batch loss prom: 0.0006510283565148711, batch loss ss: 0.01947227492928505, batch loss polya: 0.00025876989820972085\n",
      "batch loss 4.567422389984131, batch loss prom: 3.542079448699951, batch loss ss: 1.0250356197357178, batch loss polya: 0.00030751267331652343\n",
      "batch loss 0.0031280885450541973, batch loss prom: 0.0010609956225380301, batch loss ss: 0.0010578995570540428, batch loss polya: 0.0010091932490468025\n",
      "batch loss 0.0028352783992886543, batch loss prom: 0.0005535738891921937, batch loss ss: 0.0015979153104126453, batch loss polya: 0.0006837890832684934\n",
      "batch loss 0.0026075001806020737, batch loss prom: 0.0006183857913129032, batch loss ss: 0.0014572249492630363, batch loss polya: 0.0005318895564414561\n",
      "batch loss 0.2434772104024887, batch loss prom: 0.0035071787424385548, batch loss ss: 0.23973986506462097, batch loss polya: 0.00023016665363684297\n",
      "batch loss 0.003094868967309594, batch loss prom: 0.0009348789462819695, batch loss ss: 0.0016678959364071488, batch loss polya: 0.0004920940846204758\n",
      "batch loss 0.8415831923484802, batch loss prom: 0.6358320713043213, batch loss ss: 0.20559711754322052, batch loss polya: 0.00015400654228869826\n",
      "batch loss 0.002154397778213024, batch loss prom: 0.0008481719414703548, batch loss ss: 0.0006786665762774646, batch loss polya: 0.0006275591440498829\n",
      "batch loss 0.002674615941941738, batch loss prom: 0.0008825936238281429, batch loss ss: 0.0011830481234937906, batch loss polya: 0.0006089740199968219\n",
      "batch loss 0.23147788643836975, batch loss prom: 0.010721461847424507, batch loss ss: 0.11023510992527008, batch loss polya: 0.11052130907773972\n",
      "batch loss 0.0031327346805483103, batch loss prom: 0.0007039214833639562, batch loss ss: 0.0017333496361970901, batch loss polya: 0.000695463502779603\n",
      "batch loss 0.08135076612234116, batch loss prom: 0.004072349984198809, batch loss ss: 0.0765649601817131, batch loss polya: 0.0007134514744393528\n",
      "batch loss 0.0028908501844853163, batch loss prom: 0.0007755132392048836, batch loss ss: 0.0015310243470594287, batch loss polya: 0.0005843124235980213\n",
      "batch loss 0.202733114361763, batch loss prom: 0.012377472594380379, batch loss ss: 0.19014954566955566, batch loss polya: 0.0002060916303889826\n",
      "batch loss 0.21485422551631927, batch loss prom: 0.0025391501840204, batch loss ss: 0.2122577428817749, batch loss polya: 5.7338023907504976e-05\n",
      "batch loss 0.17000868916511536, batch loss prom: 0.006579285021871328, batch loss ss: 0.16330628097057343, batch loss polya: 0.00012313561455812305\n",
      "batch loss 1.065142273902893, batch loss prom: 0.0050627365708351135, batch loss ss: 1.060043454170227, batch loss polya: 3.611976353568025e-05\n",
      "batch loss 0.4309059679508209, batch loss prom: 0.05461878329515457, batch loss ss: 0.3761352002620697, batch loss polya: 0.00015198028995655477\n",
      "batch loss 0.3720499873161316, batch loss prom: 0.36163952946662903, batch loss ss: 0.006824163254350424, batch loss polya: 0.003586291102692485\n",
      "batch loss 0.18858176469802856, batch loss prom: 0.015487401746213436, batch loss ss: 0.17278672754764557, batch loss polya: 0.00030763185350224376\n",
      "batch loss 0.5402244329452515, batch loss prom: 0.02787233516573906, batch loss ss: 0.5122870206832886, batch loss polya: 6.508615479106084e-05\n",
      "batch loss 0.0027281560469418764, batch loss prom: 0.000806721393018961, batch loss ss: 0.0010658780811354518, batch loss polya: 0.0008555566309951246\n",
      "batch loss 0.3610582649707794, batch loss prom: 0.018522042781114578, batch loss ss: 0.34247279167175293, batch loss polya: 6.341733387671411e-05\n",
      "batch loss 0.24226078391075134, batch loss prom: 0.06032377481460571, batch loss ss: 0.18057823181152344, batch loss polya: 0.0013587776338681579\n",
      "batch loss 0.002466923324391246, batch loss prom: 0.0006482883472926915, batch loss ss: 0.0010800487361848354, batch loss polya: 0.0007385863573290408\n",
      "batch loss 1.4984891414642334, batch loss prom: 1.4884833097457886, batch loss ss: 0.006629141513258219, batch loss polya: 0.0033767367713153362\n",
      "batch loss 0.04298596456646919, batch loss prom: 0.006517226807773113, batch loss ss: 0.036273013800382614, batch loss polya: 0.00019572250312194228\n",
      "batch loss 0.01582404598593712, batch loss prom: 0.002998857758939266, batch loss ss: 0.012634471990168095, batch loss polya: 0.00019071667338721454\n",
      "batch loss 0.08480553328990936, batch loss prom: 0.06694664061069489, batch loss ss: 0.017508355900645256, batch loss polya: 0.0003505330823827535\n",
      "batch loss 0.13473773002624512, batch loss prom: 0.005534682422876358, batch loss ss: 0.1291714608669281, batch loss polya: 3.158996332786046e-05\n",
      "batch loss 0.44262993335723877, batch loss prom: 0.39042824506759644, batch loss ss: 0.0517311692237854, batch loss polya: 0.00047052756417542696\n",
      "batch loss 1.0129750967025757, batch loss prom: 0.9177020192146301, batch loss ss: 0.0951908752322197, batch loss polya: 8.225102646974847e-05\n",
      "batch loss 0.003528143744915724, batch loss prom: 0.0007358465809375048, batch loss ss: 0.001531857531517744, batch loss polya: 0.001260439632460475\n",
      "batch loss 0.012211190536618233, batch loss prom: 0.005341069307178259, batch loss ss: 0.006383031141012907, batch loss polya: 0.00048708971007727087\n",
      "batch loss 0.19564945995807648, batch loss prom: 0.08883616328239441, batch loss ss: 0.10665405541658401, batch loss polya: 0.00015925093612167984\n",
      "batch loss 0.06724312156438828, batch loss prom: 0.016848988831043243, batch loss ss: 0.05036981403827667, batch loss polya: 2.4318398573086597e-05\n",
      "batch loss 0.003139329142868519, batch loss prom: 0.0007516896002925932, batch loss ss: 0.0011031500762328506, batch loss polya: 0.0012844892917200923\n",
      "batch loss 0.15536703169345856, batch loss prom: 0.13119418919086456, batch loss ss: 0.02413267269730568, batch loss polya: 4.017272294731811e-05\n",
      "batch loss 0.0025542492512613535, batch loss prom: 0.0007352509419433773, batch loss ss: 0.0010619483655318618, batch loss polya: 0.0007570500019937754\n",
      "batch loss 0.5186271071434021, batch loss prom: 0.05331786721944809, batch loss ss: 0.46497970819473267, batch loss polya: 0.0003295593778602779\n",
      "batch loss 0.00315330782905221, batch loss prom: 0.0009086770587600768, batch loss ss: 0.0010121704544872046, batch loss polya: 0.0012324602575972676\n",
      "batch loss 0.24367085099220276, batch loss prom: 0.03075605258345604, batch loss ss: 0.21279749274253845, batch loss polya: 0.00011729506513802335\n",
      "batch loss 0.6783711910247803, batch loss prom: 0.6190292239189148, batch loss ss: 0.059096116572618484, batch loss polya: 0.00024589852546341717\n",
      "batch loss 0.0026868125423789024, batch loss prom: 0.0007454953738488257, batch loss ss: 0.0008393579046241939, batch loss polya: 0.0011019593803212047\n",
      "batch loss 0.3454132378101349, batch loss prom: 0.2592972218990326, batch loss ss: 0.085592120885849, batch loss polya: 0.0005239067832008004\n",
      "batch loss 0.0022385017946362495, batch loss prom: 0.0008012421894818544, batch loss ss: 0.0008024332928471267, batch loss polya: 0.0006348263123072684\n",
      "batch loss 0.7920933961868286, batch loss prom: 0.00447071110829711, batch loss ss: 0.7875956296920776, batch loss polya: 2.706014311115723e-05\n",
      "batch loss 0.0023253934923559427, batch loss prom: 0.001086717238649726, batch loss ss: 0.0006578188622370362, batch loss polya: 0.0005808573332615197\n",
      "batch loss 0.0021675117313861847, batch loss prom: 0.000697846058756113, batch loss ss: 0.0006847421173006296, batch loss polya: 0.0007849234389141202\n",
      "batch loss 0.19528888165950775, batch loss prom: 0.001086717238649726, batch loss ss: 0.19404959678649902, batch loss polya: 0.0001525762490928173\n",
      "batch loss 1.451972246170044, batch loss prom: 1.4402040243148804, batch loss ss: 0.006874244660139084, batch loss polya: 0.004894062876701355\n",
      "batch loss 0.6981374025344849, batch loss prom: 0.6644912958145142, batch loss ss: 0.030984334647655487, batch loss polya: 0.002661735750734806\n",
      "batch loss 0.21947072446346283, batch loss prom: 0.017521709203720093, batch loss ss: 0.20176950097084045, batch loss polya: 0.00017951308109331876\n",
      "batch loss 0.002440882381051779, batch loss prom: 0.0008481719414703548, batch loss ss: 0.000714404450263828, batch loss polya: 0.0008783058729022741\n",
      "batch loss 0.002338321879506111, batch loss prom: 0.0007008241955190897, batch loss ss: 0.0007425173535011709, batch loss polya: 0.0008949803304858506\n",
      "batch loss 0.40468767285346985, batch loss prom: 0.3960261344909668, batch loss ss: 0.0058735632337629795, batch loss polya: 0.002787991426885128\n",
      "batch loss 0.4658074676990509, batch loss prom: 0.12672412395477295, batch loss ss: 0.3389538824558258, batch loss polya: 0.0001294529065489769\n",
      "batch loss 1.1467469930648804, batch loss prom: 1.135467529296875, batch loss ss: 0.006268837954849005, batch loss polya: 0.005010548047721386\n",
      "batch loss 1.2455087900161743, batch loss prom: 1.2369861602783203, batch loss ss: 0.00645658653229475, batch loss polya: 0.002066026208922267\n",
      "batch loss 0.13381417095661163, batch loss prom: 0.01764809340238571, batch loss ss: 0.11584318429231644, batch loss polya: 0.0003228858404327184\n",
      "batch loss 0.4533638656139374, batch loss prom: 0.4028841555118561, batch loss ss: 0.04999726265668869, batch loss polya: 0.000482442817883566\n",
      "batch loss 0.0022912309505045414, batch loss prom: 0.0010203876299783587, batch loss ss: 0.000608854868914932, batch loss polya: 0.0006619884516112506\n",
      "batch loss 0.002286036964505911, batch loss prom: 0.0008207766804844141, batch loss ss: 0.000742398202419281, batch loss polya: 0.0007228621980175376\n",
      "batch loss 0.7780032157897949, batch loss prom: 0.5699024200439453, batch loss ss: 0.207647442817688, batch loss polya: 0.0004533693427219987\n",
      "batch loss 0.0020683896727859974, batch loss prom: 0.0007783720502629876, batch loss ss: 0.000726316764485091, batch loss polya: 0.0005637010326609015\n",
      "batch loss 0.0021691524889320135, batch loss prom: 0.0009190387791022658, batch loss ss: 0.0005957497633062303, batch loss polya: 0.0006543640629388392\n",
      "batch loss 1.1238293647766113, batch loss prom: 1.0015053749084473, batch loss ss: 0.122226282954216, batch loss polya: 9.77468371274881e-05\n",
      "batch loss 1.292709469795227, batch loss prom: 0.16759032011032104, batch loss ss: 1.125032663345337, batch loss polya: 8.642300235806033e-05\n",
      "batch loss 4.684231281280518, batch loss prom: 0.6991981863975525, batch loss ss: 3.9845499992370605, batch loss polya: 0.00048315772437490523\n",
      "batch loss 1.7703627347946167, batch loss prom: 0.014929821714758873, batch loss ss: 1.7553822994232178, batch loss polya: 5.066266385256313e-05\n",
      "batch loss 0.01369689404964447, batch loss prom: 0.0012677022023126483, batch loss ss: 0.011543858796358109, batch loss polya: 0.0008853329927660525\n",
      "batch loss 0.0020425445400178432, batch loss prom: 0.000726316764485091, batch loss ss: 0.0005839549703523517, batch loss polya: 0.0007322729215957224\n",
      "batch loss 0.0022784138564020395, batch loss prom: 0.0007247682078741491, batch loss ss: 0.0007394201820716262, batch loss polya: 0.0008142255246639252\n",
      "batch loss 0.14733447134494781, batch loss prom: 0.011916285380721092, batch loss ss: 0.13533736765384674, batch loss polya: 8.082063141046092e-05\n",
      "batch loss 0.00203704577870667, batch loss prom: 0.0008226824575103819, batch loss ss: 0.0005038899253122509, batch loss polya: 0.0007104733376763761\n",
      "batch loss 3.814300775527954, batch loss prom: 3.6710076332092285, batch loss ss: 0.1432051807641983, batch loss polya: 8.809178689261898e-05\n",
      "batch loss 0.6425164937973022, batch loss prom: 0.6214384436607361, batch loss ss: 0.019898205995559692, batch loss polya: 0.0011798333143815398\n",
      "batch loss 5.036441326141357, batch loss prom: 4.493598937988281, batch loss ss: 0.5427748560905457, batch loss polya: 6.770858453819528e-05\n",
      "batch loss 4.591843128204346, batch loss prom: 0.006788998376578093, batch loss ss: 4.584763050079346, batch loss polya: 0.0002910667099058628\n",
      "batch loss 0.2049877941608429, batch loss prom: 0.0134291872382164, batch loss ss: 0.19147300720214844, batch loss polya: 8.5588610090781e-05\n",
      "batch loss 0.0025934362784028053, batch loss prom: 0.0007307243067771196, batch loss ss: 0.0010699268896132708, batch loss polya: 0.0007927850820124149\n",
      "batch loss 0.43553611636161804, batch loss prom: 0.0187278613448143, batch loss ss: 0.4166839122772217, batch loss polya: 0.00012432756193447858\n",
      "batch loss 0.0023991847410798073, batch loss prom: 0.0007858763565309346, batch loss ss: 0.0009297577198594809, batch loss polya: 0.0006835508393123746\n",
      "batch loss 0.2149776965379715, batch loss prom: 0.08492327481508255, batch loss ss: 0.12988004088401794, batch loss polya: 0.00017438798386137933\n",
      "batch loss 0.4397863745689392, batch loss prom: 0.13899236917495728, batch loss ss: 0.30061450600624084, batch loss polya: 0.00017951308109331876\n",
      "batch loss 1.6302731037139893, batch loss prom: 0.05194803327322006, batch loss ss: 1.5782841444015503, batch loss polya: 4.088794958079234e-05\n",
      "batch loss 0.4599928557872772, batch loss prom: 0.3955448269844055, batch loss ss: 0.06422347575426102, batch loss polya: 0.00022456508304458112\n",
      "batch loss 1.993384599685669, batch loss prom: 0.10358905792236328, batch loss ss: 1.8897124528884888, batch loss polya: 8.308542601298541e-05\n",
      "batch loss 0.9092899560928345, batch loss prom: 0.13416948914527893, batch loss ss: 0.7750244736671448, batch loss polya: 9.595887240720913e-05\n",
      "batch loss 0.00496485223993659, batch loss prom: 0.0022074636071920395, batch loss ss: 0.001785947591997683, batch loss polya: 0.0009714413317851722\n",
      "batch loss 0.29942166805267334, batch loss prom: 0.04745306074619293, batch loss ss: 0.25193023681640625, batch loss polya: 3.838465272565372e-05\n",
      "batch loss 0.08074972033500671, batch loss prom: 0.0045789391733706, batch loss ss: 0.07499916106462479, batch loss polya: 0.0011716175358742476\n",
      "batch loss 0.008540923707187176, batch loss prom: 0.0035507744178175926, batch loss ss: 0.0031240014359354973, batch loss polya: 0.0018661479698494077\n",
      "batch loss 0.3254040777683258, batch loss prom: 0.2842482626438141, batch loss ss: 0.041119229048490524, batch loss polya: 3.659658250398934e-05\n",
      "batch loss 0.43718406558036804, batch loss prom: 0.034729599952697754, batch loss ss: 0.40243300795555115, batch loss polya: 2.1457441107486375e-05\n",
      "batch loss 1.211335301399231, batch loss prom: 0.12176326662302017, batch loss ss: 1.0895180702209473, batch loss polya: 5.400034933700226e-05\n",
      "batch loss 0.07850714772939682, batch loss prom: 0.023227160796523094, batch loss ss: 0.010227297432720661, batch loss polya: 0.04505268856883049\n",
      "batch loss 0.10679315030574799, batch loss prom: 0.039773814380168915, batch loss ss: 0.06692790985107422, batch loss polya: 9.142934868577868e-05\n",
      "batch loss 0.0026660561561584473, batch loss prom: 0.0011867393041029572, batch loss ss: 0.000750736624468118, batch loss polya: 0.0007285801111720502\n",
      "batch loss 0.2911089062690735, batch loss prom: 0.033863138407468796, batch loss ss: 0.257107138633728, batch loss polya: 0.00013863079948350787\n",
      "batch loss 0.0031874128617346287, batch loss prom: 0.0013656823430210352, batch loss ss: 0.0010854073334485292, batch loss polya: 0.0007363230688497424\n",
      "batch loss 1.304948091506958, batch loss prom: 0.06013431400060654, batch loss ss: 1.2447338104248047, batch loss polya: 7.998623186722398e-05\n",
      "batch loss 0.0033064871095120907, batch loss prom: 0.0009217780898325145, batch loss ss: 0.0016396900173276663, batch loss polya: 0.000745018885936588\n",
      "batch loss 0.004304917063564062, batch loss prom: 0.001116605824790895, batch loss ss: 0.0021031422074884176, batch loss polya: 0.0010851691477000713\n",
      "batch loss 0.29936474561691284, batch loss prom: 0.03082471713423729, batch loss ss: 0.26845037937164307, batch loss polya: 8.964136941358447e-05\n",
      "batch loss 0.002999295247718692, batch loss prom: 0.0008537700050510466, batch loss ss: 0.0012832987122237682, batch loss polya: 0.0008622265886515379\n",
      "batch loss 0.250566691160202, batch loss prom: 0.02833966724574566, batch loss ss: 0.22219257056713104, batch loss polya: 3.4450891689630225e-05\n",
      "batch loss 0.2574238181114197, batch loss prom: 0.05104131996631622, batch loss ss: 0.20631980895996094, batch loss polya: 6.270212179515511e-05\n",
      "batch loss 1.3694372177124023, batch loss prom: 1.3359936475753784, batch loss ss: 0.03306478261947632, batch loss polya: 0.00037889453233219683\n",
      "batch loss 0.0037141982465982437, batch loss prom: 0.0021935468539595604, batch loss ss: 0.0007444233051501215, batch loss polya: 0.00077622797107324\n",
      "batch loss 0.7401261329650879, batch loss prom: 0.6508824825286865, batch loss ss: 0.08878860622644424, batch loss polya: 0.00045503751607611775\n",
      "batch loss 0.0036681739147752523, batch loss prom: 0.0010124086402356625, batch loss ss: 0.0018192660063505173, batch loss polya: 0.0008364992681890726\n",
      "batch loss 0.5983251333236694, batch loss prom: 0.058810096234083176, batch loss ss: 0.5394837856292725, batch loss polya: 3.123234637314454e-05\n",
      "batch loss 2.416271924972534, batch loss prom: 0.19630104303359985, batch loss ss: 2.2197232246398926, batch loss polya: 0.00024780540843494236\n",
      "batch loss 0.5262241959571838, batch loss prom: 0.0036897454410791397, batch loss ss: 0.5224873423576355, batch loss polya: 4.708655978902243e-05\n",
      "batch loss 0.12846653163433075, batch loss prom: 0.08236286789178848, batch loss ss: 0.0458664707839489, batch loss polya: 0.00023719835735391825\n",
      "batch loss 0.29609376192092896, batch loss prom: 0.11760605871677399, batch loss ss: 0.17847517132759094, batch loss polya: 1.2516897186287679e-05\n",
      "batch loss 0.6691694855690002, batch loss prom: 0.3638986349105835, batch loss ss: 0.3052026629447937, batch loss polya: 6.818538531661034e-05\n",
      "batch loss 0.18615151941776276, batch loss prom: 0.012521225959062576, batch loss ss: 0.17360919713974, batch loss polya: 2.109982233378105e-05\n",
      "batch loss 0.0032514547929167747, batch loss prom: 0.0011185110779479146, batch loss ss: 0.0011206544004380703, batch loss polya: 0.0010122895473614335\n",
      "batch loss 0.05635922774672508, batch loss prom: 0.004037206526845694, batch loss ss: 0.003660883754491806, batch loss polya: 0.048661138862371445\n",
      "batch loss 0.6182211637496948, batch loss prom: 0.25768810510635376, batch loss ss: 0.3604852855205536, batch loss polya: 4.7801782784517854e-05\n",
      "batch loss 0.32409924268722534, batch loss prom: 0.16592204570770264, batch loss ss: 0.15815193951129913, batch loss polya: 2.52720492426306e-05\n",
      "batch loss 0.49810293316841125, batch loss prom: 0.46653497219085693, batch loss ss: 0.031451135873794556, batch loss polya: 0.00011681827891152352\n",
      "batch loss 0.4352002739906311, batch loss prom: 0.005800913088023663, batch loss ss: 0.42934274673461914, batch loss polya: 5.6622808187967166e-05\n",
      "batch loss 0.9633482098579407, batch loss prom: 0.9447806477546692, batch loss ss: 0.018184026703238487, batch loss polya: 0.00038354191929101944\n",
      "batch loss 0.7537614107131958, batch loss prom: 0.7368814945220947, batch loss ss: 0.01661558263003826, batch loss polya: 0.0002643712505232543\n",
      "batch loss 0.901873767375946, batch loss prom: 0.8682146072387695, batch loss ss: 0.033094536513090134, batch loss polya: 0.0005646541831083596\n",
      "batch loss 0.0036687750834971666, batch loss prom: 0.0016694430960342288, batch loss ss: 0.0009807306341826916, batch loss polya: 0.0010186012368649244\n",
      "batch loss 0.8777866363525391, batch loss prom: 0.03363678231835365, batch loss ss: 0.8441354036331177, batch loss polya: 1.4424220353248529e-05\n",
      "batch loss 0.14283166825771332, batch loss prom: 0.058582574129104614, batch loss ss: 0.08389724791049957, batch loss polya: 0.0003518439189065248\n",
      "batch loss 0.07258393615484238, batch loss prom: 0.05177056044340134, batch loss ss: 0.020218702033162117, batch loss polya: 0.0005946775199845433\n",
      "batch loss 0.0027360948733985424, batch loss prom: 0.0010238410905003548, batch loss ss: 0.0010807631770148873, batch loss polya: 0.0006314906058833003\n",
      "batch loss 0.002775682369247079, batch loss prom: 0.0009124883217737079, batch loss ss: 0.0010470629204064608, batch loss polya: 0.000816131301689893\n",
      "batch loss 0.2426254004240036, batch loss prom: 0.027708858251571655, batch loss ss: 0.21283160150051117, batch loss polya: 0.0020849411375820637\n",
      "batch loss 0.48090657591819763, batch loss prom: 0.4495033621788025, batch loss ss: 0.030719060450792313, batch loss polya: 0.0006841464783065021\n",
      "batch loss 4.119447708129883, batch loss prom: 0.40043726563453674, batch loss ss: 3.7188730239868164, batch loss polya: 0.00013743886665906757\n",
      "batch loss 0.1898648738861084, batch loss prom: 0.007594285998493433, batch loss ss: 0.18221122026443481, batch loss polya: 5.936446541454643e-05\n",
      "batch loss 0.5378739833831787, batch loss prom: 0.04292397201061249, batch loss ss: 0.49490779638290405, batch loss polya: 4.2199197196168825e-05\n",
      "batch loss 0.8977104425430298, batch loss prom: 0.031876616179943085, batch loss ss: 0.8657516837120056, batch loss polya: 8.21318244561553e-05\n",
      "batch loss 0.8143465518951416, batch loss prom: 0.7960658669471741, batch loss ss: 0.017688969150185585, batch loss polya: 0.0005916990339756012\n",
      "batch loss 0.9686364531517029, batch loss prom: 0.8962692022323608, batch loss ss: 0.07231072336435318, batch loss polya: 5.6503606174374e-05\n",
      "batch loss 0.6345536708831787, batch loss prom: 0.037016890943050385, batch loss ss: 0.5975044965744019, batch loss polya: 3.2305197237292305e-05\n",
      "batch loss 2.634188175201416, batch loss prom: 0.039608146995306015, batch loss ss: 2.5944771766662598, batch loss polya: 0.00010287232726113871\n",
      "batch loss 0.0028168626595288515, batch loss prom: 0.001142206834629178, batch loss ss: 0.0011969790793955326, batch loss polya: 0.0004776767164003104\n",
      "batch loss 0.8954076766967773, batch loss prom: 0.8398164510726929, batch loss ss: 0.05527763068675995, batch loss polya: 0.0003135904553346336\n",
      "batch loss 0.05445922538638115, batch loss prom: 0.017442872747778893, batch loss ss: 0.007887172512710094, batch loss polya: 0.029129181057214737\n",
      "batch loss 2.3869009017944336, batch loss prom: 2.0993781089782715, batch loss ss: 0.28750738501548767, batch loss polya: 1.549708758830093e-05\n",
      "batch loss 0.7863801717758179, batch loss prom: 0.6728484034538269, batch loss ss: 0.11341032385826111, batch loss polya: 0.00012146688823122531\n",
      "batch loss 0.21965590119361877, batch loss prom: 0.03618207201361656, batch loss ss: 0.18335223197937012, batch loss polya: 0.00012158608296886086\n",
      "batch loss 0.24349841475486755, batch loss prom: 0.11211350560188293, batch loss ss: 0.13136082887649536, batch loss polya: 2.407998726994265e-05\n",
      "batch loss 1.0492515563964844, batch loss prom: 0.03952358290553093, batch loss ss: 1.0096834897994995, batch loss polya: 4.446407547220588e-05\n",
      "batch loss 0.0033168471418321133, batch loss prom: 0.0014631766825914383, batch loss ss: 0.0012846082681789994, batch loss polya: 0.0005690624238923192\n",
      "batch loss 0.305919349193573, batch loss prom: 0.03139973059296608, batch loss ss: 0.2744951844215393, batch loss polya: 2.4437606043647975e-05\n",
      "batch loss 1.163964867591858, batch loss prom: 0.3668437898159027, batch loss ss: 0.7971002459526062, batch loss polya: 2.0861407392658293e-05\n",
      "batch loss 3.422353506088257, batch loss prom: 3.3607616424560547, batch loss ss: 0.061578962951898575, batch loss polya: 1.2874520507466514e-05\n",
      "batch loss 0.007059301715344191, batch loss prom: 0.002920412225648761, batch loss ss: 0.003015853464603424, batch loss polya: 0.001123035908676684\n",
      "batch loss 1.3557614088058472, batch loss prom: 0.039244748651981354, batch loss ss: 1.3164832592010498, batch loss polya: 3.3378044463461265e-05\n",
      "batch loss 0.9426931142807007, batch loss prom: 0.8971014618873596, batch loss ss: 0.04549223929643631, batch loss polya: 9.941560711013153e-05\n",
      "batch loss 0.9492465257644653, batch loss prom: 0.9215119481086731, batch loss ss: 0.026908472180366516, batch loss polya: 0.0008261366747319698\n",
      "batch loss 1.044216513633728, batch loss prom: 1.007587194442749, batch loss ss: 0.036476705223321915, batch loss polya: 0.0001525762490928173\n",
      "batch loss 0.12743379175662994, batch loss prom: 0.09422990679740906, batch loss ss: 0.03314666450023651, batch loss polya: 5.721882189391181e-05\n",
      "batch loss 0.005153540056198835, batch loss prom: 0.001166259404271841, batch loss ss: 0.003183774882927537, batch loss polya: 0.000803505361545831\n",
      "batch loss 0.39786848425865173, batch loss prom: 0.1012168824672699, batch loss ss: 0.29656827449798584, batch loss polya: 8.332382276421413e-05\n",
      "batch loss 0.003257252275943756, batch loss prom: 0.0010492063593119383, batch loss ss: 0.001503528794273734, batch loss polya: 0.0007045170641504228\n",
      "batch loss 0.1255026012659073, batch loss prom: 0.025309262797236443, batch loss ss: 0.10014791786670685, batch loss polya: 4.541770613286644e-05\n",
      "batch loss 0.09625327587127686, batch loss prom: 0.023067697882652283, batch loss ss: 0.0731218010187149, batch loss polya: 6.3774932641536e-05\n",
      "batch loss 0.5996328592300415, batch loss prom: 0.03417619690299034, batch loss ss: 0.5654240250587463, batch loss polya: 3.266281055402942e-05\n",
      "batch loss 0.43000614643096924, batch loss prom: 0.38177186250686646, batch loss ss: 0.04698479548096657, batch loss polya: 0.0012494861148297787\n",
      "batch loss 4.257650852203369, batch loss prom: 1.1384673118591309, batch loss ss: 3.1189255714416504, batch loss polya: 0.00025781645672395825\n",
      "batch loss 0.2555500566959381, batch loss prom: 0.0038486472330987453, batch loss ss: 0.2516482472419739, batch loss polya: 5.3165931603871286e-05\n",
      "batch loss 1.8493322134017944, batch loss prom: 0.02012033201754093, batch loss ss: 1.8291977643966675, batch loss polya: 1.4066597032069694e-05\n",
      "batch loss 0.10558928549289703, batch loss prom: 0.016758611425757408, batch loss ss: 0.08871552348136902, batch loss polya: 0.00011514954530866817\n",
      "batch loss 0.0035766270011663437, batch loss prom: 0.0010350352386012673, batch loss ss: 0.0017625049222260714, batch loss polya: 0.0007790867821313441\n",
      "batch loss 0.3256644606590271, batch loss prom: 0.06603144854307175, batch loss ss: 0.2586066722869873, batch loss polya: 0.001026341924443841\n",
      "batch loss 0.748289167881012, batch loss prom: 0.03269634395837784, batch loss ss: 0.7155471444129944, batch loss polya: 4.565611743601039e-05\n",
      "batch loss 0.3001776933670044, batch loss prom: 0.002261582762002945, batch loss ss: 0.29785043001174927, batch loss polya: 6.568216485902667e-05\n",
      "batch loss 0.2890751361846924, batch loss prom: 0.00686619384214282, batch loss ss: 0.2822008430957794, batch loss polya: 8.106198947643861e-06\n",
      "batch loss 0.18458539247512817, batch loss prom: 0.12000812590122223, batch loss ss: 0.06439226865768433, batch loss polya: 0.00018499570433050394\n",
      "batch loss 0.32035747170448303, batch loss prom: 0.20034857094287872, batch loss ss: 0.11995991319417953, batch loss polya: 4.8993817472364753e-05\n",
      "batch loss 0.4132387638092041, batch loss prom: 0.017680302262306213, batch loss ss: 0.39554402232170105, batch loss polya: 1.4424220353248529e-05\n",
      "batch loss 1.5615699291229248, batch loss prom: 0.124661386013031, batch loss ss: 1.4368077516555786, batch loss polya: 0.00010084597306558862\n",
      "batch loss 0.0031154784373939037, batch loss prom: 0.0008704449282959104, batch loss ss: 0.0015751824248582125, batch loss polya: 0.00066985102603212\n",
      "batch loss 0.32360485196113586, batch loss prom: 0.013474117033183575, batch loss ss: 0.31009331345558167, batch loss polya: 3.7431014789035544e-05\n",
      "batch loss 0.1529521495103836, batch loss prom: 0.02629220299422741, batch loss ss: 0.12655754387378693, batch loss polya: 0.00010239553375868127\n",
      "batch loss 0.8267461061477661, batch loss prom: 0.02783048339188099, batch loss ss: 0.7989076375961304, batch loss polya: 7.986990567587782e-06\n",
      "batch loss 0.6067681908607483, batch loss prom: 0.10383773595094681, batch loss ss: 0.5029214024543762, batch loss polya: 9.059865078597795e-06\n",
      "batch loss 0.2449479103088379, batch loss prom: 0.07648821920156479, batch loss ss: 0.16843882203102112, batch loss polya: 2.0861407392658293e-05\n",
      "batch loss 1.5172861814498901, batch loss prom: 0.012226044200360775, batch loss ss: 1.5050362348556519, batch loss polya: 2.396077979938127e-05\n",
      "batch loss 2.1287474632263184, batch loss prom: 0.1078610047698021, batch loss ss: 2.020857095718384, batch loss polya: 2.9444261599564925e-05\n",
      "batch loss 1.366222858428955, batch loss prom: 0.008771933615207672, batch loss ss: 1.3572882413864136, batch loss polya: 0.0001627074379939586\n",
      "batch loss 0.7400568723678589, batch loss prom: 0.14914751052856445, batch loss ss: 0.5908907651901245, batch loss polya: 1.8596476365928538e-05\n",
      "batch loss 1.116498589515686, batch loss prom: 1.0215516090393066, batch loss ss: 0.09474997967481613, batch loss polya: 0.00019703354337252676\n",
      "batch loss 0.003150380915030837, batch loss prom: 0.0007397775771096349, batch loss ss: 0.0017171651124954224, batch loss polya: 0.0006934384000487626\n",
      "batch loss 0.10374985635280609, batch loss prom: 0.02301737293601036, batch loss ss: 0.08067966997623444, batch loss polya: 5.280832192511298e-05\n",
      "batch loss 0.17200665175914764, batch loss prom: 0.0016847953666001558, batch loss ss: 0.16993866860866547, batch loss polya: 0.0003831844369415194\n",
      "batch loss 0.5842175483703613, batch loss prom: 0.40927785634994507, batch loss ss: 0.1749296933412552, batch loss polya: 1.0013530300057027e-05\n",
      "batch loss 0.0035179380793124437, batch loss prom: 0.0008722314960323274, batch loss ss: 0.0021333571057766676, batch loss polya: 0.0005123494775034487\n",
      "batch loss 4.29905891418457, batch loss prom: 3.6509931087493896, batch loss ss: 0.6480627059936523, batch loss polya: 2.861018856492592e-06\n",
      "batch loss 0.0029103511478751898, batch loss prom: 0.0008336406317539513, batch loss ss: 0.0015549485106021166, batch loss polya: 0.0005217621219344437\n",
      "batch loss 0.5286478996276855, batch loss prom: 0.5019800066947937, batch loss ss: 0.024941792711615562, batch loss polya: 0.0017260904423892498\n",
      "batch loss 0.23248225450515747, batch loss prom: 0.0164041668176651, batch loss ss: 0.2160729616880417, batch loss polya: 5.125986263010418e-06\n",
      "batch loss 0.163084477186203, batch loss prom: 0.14249998331069946, batch loss ss: 0.020505346357822418, batch loss polya: 7.915183232398704e-05\n",
      "batch loss 0.24177385866641998, batch loss prom: 0.18753668665885925, batch loss ss: 0.054194968193769455, batch loss polya: 4.2199197196168825e-05\n",
      "batch loss 1.0092270374298096, batch loss prom: 0.20799674093723297, batch loss ss: 0.801223874092102, batch loss polya: 6.437280717364047e-06\n",
      "batch loss 0.5394848585128784, batch loss prom: 0.1540069729089737, batch loss ss: 0.3854740560054779, batch loss polya: 3.814689989667386e-06\n",
      "batch loss 0.4235919415950775, batch loss prom: 0.008751017972826958, batch loss ss: 0.4148232936859131, batch loss polya: 1.764281842042692e-05\n",
      "batch loss 0.3022240996360779, batch loss prom: 0.06981072574853897, batch loss ss: 0.23240694403648376, batch loss polya: 6.437280717364047e-06\n",
      "batch loss 0.07885416597127914, batch loss prom: 0.013365083374083042, batch loss ss: 0.06546786427497864, batch loss polya: 2.1219027985353023e-05\n",
      "batch loss 2.0162346363067627, batch loss prom: 1.8632757663726807, batch loss ss: 0.15292833745479584, batch loss polya: 3.0517112463712692e-05\n",
      "batch loss 0.38047659397125244, batch loss prom: 0.07100032269954681, batch loss ss: 0.3094576895236969, batch loss polya: 1.8596476365928538e-05\n",
      "batch loss 1.3081347942352295, batch loss prom: 0.9738667011260986, batch loss ss: 0.334244966506958, batch loss polya: 2.312633478140924e-05\n",
      "batch loss 1.0015525817871094, batch loss prom: 0.9574892520904541, batch loss ss: 0.04399688169360161, batch loss polya: 6.639736966462806e-05\n",
      "batch loss 0.14112266898155212, batch loss prom: 0.05205588415265083, batch loss ss: 0.0889919176697731, batch loss polya: 7.486063259420916e-05\n",
      "batch loss 0.004388594068586826, batch loss prom: 0.001397348241880536, batch loss ss: 0.0023292573168873787, batch loss polya: 0.0006619884516112506\n",
      "batch loss 1.4698156118392944, batch loss prom: 0.19369961321353912, batch loss ss: 1.2761039733886719, batch loss polya: 1.2040065485052764e-05\n",
      "batch loss 0.003444091882556677, batch loss prom: 0.0015595904551446438, batch loss ss: 0.0010998159414157271, batch loss polya: 0.0007846852531656623\n",
      "batch loss 0.8445001840591431, batch loss prom: 0.7810807824134827, batch loss ss: 0.0630873367190361, batch loss polya: 0.00033206192892976105\n",
      "batch loss 0.9194096922874451, batch loss prom: 0.9010191559791565, batch loss ss: 0.01810547523200512, batch loss polya: 0.0002851079625543207\n",
      "batch loss 0.0031858498696237803, batch loss prom: 0.0012985378270968795, batch loss ss: 0.001212219474837184, batch loss polya: 0.0006750926841050386\n",
      "batch loss 0.0597183033823967, batch loss prom: 0.02129499986767769, batch loss ss: 0.03836429491639137, batch loss polya: 5.900685573578812e-05\n",
      "batch loss 0.5309305191040039, batch loss prom: 0.5021587610244751, batch loss ss: 0.028488442301750183, batch loss polya: 0.0002833203470800072\n",
      "batch loss 2.601226568222046, batch loss prom: 0.05150666832923889, batch loss ss: 2.549689769744873, batch loss polya: 3.0040289857424796e-05\n",
      "batch loss 0.19006696343421936, batch loss prom: 0.08340823650360107, batch loss ss: 0.10662726312875748, batch loss polya: 3.1470757676288486e-05\n",
      "batch loss 1.2271955013275146, batch loss prom: 1.1207139492034912, batch loss ss: 0.10637103021144867, batch loss polya: 0.00011050090688513592\n",
      "batch loss 0.5782190561294556, batch loss prom: 0.527854859828949, batch loss ss: 0.05007482320070267, batch loss polya: 0.00028939827461726964\n",
      "batch loss 0.5328033566474915, batch loss prom: 0.473000168800354, batch loss ss: 0.059794582426548004, batch loss polya: 8.583032467868179e-06\n",
      "batch loss 1.4091657400131226, batch loss prom: 1.1593413352966309, batch loss ss: 0.2497086375951767, batch loss polya: 0.00011574551899684593\n",
      "batch loss 0.4761608839035034, batch loss prom: 0.4293140470981598, batch loss ss: 0.046364277601242065, batch loss polya: 0.0004825619689654559\n",
      "batch loss 1.4249674081802368, batch loss prom: 0.09677637368440628, batch loss ss: 1.328184723854065, batch loss polya: 6.318072337307967e-06\n",
      "batch loss 0.5575829148292542, batch loss prom: 0.5285780429840088, batch loss ss: 0.028411507606506348, batch loss polya: 0.0005933669744990766\n",
      "batch loss 0.0031117594335228205, batch loss prom: 0.0011143434094265103, batch loss ss: 0.0014974582009017467, batch loss polya: 0.0004999579978175461\n",
      "batch loss 0.003495211014524102, batch loss prom: 0.0011257746955379844, batch loss ss: 0.0015207880642265081, batch loss polya: 0.0008486483711749315\n",
      "batch loss 1.1005843877792358, batch loss prom: 0.345866858959198, batch loss ss: 0.7547111511230469, batch loss polya: 6.318072337307967e-06\n",
      "batch loss 0.1938200742006302, batch loss prom: 0.01564948633313179, batch loss ss: 0.17814412713050842, batch loss polya: 2.6464111215318553e-05\n",
      "batch loss 1.9375381469726562, batch loss prom: 0.21022437512874603, batch loss ss: 1.7273014783859253, batch loss polya: 1.2278481335670222e-05\n",
      "batch loss 0.157913476228714, batch loss prom: 0.048728469759225845, batch loss ss: 0.10914923995733261, batch loss polya: 3.576214658096433e-05\n",
      "batch loss 0.5555645823478699, batch loss prom: 0.09081654995679855, batch loss ss: 0.46474170684814453, batch loss polya: 6.318072337307967e-06\n",
      "batch loss 0.16998514533042908, batch loss prom: 0.03698219731450081, batch loss ss: 0.1329628974199295, batch loss polya: 4.005352093372494e-05\n",
      "batch loss 1.1800084114074707, batch loss prom: 0.09813288599252701, batch loss ss: 1.0818723440170288, batch loss polya: 3.2186455882765586e-06\n",
      "batch loss 1.332135558128357, batch loss prom: 1.2783715724945068, batch loss ss: 0.053553033620119095, batch loss polya: 0.0002109781780745834\n",
      "batch loss 0.004014118108898401, batch loss prom: 0.0008299481705762446, batch loss ss: 0.0026814716402441263, batch loss polya: 0.0005026984144933522\n",
      "batch loss 0.1789710521697998, batch loss prom: 0.031267907470464706, batch loss ss: 0.1476888358592987, batch loss polya: 1.4305012882687151e-05\n",
      "batch loss 0.07631842792034149, batch loss prom: 0.016832226887345314, batch loss ss: 0.059437207877635956, batch loss polya: 4.8993817472364753e-05\n",
      "batch loss 0.562836229801178, batch loss prom: 0.45850902795791626, batch loss ss: 0.10431717336177826, batch loss polya: 1.0013530300057027e-05\n",
      "batch loss 0.8001702427864075, batch loss prom: 0.5414841771125793, batch loss ss: 0.2586482763290405, batch loss polya: 3.7788631743751466e-05\n",
      "batch loss 1.6932669878005981, batch loss prom: 0.026807740330696106, batch loss ss: 1.666435718536377, batch loss polya: 2.3483953555114567e-05\n",
      "batch loss 0.678408145904541, batch loss prom: 0.3452600836753845, batch loss ss: 0.33313611149787903, batch loss polya: 1.1920858014491387e-05\n",
      "batch loss 1.0926544666290283, batch loss prom: 0.8993257880210876, batch loss ss: 0.1933080554008484, batch loss polya: 2.062299427052494e-05\n",
      "batch loss 0.14856043457984924, batch loss prom: 0.01685543730854988, batch loss ss: 0.13168974220752716, batch loss polya: 1.5258672647178173e-05\n",
      "batch loss 0.0041276803240180016, batch loss prom: 0.0010679024271667004, batch loss ss: 0.002135260496288538, batch loss polya: 0.0009245174005627632\n",
      "batch loss 0.7807874083518982, batch loss prom: 0.017271587625145912, batch loss ss: 0.7634724378585815, batch loss polya: 4.339123915997334e-05\n",
      "batch loss 0.9046176671981812, batch loss prom: 0.819219708442688, batch loss ss: 0.0853579118847847, batch loss polya: 4.005352093372494e-05\n",
      "batch loss 1.1647884845733643, batch loss prom: 0.14646375179290771, batch loss ss: 1.0183125734329224, batch loss polya: 1.2159273865108844e-05\n",
      "batch loss 0.004578706808388233, batch loss prom: 0.0010939810890704393, batch loss ss: 0.002963082632049918, batch loss polya: 0.0005216429708525538\n",
      "batch loss 0.8416308760643005, batch loss prom: 0.08937355130910873, batch loss ss: 0.7522250413894653, batch loss polya: 3.2305197237292305e-05\n",
      "batch loss 0.004032030235975981, batch loss prom: 0.0008976006065495312, batch loss ss: 0.002472441177815199, batch loss polya: 0.0006619884516112506\n",
      "batch loss 0.06792613118886948, batch loss prom: 0.011760427616536617, batch loss ss: 0.05605901777744293, batch loss polya: 0.00010668662434909493\n",
      "batch loss 1.787851095199585, batch loss prom: 1.6004300117492676, batch loss ss: 0.18740583956241608, batch loss polya: 1.5258672647178173e-05\n",
      "batch loss 0.003672396531328559, batch loss prom: 0.0007227431051433086, batch loss ss: 0.002337939338758588, batch loss polya: 0.0006117141456343234\n",
      "batch loss 0.2937195599079132, batch loss prom: 0.013141566887497902, batch loss ss: 0.28056463599205017, batch loss polya: 1.3351351299206726e-05\n",
      "batch loss 0.1683485358953476, batch loss prom: 0.04111820086836815, batch loss ss: 0.12715010344982147, batch loss polya: 8.022463589441031e-05\n",
      "batch loss 1.1059744358062744, batch loss prom: 0.8723968267440796, batch loss ss: 0.2335129827260971, batch loss polya: 6.460934673668817e-05\n",
      "batch loss 0.0035944879055023193, batch loss prom: 0.000867467257194221, batch loss ss: 0.00217189802788198, batch loss polya: 0.0005551227368414402\n",
      "batch loss 0.0032239225693047047, batch loss prom: 0.001104817260056734, batch loss ss: 0.0014429405564442277, batch loss polya: 0.0006761648692190647\n",
      "batch loss 0.0033283394295722246, batch loss prom: 0.0010175295174121857, batch loss ss: 0.0017840436194092035, batch loss polya: 0.0005267662927508354\n",
      "batch loss 0.19488579034805298, batch loss prom: 0.08401398360729218, batch loss ss: 0.1108643040060997, batch loss polya: 7.510157047363464e-06\n",
      "batch loss 0.8855300545692444, batch loss prom: 0.7839783430099487, batch loss ss: 0.10153874009847641, batch loss polya: 1.2993727978027891e-05\n",
      "batch loss 0.7550192475318909, batch loss prom: 0.7006334066390991, batch loss ss: 0.05428021773695946, batch loss polya: 0.00010561384988250211\n",
      "batch loss 0.01932160183787346, batch loss prom: 0.00283316383138299, batch loss ss: 0.016440637409687042, batch loss polya: 4.7801782784517854e-05\n",
      "batch loss 0.03389037400484085, batch loss prom: 0.007973626255989075, batch loss ss: 0.025897912681102753, batch loss polya: 1.883488948806189e-05\n",
      "batch loss 0.0052865538746118546, batch loss prom: 0.0015374518698081374, batch loss ss: 0.0030573313124477863, batch loss polya: 0.000691770575940609\n",
      "batch loss 0.45722392201423645, batch loss prom: 0.42037615180015564, batch loss ss: 0.036430615931749344, batch loss polya: 0.00041714549297466874\n",
      "batch loss 0.1516132950782776, batch loss prom: 0.0802614763379097, batch loss ss: 0.07096446305513382, batch loss polya: 0.0003873551613651216\n",
      "batch loss 0.003532565198838711, batch loss prom: 0.0009326160652562976, batch loss ss: 0.0020610298961400986, batch loss polya: 0.0005389191792346537\n",
      "batch loss 1.4196892976760864, batch loss prom: 0.1254911571741104, batch loss ss: 1.293992042541504, batch loss polya: 0.0002060916303889826\n",
      "batch loss 0.0037183931563049555, batch loss prom: 0.0009171332349069417, batch loss ss: 0.002368147252127528, batch loss polya: 0.000433112756581977\n",
      "batch loss 0.5658676028251648, batch loss prom: 0.006483709439635277, batch loss ss: 0.5593744516372681, batch loss polya: 9.417489309271332e-06\n",
      "batch loss 0.7846867442131042, batch loss prom: 0.7667090892791748, batch loss ss: 0.017039567232131958, batch loss polya: 0.0009380945703014731\n",
      "batch loss 1.9136061668395996, batch loss prom: 0.1595519483089447, batch loss ss: 1.7540414333343506, batch loss polya: 1.2755313036905136e-05\n",
      "batch loss 0.004606836475431919, batch loss prom: 0.002709886059165001, batch loss ss: 0.0012329365126788616, batch loss polya: 0.0006640136707574129\n",
      "batch loss 0.002697721589356661, batch loss prom: 0.0007027302053757012, batch loss ss: 0.001413061749190092, batch loss polya: 0.0005819296347908676\n",
      "batch loss 0.03947392478585243, batch loss prom: 0.01785280555486679, batch loss ss: 0.020898733288049698, batch loss polya: 0.0007223857101053\n",
      "batch loss 0.11628077924251556, batch loss prom: 0.056509871035814285, batch loss ss: 0.05974157899618149, batch loss polya: 2.932505594799295e-05\n",
      "batch loss 0.25359252095222473, batch loss prom: 0.026687150821089745, batch loss ss: 0.22686995565891266, batch loss polya: 3.540453326422721e-05\n",
      "batch loss 0.7819130420684814, batch loss prom: 0.149146169424057, batch loss ss: 0.6327614784240723, batch loss polya: 5.364403477869928e-06\n",
      "batch loss 0.25941118597984314, batch loss prom: 0.01272981520742178, batch loss ss: 0.24667255580425262, batch loss polya: 8.821448318485636e-06\n",
      "batch loss 0.14579279720783234, batch loss prom: 0.09778106212615967, batch loss ss: 0.047712452709674835, batch loss polya: 0.0002992897352669388\n",
      "batch loss 0.3310762047767639, batch loss prom: 0.19676998257637024, batch loss ss: 0.13428999483585358, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.22793461382389069, batch loss prom: 0.0048507628962397575, batch loss ss: 0.2230623960494995, batch loss polya: 2.1457441107486375e-05\n",
      "batch loss 3.9300694465637207, batch loss prom: 0.6557166576385498, batch loss ss: 3.2742910385131836, batch loss polya: 6.174850568640977e-05\n",
      "batch loss 0.0028915598522871733, batch loss prom: 0.0009897815762087703, batch loss ss: 0.0014559156261384487, batch loss polya: 0.00044586253352463245\n",
      "batch loss 0.5397493839263916, batch loss prom: 0.0018574618734419346, batch loss ss: 0.5378795266151428, batch loss polya: 1.2397689715726301e-05\n",
      "batch loss 0.24682244658470154, batch loss prom: 0.007824248634278774, batch loss ss: 0.238978773355484, batch loss polya: 1.9430925021879375e-05\n",
      "batch loss 0.0030709640122950077, batch loss prom: 0.0007812308613210917, batch loss ss: 0.001671347301453352, batch loss polya: 0.0006183857913129032\n",
      "batch loss 0.08274197578430176, batch loss prom: 0.00589714664965868, batch loss ss: 0.07683612406253815, batch loss polya: 8.702239938429557e-06\n",
      "batch loss 0.9530947804450989, batch loss prom: 0.9076032638549805, batch loss ss: 0.045346539467573166, batch loss polya: 0.00014494798961095512\n",
      "batch loss 0.1325347125530243, batch loss prom: 0.02449706755578518, batch loss ss: 0.10803072899580002, batch loss polya: 6.9141146923357155e-06\n",
      "batch loss 0.4397507905960083, batch loss prom: 0.09079978615045547, batch loss ss: 0.3489399254322052, batch loss polya: 1.1086402082582936e-05\n",
      "batch loss 0.281850665807724, batch loss prom: 0.007202375214546919, batch loss ss: 0.27458903193473816, batch loss polya: 5.924526340095326e-05\n",
      "batch loss 0.0030640591867268085, batch loss prom: 0.0006852186052128673, batch loss ss: 0.0017836865736171603, batch loss polya: 0.0005951540661044419\n",
      "batch loss 0.0033359520602971315, batch loss prom: 0.0006512666586786509, batch loss ss: 0.0019501493079587817, batch loss polya: 0.0007345362100750208\n",
      "batch loss 0.023277301341295242, batch loss prom: 0.002351853996515274, batch loss ss: 0.020869897678494453, batch loss polya: 5.5549986427649856e-05\n",
      "batch loss 0.0027904375456273556, batch loss prom: 0.001100054127164185, batch loss ss: 0.0011973362416028976, batch loss polya: 0.0004930472350679338\n",
      "batch loss 0.3619139492511749, batch loss prom: 0.014844789169728756, batch loss ss: 0.34706464409828186, batch loss polya: 4.529942543740617e-06\n",
      "batch loss 0.9724040627479553, batch loss prom: 0.20406848192214966, batch loss ss: 0.7683079242706299, batch loss polya: 2.7656173188006505e-05\n",
      "batch loss 0.004016507882624865, batch loss prom: 0.001527096494100988, batch loss ss: 0.001434250851161778, batch loss polya: 0.0010551605373620987\n",
      "batch loss 0.1237272173166275, batch loss prom: 0.06996090710163116, batch loss ss: 0.05369776859879494, batch loss polya: 6.854299135738984e-05\n",
      "batch loss 0.015750668942928314, batch loss prom: 0.003034512745216489, batch loss ss: 0.01264165248721838, batch loss polya: 7.450303382938728e-05\n",
      "batch loss 0.039151061326265335, batch loss prom: 0.0019913145806640387, batch loss ss: 0.037138767540454865, batch loss polya: 2.098061486321967e-05\n",
      "batch loss 0.03325677663087845, batch loss prom: 0.004437718074768782, batch loss ss: 0.028782224282622337, batch loss polya: 3.683499380713329e-05\n",
      "batch loss 0.37588492035865784, batch loss prom: 0.010454414412379265, batch loss ss: 0.3654184639453888, batch loss polya: 1.2040065485052764e-05\n",
      "batch loss 0.07730673998594284, batch loss prom: 0.01270933449268341, batch loss ss: 0.06441216915845871, batch loss polya: 0.00018523407925385982\n",
      "batch loss 0.17512701451778412, batch loss prom: 0.023972073569893837, batch loss ss: 0.15114635229110718, batch loss polya: 8.583032467868179e-06\n",
      "batch loss 0.02639065869152546, batch loss prom: 0.0008709213580004871, batch loss ss: 0.025044921785593033, batch loss polya: 0.0004748170613311231\n",
      "batch loss 0.005215117707848549, batch loss prom: 0.0024431876372545958, batch loss ss: 0.0015561387408524752, batch loss polya: 0.0012157914461567998\n",
      "batch loss 0.002738900948315859, batch loss prom: 0.0008535317610949278, batch loss ss: 0.0012737740762531757, batch loss polya: 0.0006115949945524335\n",
      "batch loss 0.019917957484722137, batch loss prom: 0.004201157949864864, batch loss ss: 0.015475312247872353, batch loss polya: 0.00024148885859176517\n",
      "batch loss 0.003123076632618904, batch loss prom: 0.0012040039291605353, batch loss ss: 0.0014384171226993203, batch loss polya: 0.00048065552255138755\n",
      "batch loss 0.06774984300136566, batch loss prom: 0.0023310412652790546, batch loss ss: 0.06540533155202866, batch loss polya: 1.3470558769768104e-05\n",
      "batch loss 2.9447336196899414, batch loss prom: 2.904054641723633, batch loss ss: 0.03830808028578758, batch loss polya: 0.002370882546529174\n",
      "batch loss 1.377540946006775, batch loss prom: 0.05258568376302719, batch loss ss: 1.3249287605285645, batch loss polya: 2.6464111215318553e-05\n",
      "batch loss 0.3034581243991852, batch loss prom: 0.2740634083747864, batch loss ss: 0.02876751311123371, batch loss polya: 0.0006272017490118742\n",
      "batch loss 0.005064787343144417, batch loss prom: 0.0030393856577575207, batch loss ss: 0.0011186301708221436, batch loss polya: 0.0009067714563570917\n",
      "batch loss 0.06587658077478409, batch loss prom: 0.01852274499833584, batch loss ss: 0.047348350286483765, batch loss polya: 5.483612312673358e-06\n",
      "batch loss 0.0027228090912103653, batch loss prom: 0.0009401192655786872, batch loss ss: 0.0012443665182217956, batch loss polya: 0.0005383234238252044\n",
      "batch loss 0.5352624654769897, batch loss prom: 0.5128524899482727, batch loss ss: 0.0214494951069355, batch loss polya: 0.0009604846709407866\n",
      "batch loss 0.0025920693296939135, batch loss prom: 0.0010021670022979379, batch loss ss: 0.0010689741466194391, batch loss polya: 0.0005209281225688756\n",
      "batch loss 0.6862431168556213, batch loss prom: 0.08811556547880173, batch loss ss: 0.5981189608573914, batch loss polya: 8.583032467868179e-06\n",
      "batch loss 0.002882248256355524, batch loss prom: 0.0013705631718039513, batch loss ss: 0.000936189026106149, batch loss polya: 0.0005754960584454238\n",
      "batch loss 0.0028601482044905424, batch loss prom: 0.0007565735140815377, batch loss ss: 0.0016139827203005552, batch loss polya: 0.0004895919119007885\n",
      "batch loss 5.070700168609619, batch loss prom: 5.038324356079102, batch loss ss: 0.03232984617352486, batch loss polya: 4.589452510117553e-05\n",
      "batch loss 0.0023538474924862385, batch loss prom: 0.000715833914000541, batch loss ss: 0.001111366436816752, batch loss polya: 0.0005266471416689456\n",
      "batch loss 0.06924997270107269, batch loss prom: 0.004380037076771259, batch loss ss: 0.06486206501722336, batch loss polya: 7.867782187531702e-06\n",
      "batch loss 0.0028834822587668896, batch loss prom: 0.0011937642702832818, batch loss ss: 0.0011181537993252277, batch loss polya: 0.0005715643637813628\n",
      "-----\n",
      "prom acc: 86.25, prom loss: 0.24274465441703796\n",
      "ss acc: 78.75, ss loss: 0.5950142741203308\n",
      "polya acc: 100.0, polya loss: 0.00030460773268714547\n",
      "-----\n",
      "batch loss 0.6704007387161255, batch loss prom: 0.5096803307533264, batch loss ss: 0.16027644276618958, batch loss polya: 0.00044400058686733246\n",
      "batch loss 0.766613781452179, batch loss prom: 0.008161290548741817, batch loss ss: 0.7584428191184998, batch loss polya: 9.65590606938349e-06\n",
      "batch loss 0.25600117444992065, batch loss prom: 0.050984226167201996, batch loss ss: 0.20499800145626068, batch loss polya: 1.8954096958623268e-05\n",
      "batch loss 0.47588661313056946, batch loss prom: 0.4274432063102722, batch loss ss: 0.04757605865597725, batch loss polya: 0.0008673481643199921\n",
      "batch loss 0.015344304032623768, batch loss prom: 0.0032896471675485373, batch loss ss: 0.01197812706232071, batch loss polya: 7.652943895664066e-05\n",
      "batch loss 0.06890043616294861, batch loss prom: 0.013231802731752396, batch loss ss: 0.0556059330701828, batch loss polya: 6.270212179515511e-05\n",
      "batch loss 0.3052970767021179, batch loss prom: 0.015171372331678867, batch loss ss: 0.29011091589927673, batch loss polya: 1.4781842764932662e-05\n",
      "batch loss 0.2651662230491638, batch loss prom: 0.009543864987790585, batch loss ss: 0.2556149661540985, batch loss polya: 7.390948667307384e-06\n",
      "batch loss 0.02011099085211754, batch loss prom: 0.00842977873980999, batch loss ss: 0.011613264679908752, batch loss polya: 6.794698856538162e-05\n",
      "batch loss 0.21660135686397552, batch loss prom: 0.004826442804187536, batch loss ss: 0.2117585837841034, batch loss polya: 1.6331539882230572e-05\n",
      "batch loss 0.002309717470780015, batch loss prom: 0.0011193446116521955, batch loss ss: 0.0008285188814625144, batch loss polya: 0.0003618539194576442\n",
      "batch loss 0.5621005296707153, batch loss prom: 0.49148377776145935, batch loss ss: 0.06922757625579834, batch loss polya: 0.0013891342096030712\n",
      "batch loss 0.14033390581607819, batch loss prom: 0.11368986964225769, batch loss ss: 0.02658837102353573, batch loss polya: 5.566918844124302e-05\n",
      "batch loss 0.17445018887519836, batch loss prom: 0.018653331324458122, batch loss ss: 0.15577968955039978, batch loss polya: 1.7165990357170813e-05\n",
      "batch loss 0.6441000699996948, batch loss prom: 0.5508669018745422, batch loss ss: 0.09310391545295715, batch loss polya: 0.0001292145170737058\n",
      "batch loss 0.0026106582954525948, batch loss prom: 0.0015960109885782003, batch loss ss: 0.0007154765771701932, batch loss polya: 0.0002991705550812185\n",
      "batch loss 0.7400685548782349, batch loss prom: 0.6838086247444153, batch loss ss: 0.053058791905641556, batch loss polya: 0.0032011240255087614\n",
      "batch loss 0.0802236944437027, batch loss prom: 0.012784897349774837, batch loss ss: 0.06742949783802032, batch loss polya: 9.298280929215252e-06\n",
      "batch loss 0.06028076261281967, batch loss prom: 0.011140760965645313, batch loss ss: 0.04911556467413902, batch loss polya: 2.4437606043647975e-05\n",
      "batch loss 0.0024456526152789593, batch loss prom: 0.001022531185299158, batch loss ss: 0.001167569193057716, batch loss polya: 0.00025555206229910254\n",
      "batch loss 0.02083890326321125, batch loss prom: 0.013236744329333305, batch loss ss: 0.007498452439904213, batch loss polya: 0.0001037067049765028\n",
      "batch loss 0.8717290163040161, batch loss prom: 0.8367725610733032, batch loss ss: 0.03490781784057617, batch loss polya: 4.8636207793606445e-05\n",
      "batch loss 0.005010522902011871, batch loss prom: 0.0037612426094710827, batch loss ss: 0.0006048041977919638, batch loss polya: 0.0006444760947488248\n",
      "batch loss 0.7797167897224426, batch loss prom: 0.009781289845705032, batch loss ss: 0.7699300050735474, batch loss polya: 5.483612312673358e-06\n",
      "batch loss 0.44085973501205444, batch loss prom: 0.39026445150375366, batch loss ss: 0.05048202723264694, batch loss polya: 0.00011324241495458409\n",
      "batch loss 0.19668777287006378, batch loss prom: 0.05529285594820976, batch loss ss: 0.14134448766708374, batch loss polya: 5.0424259825376794e-05\n",
      "batch loss 0.14459823071956635, batch loss prom: 0.07465857267379761, batch loss ss: 0.06992344558238983, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 1.1041209697723389, batch loss prom: 1.0683220624923706, batch loss ss: 0.03574105352163315, batch loss polya: 5.781483559985645e-05\n",
      "batch loss 0.07972384989261627, batch loss prom: 0.005747814662754536, batch loss ss: 0.07393919676542282, batch loss polya: 3.683499380713329e-05\n",
      "batch loss 0.4984630346298218, batch loss prom: 0.46696993708610535, batch loss ss: 0.03135409578680992, batch loss polya: 0.0001389883691444993\n",
      "batch loss 0.1125100776553154, batch loss prom: 0.028303859755396843, batch loss ss: 0.08415042608976364, batch loss polya: 5.578839045483619e-05\n",
      "batch loss 0.49117428064346313, batch loss prom: 0.44472765922546387, batch loss ss: 0.04640991613268852, batch loss polya: 3.671578815556131e-05\n",
      "batch loss 0.14124701917171478, batch loss prom: 0.0028823756147176027, batch loss ss: 0.1383197009563446, batch loss polya: 4.494089080253616e-05\n",
      "batch loss 0.04592365399003029, batch loss prom: 0.009735485538840294, batch loss ss: 0.036119986325502396, batch loss polya: 6.818538531661034e-05\n",
      "batch loss 0.050441768020391464, batch loss prom: 0.008465713821351528, batch loss ss: 0.04192741587758064, batch loss polya: 4.8636207793606445e-05\n",
      "batch loss 0.0027102488093078136, batch loss prom: 0.0016313589876517653, batch loss ss: 0.0006839081761427224, batch loss polya: 0.00039498155820183456\n",
      "batch loss 0.5565207600593567, batch loss prom: 0.5385980606079102, batch loss ss: 0.01765500381588936, batch loss polya: 0.00026770823751576245\n",
      "batch loss 0.06143529713153839, batch loss prom: 0.02634747326374054, batch loss ss: 0.034521978348493576, batch loss polya: 0.0005658455775119364\n",
      "batch loss 0.10039620101451874, batch loss prom: 0.02375289425253868, batch loss ss: 0.07662458717823029, batch loss polya: 1.8715683836489916e-05\n",
      "batch loss 0.02315996214747429, batch loss prom: 0.019058091565966606, batch loss ss: 0.003993157297372818, batch loss polya: 0.00010871296399272978\n",
      "batch loss 0.2312941700220108, batch loss prom: 0.0038579099345952272, batch loss ss: 0.2274002581834793, batch loss polya: 3.6000557884108275e-05\n",
      "batch loss 0.035652145743370056, batch loss prom: 0.007572043687105179, batch loss ss: 0.028032774105668068, batch loss polya: 4.732496745418757e-05\n",
      "batch loss 0.10334218293428421, batch loss prom: 0.058507245033979416, batch loss ss: 0.04481300339102745, batch loss polya: 2.1934269170742482e-05\n",
      "batch loss 0.1232905238866806, batch loss prom: 0.017225069925189018, batch loss ss: 0.106059730052948, batch loss polya: 5.722029527532868e-06\n",
      "batch loss 0.0021366109140217304, batch loss prom: 0.0011069605825468898, batch loss ss: 0.0007447806419804692, batch loss polya: 0.0002848696312867105\n",
      "batch loss 0.5576044917106628, batch loss prom: 0.5042983889579773, batch loss ss: 0.05328475311398506, batch loss polya: 2.13382354559144e-05\n",
      "batch loss 0.06516501307487488, batch loss prom: 0.03149029612541199, batch loss ss: 0.03336875140666962, batch loss polya: 0.00030596344731748104\n",
      "batch loss 0.11737696081399918, batch loss prom: 0.10260234773159027, batch loss ss: 0.014072122052311897, batch loss polya: 0.0007024919614195824\n",
      "batch loss 0.6116839647293091, batch loss prom: 0.3839034140110016, batch loss ss: 0.2277514636516571, batch loss polya: 2.90866428258596e-05\n",
      "batch loss 0.03606673330068588, batch loss prom: 0.022150026634335518, batch loss ss: 0.013900493271648884, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.8094500303268433, batch loss prom: 0.7969980239868164, batch loss ss: 0.011709647253155708, batch loss polya: 0.000742398202419281\n",
      "batch loss 0.0020363591611385345, batch loss prom: 0.0008703258354216814, batch loss ss: 0.0008822362869977951, batch loss polya: 0.00028379703871905804\n",
      "batch loss 0.34739407896995544, batch loss prom: 0.32429954409599304, batch loss ss: 0.02275533601641655, batch loss polya: 0.0003392120997887105\n",
      "batch loss 0.03694017976522446, batch loss prom: 0.0033985970076173544, batch loss ss: 0.03350617736577988, batch loss polya: 3.540453326422721e-05\n",
      "batch loss 0.030377473682165146, batch loss prom: 0.009590504691004753, batch loss ss: 0.020616991445422173, batch loss polya: 0.0001699779968475923\n",
      "batch loss 0.04034007340669632, batch loss prom: 0.004940207581967115, batch loss ss: 0.03535599634051323, batch loss polya: 4.386805812828243e-05\n",
      "batch loss 0.042652226984500885, batch loss prom: 0.019440708681941032, batch loss ss: 0.02317742630839348, batch loss polya: 3.40932747349143e-05\n",
      "batch loss 0.0020420292858034372, batch loss prom: 0.001105769770219922, batch loss ss: 0.0006400682032108307, batch loss polya: 0.0002961912250611931\n",
      "batch loss 0.0019858279265463352, batch loss prom: 0.0009925207123160362, batch loss ss: 0.0007320346776396036, batch loss polya: 0.00026127262390218675\n",
      "batch loss 0.028309671208262444, batch loss prom: 0.014879790134727955, batch loss ss: 0.013368846848607063, batch loss polya: 6.103329360485077e-05\n",
      "batch loss 0.029365362599492073, batch loss prom: 0.004975675139576197, batch loss ss: 0.024268578737974167, batch loss polya: 0.00012110930401831865\n",
      "batch loss 0.4604375958442688, batch loss prom: 0.4331435561180115, batch loss ss: 0.02566184289753437, batch loss polya: 0.0016321921721100807\n",
      "batch loss 0.0019196446519345045, batch loss prom: 0.0008911690674722195, batch loss ss: 0.000704278820194304, batch loss polya: 0.00032419670606032014\n",
      "batch loss 0.2602658271789551, batch loss prom: 0.18392357230186462, batch loss ss: 0.0762513130903244, batch loss polya: 9.095255518332124e-05\n",
      "batch loss 1.4560432434082031, batch loss prom: 1.4381694793701172, batch loss ss: 0.01776205003261566, batch loss polya: 0.00011169286881340668\n",
      "batch loss 0.02716490998864174, batch loss prom: 0.021179579198360443, batch loss ss: 0.004038512706756592, batch loss polya: 0.0019468179671093822\n",
      "batch loss 0.4130137860774994, batch loss prom: 0.39746060967445374, batch loss ss: 0.014740251004695892, batch loss polya: 0.000812915270216763\n",
      "batch loss 0.7573601603507996, batch loss prom: 0.7425398826599121, batch loss ss: 0.013333793729543686, batch loss polya: 0.0014865073608234525\n",
      "batch loss 0.04914090037345886, batch loss prom: 0.02698540687561035, batch loss ss: 0.02214011736214161, batch loss polya: 1.537788011773955e-05\n",
      "batch loss 0.001979865599423647, batch loss prom: 0.001022769371047616, batch loss ss: 0.0006898645660839975, batch loss polya: 0.00026723151677288115\n",
      "batch loss 0.04595759138464928, batch loss prom: 0.010792340151965618, batch loss ss: 0.034789931029081345, batch loss polya: 0.00037531962152570486\n",
      "batch loss 0.03442983329296112, batch loss prom: 0.005844883155077696, batch loss ss: 0.028535597026348114, batch loss polya: 4.935142715112306e-05\n",
      "batch loss 0.5334222316741943, batch loss prom: 0.09727392345666885, batch loss ss: 0.4361412823200226, batch loss polya: 7.033323527139146e-06\n",
      "batch loss 0.0019133004825562239, batch loss prom: 0.000957150012254715, batch loss ss: 0.0006704466650262475, batch loss polya: 0.0002857038634829223\n",
      "batch loss 0.08908123522996902, batch loss prom: 0.003745803376659751, batch loss ss: 0.08531314134597778, batch loss polya: 2.2291887944447808e-05\n",
      "batch loss 0.10159183293581009, batch loss prom: 0.011750530451536179, batch loss ss: 0.08939436823129654, batch loss polya: 0.0004469349514693022\n",
      "batch loss 0.0019136563641950488, batch loss prom: 0.0009380945703014731, batch loss ss: 0.0007057083421386778, batch loss polya: 0.0002698534226510674\n",
      "batch loss 0.002008532639592886, batch loss prom: 0.001148398732766509, batch loss ss: 0.0005511910421773791, batch loss polya: 0.00030894274823367596\n",
      "batch loss 0.006855316925793886, batch loss prom: 0.0018154582940042019, batch loss ss: 0.004147856030613184, batch loss polya: 0.0008920027757994831\n",
      "batch loss 0.8965136408805847, batch loss prom: 0.1285337656736374, batch loss ss: 0.7679774761199951, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.27264559268951416, batch loss prom: 0.25259682536125183, batch loss ss: 0.01980775035917759, batch loss polya: 0.00024101213784888387\n",
      "batch loss 0.05130518600344658, batch loss prom: 0.014193067327141762, batch loss ss: 0.03704893961548805, batch loss polya: 6.317892984952778e-05\n",
      "batch loss 0.09194277971982956, batch loss prom: 0.0028656155336648226, batch loss ss: 0.08903401345014572, batch loss polya: 4.31528314948082e-05\n",
      "batch loss 1.3553850650787354, batch loss prom: 0.021106049418449402, batch loss ss: 1.3342751264572144, batch loss polya: 3.933898824470816e-06\n",
      "batch loss 0.04542303457856178, batch loss prom: 0.01102463435381651, batch loss ss: 0.03434392064809799, batch loss polya: 5.447716102935374e-05\n",
      "batch loss 0.001953571569174528, batch loss prom: 0.0008722314960323274, batch loss ss: 0.0008100565755739808, batch loss polya: 0.0002712835557758808\n",
      "batch loss 0.0018317154608666897, batch loss prom: 0.0008442413527518511, batch loss ss: 0.0007179781678132713, batch loss polya: 0.0002694958820939064\n",
      "batch loss 0.3404116630554199, batch loss prom: 0.04364968091249466, batch loss ss: 0.29675400257110596, batch loss polya: 7.986990567587782e-06\n",
      "batch loss 0.049048587679862976, batch loss prom: 0.015385161153972149, batch loss ss: 0.03358951956033707, batch loss polya: 7.390703103737906e-05\n",
      "batch loss 0.3146696090698242, batch loss prom: 0.28558117151260376, batch loss ss: 0.028148217126727104, batch loss polya: 0.0009402383584529161\n",
      "batch loss 0.6766926050186157, batch loss prom: 0.4705556631088257, batch loss ss: 0.2061070054769516, batch loss polya: 2.992108420585282e-05\n",
      "batch loss 0.0019869201350957155, batch loss prom: 0.0007781338645145297, batch loss ss: 0.0009320206008851528, batch loss polya: 0.000276765669696033\n",
      "batch loss 1.4657062292099, batch loss prom: 1.4558825492858887, batch loss ss: 0.009002807550132275, batch loss polya: 0.0008208957733586431\n",
      "batch loss 0.3504483103752136, batch loss prom: 0.28821152448654175, batch loss ss: 0.06204189732670784, batch loss polya: 0.00019488819816615433\n",
      "batch loss 1.281574010848999, batch loss prom: 1.260131597518921, batch loss ss: 0.02136559970676899, batch loss polya: 7.676783570786938e-05\n",
      "batch loss 0.012599370442330837, batch loss prom: 0.0077395569533109665, batch loss ss: 0.004777801223099232, batch loss polya: 8.201262971851975e-05\n",
      "batch loss 0.42522814869880676, batch loss prom: 0.3947089910507202, batch loss ss: 0.030256079509854317, batch loss polya: 0.00026306029758416116\n",
      "batch loss 0.4361128509044647, batch loss prom: 0.35608023405075073, batch loss ss: 0.07908141613006592, batch loss polya: 0.0009511952521279454\n",
      "batch loss 0.07354764640331268, batch loss prom: 0.007266520522534847, batch loss ss: 0.0662190169095993, batch loss polya: 6.210611172718927e-05\n",
      "batch loss 0.07208642363548279, batch loss prom: 0.011293533258140087, batch loss ss: 0.060743656009435654, batch loss polya: 4.9232225137529895e-05\n",
      "batch loss 0.032689981162548065, batch loss prom: 0.004758699797093868, batch loss ss: 0.027899811044335365, batch loss polya: 3.1470757676288486e-05\n",
      "batch loss 0.0019168856088072062, batch loss prom: 0.0008250646642409265, batch loss ss: 0.0008223251206800342, batch loss polya: 0.0002694958820939064\n",
      "batch loss 0.03610185533761978, batch loss prom: 0.029526714235544205, batch loss ss: 0.006408142391592264, batch loss polya: 0.00016699827392585576\n",
      "batch loss 0.5339915752410889, batch loss prom: 0.5235551595687866, batch loss ss: 0.010384219698607922, batch loss polya: 5.221230458118953e-05\n",
      "batch loss 0.04017068073153496, batch loss prom: 0.010004495270550251, batch loss ss: 0.030124222859740257, batch loss polya: 4.1960789531003684e-05\n",
      "batch loss 0.0020302324555814266, batch loss prom: 0.0010842165211215615, batch loss ss: 0.0006820021662861109, batch loss polya: 0.0002640137099660933\n",
      "batch loss 0.27528074383735657, batch loss prom: 0.26355624198913574, batch loss ss: 0.010200276039540768, batch loss polya: 0.0015242397785186768\n",
      "batch loss 0.0197162926197052, batch loss prom: 0.01539408229291439, batch loss ss: 0.004095738288015127, batch loss polya: 0.000226472009671852\n",
      "batch loss 0.5061578750610352, batch loss prom: 0.4944860637187958, batch loss ss: 0.010483316145837307, batch loss polya: 0.001188525347970426\n",
      "batch loss 0.008036606013774872, batch loss prom: 0.004837119951844215, batch loss ss: 0.0029037713538855314, batch loss polya: 0.00029571453342214227\n",
      "batch loss 0.012278903275728226, batch loss prom: 0.006796812638640404, batch loss ss: 0.0054518114775419235, batch loss polya: 3.0278701160568744e-05\n",
      "batch loss 1.0697640180587769, batch loss prom: 1.0511919260025024, batch loss ss: 0.018504254519939423, batch loss polya: 6.782778655178845e-05\n",
      "batch loss 0.00218013278208673, batch loss prom: 0.0011102947173640132, batch loss ss: 0.0006672301678918302, batch loss polya: 0.00040260792593471706\n",
      "batch loss 0.05947921797633171, batch loss prom: 0.045624248683452606, batch loss ss: 0.013039910234510899, batch loss polya: 0.0008150592911988497\n",
      "batch loss 0.04210696369409561, batch loss prom: 0.03413667902350426, batch loss ss: 0.007853109389543533, batch loss polya: 0.00011717586312443018\n",
      "batch loss 0.8338078856468201, batch loss prom: 0.7976750135421753, batch loss ss: 0.03553594648838043, batch loss polya: 0.0005969410995021462\n",
      "batch loss 0.0019416504073888063, batch loss prom: 0.0008256602450273931, batch loss ss: 0.0008636558777652681, batch loss polya: 0.00025233422638848424\n",
      "batch loss 0.08283817768096924, batch loss prom: 0.0038883094675838947, batch loss ss: 0.07892698049545288, batch loss polya: 2.288792165927589e-05\n",
      "batch loss 0.3924524188041687, batch loss prom: 0.14013533294200897, batch loss ss: 0.25231313705444336, batch loss polya: 3.933898824470816e-06\n",
      "batch loss 0.004201138392090797, batch loss prom: 0.002314985264092684, batch loss ss: 0.0011438739020377398, batch loss polya: 0.000742279109545052\n",
      "batch loss 0.13036873936653137, batch loss prom: 0.004481391981244087, batch loss ss: 0.12588496506214142, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.001763698412105441, batch loss prom: 0.0007873057620599866, batch loss ss: 0.0007133323233574629, batch loss polya: 0.00026306029758416116\n",
      "batch loss 1.6592354774475098, batch loss prom: 1.64443039894104, batch loss ss: 0.01410397607833147, batch loss polya: 0.0007010624394752085\n",
      "batch loss 1.3710687160491943, batch loss prom: 1.3629565238952637, batch loss ss: 0.007748901844024658, batch loss polya: 0.0003634030872490257\n",
      "batch loss 0.00187758170068264, batch loss prom: 0.0008011230966076255, batch loss ss: 0.0008011230966076255, batch loss polya: 0.00027533553657121956\n",
      "batch loss 0.45441433787345886, batch loss prom: 0.4489781856536865, batch loss ss: 0.005012089852243662, batch loss polya: 0.0004240567213855684\n",
      "batch loss 0.0241375844925642, batch loss prom: 0.008109500631690025, batch loss ss: 0.016023553907871246, batch loss polya: 4.529942543740617e-06\n",
      "batch loss 0.3272976875305176, batch loss prom: 0.042410049587488174, batch loss ss: 0.28485867381095886, batch loss polya: 2.8967437174287625e-05\n",
      "batch loss 0.41041967272758484, batch loss prom: 0.3946901261806488, batch loss ss: 0.01572072133421898, batch loss polya: 8.821448318485636e-06\n",
      "batch loss 0.388163685798645, batch loss prom: 0.3850964903831482, batch loss ss: 0.0028183048125356436, batch loss polya: 0.0002488780301064253\n",
      "batch loss 0.0032360220793634653, batch loss prom: 0.0024367659352719784, batch loss ss: 0.0004407388041727245, batch loss polya: 0.00035851728171110153\n",
      "batch loss 0.11076357960700989, batch loss prom: 0.09886682033538818, batch loss ss: 0.011803899891674519, batch loss polya: 9.285972191719338e-05\n",
      "batch loss 0.24853017926216125, batch loss prom: 0.09318167716264725, batch loss ss: 0.00734131271019578, batch loss polya: 0.14800718426704407\n",
      "batch loss 0.047977108508348465, batch loss prom: 0.008157389238476753, batch loss ss: 0.03974998742341995, batch loss polya: 6.97350042173639e-05\n",
      "batch loss 0.37635016441345215, batch loss prom: 0.33362963795661926, batch loss ss: 0.04266401752829552, batch loss polya: 5.6503606174374e-05\n",
      "batch loss 0.0301292072981596, batch loss prom: 0.023289354518055916, batch loss ss: 0.00679586548358202, batch loss polya: 4.3987260141875595e-05\n",
      "batch loss 0.005900742020457983, batch loss prom: 0.002789655700325966, batch loss ss: 0.0030597082804888487, batch loss polya: 5.1377883210079744e-05\n",
      "batch loss 0.3653402030467987, batch loss prom: 0.35876569151878357, batch loss ss: 0.006561639253050089, batch loss polya: 1.2874520507466514e-05\n",
      "batch loss 0.42494887113571167, batch loss prom: 0.41808852553367615, batch loss ss: 0.00621872628107667, batch loss polya: 0.0006416169344447553\n",
      "batch loss 0.06249038875102997, batch loss prom: 0.00346666993573308, batch loss ss: 0.05901048704981804, batch loss polya: 1.3232143828645349e-05\n",
      "batch loss 0.8012348413467407, batch loss prom: 0.7957463264465332, batch loss ss: 0.0054518114775419235, batch loss polya: 3.671578815556131e-05\n",
      "batch loss 0.044422123581171036, batch loss prom: 0.03312152251601219, batch loss ss: 0.011237424798309803, batch loss polya: 6.317892984952778e-05\n",
      "batch loss 0.001754342345520854, batch loss prom: 0.0007060657371766865, batch loss ss: 0.0006404255982488394, batch loss polya: 0.0004078510100953281\n",
      "batch loss 0.0017398000927641988, batch loss prom: 0.0006537684239447117, batch loss ss: 0.0007095203618519008, batch loss polya: 0.00037651124875992537\n",
      "batch loss 0.028498724102973938, batch loss prom: 0.0024221388157457113, batch loss ss: 0.025806255638599396, batch loss polya: 0.0002703301142901182\n",
      "batch loss 0.017724988982081413, batch loss prom: 0.0031241201795637608, batch loss ss: 0.014399544335901737, batch loss polya: 0.00020132421923335642\n",
      "batch loss 0.034343473613262177, batch loss prom: 0.004973065573722124, batch loss ss: 0.029315927997231483, batch loss polya: 5.447716102935374e-05\n",
      "batch loss 0.03036324679851532, batch loss prom: 0.020215081050992012, batch loss ss: 0.010025149211287498, batch loss polya: 0.0001230164198204875\n",
      "batch loss 0.020359395071864128, batch loss prom: 0.0034868652001023293, batch loss ss: 0.016817575320601463, batch loss polya: 5.495397272170521e-05\n",
      "batch loss 0.6490039229393005, batch loss prom: 0.6418527960777283, batch loss ss: 0.007121891248971224, batch loss polya: 2.9205850296420977e-05\n",
      "batch loss 0.043188296258449554, batch loss prom: 0.0016287406906485558, batch loss ss: 0.041453585028648376, batch loss polya: 0.00010597144137136638\n",
      "batch loss 0.02759545110166073, batch loss prom: 0.025775935500860214, batch loss ss: 0.001745249843224883, batch loss polya: 7.426462980220094e-05\n",
      "batch loss 0.02106356993317604, batch loss prom: 0.004054185003042221, batch loss ss: 0.01690126769244671, batch loss polya: 0.0001081169830285944\n",
      "batch loss 0.0018105743220075965, batch loss prom: 0.0005660838796757162, batch loss ss: 0.0007799206068739295, batch loss polya: 0.00046456989366561174\n",
      "batch loss 0.0023931125178933144, batch loss prom: 0.0011807858245447278, batch loss ss: 0.00045813556062057614, batch loss polya: 0.0007541911327280104\n",
      "batch loss 0.0018836194649338722, batch loss prom: 0.0007401349139399827, batch loss ss: 0.0006111184484325349, batch loss polya: 0.0005323661607690156\n",
      "batch loss 0.0020001204684376717, batch loss prom: 0.0007339406292885542, batch loss ss: 0.0004992430913262069, batch loss polya: 0.0007669368060305715\n",
      "batch loss 0.40444210171699524, batch loss prom: 0.3860190808773041, batch loss ss: 0.018418239429593086, batch loss polya: 4.768360213347478e-06\n",
      "batch loss 0.018654048442840576, batch loss prom: 0.0037939015310257673, batch loss ss: 0.014619254507124424, batch loss polya: 0.00024089295766316354\n",
      "batch loss 0.0018035608809441328, batch loss prom: 0.000593962671700865, batch loss ss: 0.000705470098182559, batch loss polya: 0.0005041282274760306\n",
      "batch loss 0.0018357287626713514, batch loss prom: 0.0007211944903247058, batch loss ss: 0.0005352256703190506, batch loss polya: 0.0005793085438199341\n",
      "batch loss 0.0018323934637010098, batch loss prom: 0.000717025191988796, batch loss ss: 0.0005354639724828303, batch loss polya: 0.0005799042410217226\n",
      "batch loss 2.3152918815612793, batch loss prom: 2.312464475631714, batch loss ss: 0.002806179691106081, batch loss polya: 2.13382354559144e-05\n",
      "batch loss 0.026286881417036057, batch loss prom: 0.006365145090967417, batch loss ss: 0.01977035216987133, batch loss polya: 0.00015138434537220746\n",
      "batch loss 0.43963706493377686, batch loss prom: 0.4319275915622711, batch loss ss: 0.007636639289557934, batch loss polya: 7.283422019099817e-05\n",
      "batch loss 0.5931863784790039, batch loss prom: 0.5875698924064636, batch loss ss: 0.00559111125767231, batch loss polya: 2.539125671319198e-05\n",
      "batch loss 0.1743299514055252, batch loss prom: 0.004862270317971706, batch loss ss: 0.16943907737731934, batch loss polya: 2.8609820219571702e-05\n",
      "batch loss 0.0018886022735387087, batch loss prom: 0.0006113567505963147, batch loss ss: 0.0008167268824763596, batch loss polya: 0.0004605186404660344\n",
      "batch loss 0.0020520673133432865, batch loss prom: 0.0008119623525999486, batch loss ss: 0.0005712069687433541, batch loss polya: 0.0006688979919999838\n",
      "batch loss 0.0018946852069348097, batch loss prom: 0.0006573423161171377, batch loss ss: 0.0007746794726699591, batch loss polya: 0.00046266341814771295\n",
      "batch loss 0.004119273275136948, batch loss prom: 0.0025800534058362246, batch loss ss: 0.0014699617167934775, batch loss polya: 6.925819616299123e-05\n",
      "batch loss 0.0018315253546461463, batch loss prom: 0.0006425699684768915, batch loss ss: 0.0008001701789908111, batch loss polya: 0.0003887851198669523\n",
      "batch loss 0.0018752648029476404, batch loss prom: 0.000651147507596761, batch loss ss: 0.0007728926721028984, batch loss polya: 0.00045122456504032016\n",
      "batch loss 0.0018772643525153399, batch loss prom: 0.0006344689172692597, batch loss ss: 0.000849482137709856, batch loss polya: 0.0003933132975362241\n",
      "batch loss 0.0018107014475390315, batch loss prom: 0.0007463291985914111, batch loss ss: 0.0005831210291944444, batch loss polya: 0.0004812512779608369\n",
      "batch loss 0.04968328773975372, batch loss prom: 0.0017408467829227448, batch loss ss: 0.04792110249400139, batch loss polya: 2.13382354559144e-05\n",
      "batch loss 0.03018079698085785, batch loss prom: 0.0033939636778086424, batch loss ss: 0.026734622195363045, batch loss polya: 5.221230458118953e-05\n",
      "batch loss 0.11543799191713333, batch loss prom: 0.008799348957836628, batch loss ss: 0.10663530230522156, batch loss polya: 3.3378546504536644e-06\n",
      "batch loss 0.28608766198158264, batch loss prom: 0.27803918719291687, batch loss ss: 0.007867183536291122, batch loss polya: 0.00018130090029444546\n",
      "batch loss 0.006161650642752647, batch loss prom: 0.004676120821386576, batch loss ss: 0.0014193708775565028, batch loss polya: 6.615896563744172e-05\n",
      "batch loss 0.22925066947937012, batch loss prom: 0.0007594323833473027, batch loss ss: 0.22848300635814667, batch loss polya: 8.22540732769994e-06\n",
      "batch loss 0.02524675987660885, batch loss prom: 0.002080539707094431, batch loss ss: 0.023090645670890808, batch loss polya: 7.557583012385294e-05\n",
      "batch loss 0.016571827232837677, batch loss prom: 0.005055620335042477, batch loss ss: 0.011377218179404736, batch loss polya: 0.0001389883691444993\n",
      "batch loss 0.001928719342686236, batch loss prom: 0.0009253510506823659, batch loss ss: 0.0005552418879233301, batch loss polya: 0.0004481264913920313\n",
      "batch loss 0.0018690580036491156, batch loss prom: 0.0007120219524949789, batch loss ss: 0.0007578838267363608, batch loss polya: 0.00039915222441777587\n",
      "batch loss 0.0017446997808292508, batch loss prom: 0.0006987990345805883, batch loss ss: 0.000603493710514158, batch loss polya: 0.000442407006630674\n",
      "batch loss 0.0024678357876837254, batch loss prom: 0.00116637849714607, batch loss ss: 0.0007116645574569702, batch loss polya: 0.000589792791288346\n",
      "batch loss 0.0017407562118023634, batch loss prom: 0.0007678897818550467, batch loss ss: 0.0005346299149096012, batch loss polya: 0.00043823651503771544\n",
      "batch loss 0.6500197649002075, batch loss prom: 0.6415080428123474, batch loss ss: 0.008423158898949623, batch loss polya: 8.856858039507642e-05\n",
      "batch loss 0.0796407014131546, batch loss prom: 0.001019911258481443, batch loss ss: 0.07856547832489014, batch loss polya: 5.531158240046352e-05\n",
      "batch loss 0.0017774441512301564, batch loss prom: 0.0008088654140010476, batch loss ss: 0.0005086558521725237, batch loss polya: 0.0004599228559527546\n",
      "batch loss 0.0056895241141319275, batch loss prom: 0.0026996617671102285, batch loss ss: 0.002977345371618867, batch loss polya: 1.2516897186287679e-05\n",
      "batch loss 0.01285193394869566, batch loss prom: 0.008541951887309551, batch loss ss: 0.004288524389266968, batch loss polya: 2.1457441107486375e-05\n",
      "batch loss 0.0019226598087698221, batch loss prom: 0.0006700892699882388, batch loss ss: 0.0008407871937379241, batch loss polya: 0.0004117832868359983\n",
      "batch loss 0.49232152104377747, batch loss prom: 0.46876630187034607, batch loss ss: 0.02322937361896038, batch loss polya: 0.00032586511224508286\n",
      "batch loss 0.0017987412866204977, batch loss prom: 0.0008922410197556019, batch loss ss: 0.0004468158003874123, batch loss polya: 0.0004596845537889749\n",
      "batch loss 0.351906955242157, batch loss prom: 0.3160381019115448, batch loss ss: 0.03572472184896469, batch loss polya: 0.00014411364099942148\n",
      "batch loss 0.001860997173935175, batch loss prom: 0.0010143141262233257, batch loss ss: 0.000444551813416183, batch loss polya: 0.0004021312633994967\n",
      "batch loss 0.021982578560709953, batch loss prom: 0.0034499194007366896, batch loss ss: 0.01847687177360058, batch loss polya: 5.578839045483619e-05\n",
      "batch loss 0.01864166557788849, batch loss prom: 0.0031008278019726276, batch loss ss: 0.015470029786229134, batch loss polya: 7.080780778778717e-05\n",
      "batch loss 0.0068134767934679985, batch loss prom: 0.004578582942485809, batch loss ss: 0.0020855360198765993, batch loss polya: 0.00014935807848814875\n",
      "batch loss 0.5189836025238037, batch loss prom: 0.507114052772522, batch loss ss: 0.011610318906605244, batch loss polya: 0.0002592465898487717\n",
      "batch loss 0.0019225883297622204, batch loss prom: 0.0010278901318088174, batch loss ss: 0.0005235493299551308, batch loss polya: 0.0003711488388944417\n",
      "batch loss 0.0017277681035920978, batch loss prom: 0.0007776573766022921, batch loss ss: 0.0004798214649781585, batch loss polya: 0.0004702892620116472\n",
      "batch loss 0.0017998164985328913, batch loss prom: 0.0008823553798720241, batch loss ss: 0.0004980515805073082, batch loss polya: 0.00041940953815355897\n",
      "batch loss 0.0018616407178342342, batch loss prom: 0.0009239218779839575, batch loss ss: 0.0004683827864937484, batch loss polya: 0.0004693360242526978\n",
      "batch loss 0.5530763864517212, batch loss prom: 0.5350879430770874, batch loss ss: 0.017986057326197624, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.2779719829559326, batch loss prom: 0.26183444261550903, batch loss ss: 0.016117166727781296, batch loss polya: 2.038458114839159e-05\n",
      "batch loss 1.9090802669525146, batch loss prom: 1.881628155708313, batch loss ss: 0.02740478701889515, batch loss polya: 4.732496745418757e-05\n",
      "batch loss 0.04729006066918373, batch loss prom: 0.011773504316806793, batch loss ss: 0.035472091287374496, batch loss polya: 4.446407547220588e-05\n",
      "batch loss 0.0016872589476406574, batch loss prom: 0.000754786713514477, batch loss ss: 0.0005287918029353023, batch loss polya: 0.00040368037298321724\n",
      "batch loss 0.016924574971199036, batch loss prom: 0.004665679298341274, batch loss ss: 0.012220391072332859, batch loss polya: 3.85038583772257e-05\n",
      "batch loss 0.0017981836572289467, batch loss prom: 0.0007350126979872584, batch loss ss: 0.0006430465145967901, batch loss polya: 0.00042012447374872863\n",
      "batch loss 0.006594328209757805, batch loss prom: 0.00403376342728734, batch loss ss: 0.0025084717199206352, batch loss polya: 5.209310256759636e-05\n",
      "batch loss 0.03350503742694855, batch loss prom: 0.00408398499712348, batch loss ss: 0.029312223196029663, batch loss polya: 0.00010883215873036534\n",
      "batch loss 0.04172317683696747, batch loss prom: 0.01577376201748848, batch loss ss: 0.02593868412077427, batch loss polya: 1.07287787614041e-05\n",
      "batch loss 0.0017570696072652936, batch loss prom: 0.0007739647408016026, batch loss ss: 0.0005956306122243404, batch loss polya: 0.00038747431244701147\n",
      "batch loss 0.3469400703907013, batch loss prom: 0.33814799785614014, batch loss ss: 0.00873364694416523, batch loss polya: 5.8410845667822286e-05\n",
      "batch loss 0.0022286884486675262, batch loss prom: 0.001364372787065804, batch loss ss: 0.00037496211007237434, batch loss polya: 0.0004893536097370088\n",
      "batch loss 0.0019674240611493587, batch loss prom: 0.0009672730811871588, batch loss ss: 0.0004439560289029032, batch loss polya: 0.0005561950383707881\n",
      "batch loss 0.01039459090679884, batch loss prom: 0.0082395626232028, batch loss ss: 0.0020880342926830053, batch loss polya: 6.69933797325939e-05\n",
      "batch loss 0.08624321222305298, batch loss prom: 0.081940658390522, batch loss ss: 0.004241281189024448, batch loss polya: 6.12716976320371e-05\n",
      "batch loss 0.008562173694372177, batch loss prom: 0.004975912161171436, batch loss ss: 0.003049844177439809, batch loss polya: 0.0005364171229302883\n",
      "batch loss 1.0617154836654663, batch loss prom: 1.0584136247634888, batch loss ss: 0.0032719431910663843, batch loss polya: 2.992108420585282e-05\n",
      "batch loss 0.018405862152576447, batch loss prom: 0.00212395959533751, batch loss ss: 0.016064966097474098, batch loss polya: 0.0002169373765354976\n",
      "batch loss 0.37810274958610535, batch loss prom: 0.052726034075021744, batch loss ss: 0.32536861300468445, batch loss polya: 8.106198947643861e-06\n",
      "batch loss 0.015484877862036228, batch loss prom: 0.002078041434288025, batch loss ss: 0.013246155343949795, batch loss polya: 0.00016068121476564556\n",
      "batch loss 0.0016884475480765104, batch loss prom: 0.0007526425761170685, batch loss ss: 0.0005535738891921937, batch loss polya: 0.00038223114097490907\n",
      "batch loss 0.048269081860780716, batch loss prom: 0.04662065580487251, batch loss ss: 0.001618743408471346, batch loss polya: 2.9682672902708873e-05\n",
      "batch loss 0.027841880917549133, batch loss prom: 0.02429661899805069, batch loss ss: 0.0031443224288523197, batch loss polya: 0.0004009396652691066\n",
      "batch loss 0.004389900714159012, batch loss prom: 0.0018170052208006382, batch loss ss: 0.002436052542179823, batch loss polya: 0.00013684290752280504\n",
      "batch loss 0.22825461626052856, batch loss prom: 0.006947408430278301, batch loss ss: 0.221292182803154, batch loss polya: 1.5020257706055418e-05\n",
      "batch loss 0.0016930908896028996, batch loss prom: 0.0007862337515689433, batch loss ss: 0.0004804172203876078, batch loss polya: 0.000426439888542518\n",
      "batch loss 0.001795436954125762, batch loss prom: 0.0008057684754021466, batch loss ss: 0.00051771110156551, batch loss polya: 0.00047195740626193583\n",
      "batch loss 0.04669699817895889, batch loss prom: 0.0023022594396024942, batch loss ss: 0.04434407502412796, batch loss polya: 5.066266385256313e-05\n",
      "batch loss 0.015200243331491947, batch loss prom: 0.0038615912199020386, batch loss ss: 0.010698345489799976, batch loss polya: 0.0006403064471669495\n",
      "batch loss 0.09517436474561691, batch loss prom: 0.09252995252609253, batch loss ss: 0.002630585338920355, batch loss polya: 1.3828182090946939e-05\n",
      "batch loss 0.6263319253921509, batch loss prom: 0.6199625134468079, batch loss ss: 0.00629359669983387, batch loss polya: 7.581423415103927e-05\n",
      "batch loss 0.002199262147769332, batch loss prom: 0.0012156723532825708, batch loss ss: 0.0005415403284132481, batch loss polya: 0.00044204952428117394\n",
      "batch loss 0.38639670610427856, batch loss prom: 0.3770493268966675, batch loss ss: 0.008918924257159233, batch loss polya: 0.00042846560245379806\n",
      "batch loss 0.0017740902258083224, batch loss prom: 0.0008588915807195008, batch loss ss: 0.0004638549580704421, batch loss polya: 0.00045134371612221\n",
      "batch loss 0.0017247614450752735, batch loss prom: 0.0008546037715859711, batch loss ss: 0.0004363300104159862, batch loss polya: 0.0004338276921771467\n",
      "batch loss 0.3700582981109619, batch loss prom: 0.3642967939376831, batch loss ss: 0.00572991743683815, batch loss polya: 3.158996332786046e-05\n",
      "batch loss 0.024157922714948654, batch loss prom: 0.010105399414896965, batch loss ss: 0.0140503766015172, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 0.0017127509927377105, batch loss prom: 0.0007384672062471509, batch loss ss: 0.0006090931710787117, batch loss polya: 0.0003651905863080174\n",
      "batch loss 0.012617077678442001, batch loss prom: 0.0069295321591198444, batch loss ss: 0.0056764595210552216, batch loss polya: 1.1086402082582936e-05\n",
      "batch loss 0.01776636764407158, batch loss prom: 0.0023889592848718166, batch loss ss: 0.014974800869822502, batch loss polya: 0.00040260792593471706\n",
      "batch loss 0.010734758339822292, batch loss prom: 0.00949273630976677, batch loss ss: 0.001211266964673996, batch loss polya: 3.075552376685664e-05\n",
      "batch loss 0.03770879656076431, batch loss prom: 0.0361018180847168, batch loss ss: 0.001517693279311061, batch loss polya: 8.928377064876258e-05\n",
      "batch loss 0.01918536238372326, batch loss prom: 0.004625573288649321, batch loss ss: 0.014421635307371616, batch loss polya: 0.00013815402053296566\n",
      "batch loss 0.004867184907197952, batch loss prom: 0.0018076046835631132, batch loss ss: 0.003023341065272689, batch loss polya: 3.6238969187252223e-05\n",
      "batch loss 0.002104631857946515, batch loss prom: 0.0012471048394218087, batch loss ss: 0.000417741306591779, batch loss polya: 0.0004397855664137751\n",
      "batch loss 0.08154159784317017, batch loss prom: 0.0005297449533827603, batch loss ss: 0.08093806356191635, batch loss polya: 7.378782902378589e-05\n",
      "batch loss 3.9133682250976562, batch loss prom: 0.009694283828139305, batch loss ss: 3.9036707878112793, batch loss polya: 3.2186455882765586e-06\n",
      "batch loss 1.2028592824935913, batch loss prom: 0.0012660353677347302, batch loss ss: 1.2015354633331299, batch loss polya: 5.781483559985645e-05\n",
      "batch loss 0.21197983622550964, batch loss prom: 0.005322215612977743, batch loss ss: 0.20665523409843445, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.3445107936859131, batch loss prom: 0.32455775141716003, batch loss ss: 0.019862094894051552, batch loss polya: 9.095255518332124e-05\n",
      "batch loss 0.660039484500885, batch loss prom: 0.6514860987663269, batch loss ss: 0.008543606847524643, batch loss polya: 9.775113539944869e-06\n",
      "batch loss 0.1101304218173027, batch loss prom: 0.040770113468170166, batch loss ss: 0.06926661729812622, batch loss polya: 9.369411418447271e-05\n",
      "batch loss 0.017285851761698723, batch loss prom: 0.002884277608245611, batch loss ss: 0.014071298763155937, batch loss polya: 0.0003302744007669389\n",
      "batch loss 0.0016792992828413844, batch loss prom: 0.0005942009738646448, batch loss ss: 0.0006312523037195206, batch loss polya: 0.0004538459761533886\n",
      "batch loss 0.0017917430959641933, batch loss prom: 0.0006239851354621351, batch loss ss: 0.0007650309125892818, batch loss polya: 0.0004027270770166069\n",
      "batch loss 0.020367592573165894, batch loss prom: 0.0024764842819422483, batch loss ss: 0.017824115231633186, batch loss polya: 6.69933797325939e-05\n",
      "batch loss 0.051361244171857834, batch loss prom: 0.016528230160474777, batch loss ss: 0.03482896089553833, batch loss polya: 4.0531076592742465e-06\n",
      "batch loss 0.0016686946619302034, batch loss prom: 0.0006559127941727638, batch loss ss: 0.0005540504935197532, batch loss polya: 0.0004587313160300255\n",
      "batch loss 0.004585369490087032, batch loss prom: 0.0021469180937856436, batch loss ss: 0.002272049430757761, batch loss polya: 0.00016640232934150845\n",
      "batch loss 0.0021051971707493067, batch loss prom: 0.000814582861494273, batch loss ss: 0.000570253818295896, batch loss polya: 0.0007203606073744595\n",
      "batch loss 0.02276485785841942, batch loss prom: 0.0024874242953956127, batch loss ss: 0.020114725455641747, batch loss polya: 0.0001627074379939586\n",
      "batch loss 0.06672777980566025, batch loss prom: 0.018786827102303505, batch loss ss: 0.047932010143995285, batch loss polya: 8.940656698541716e-06\n",
      "batch loss 0.026613475754857063, batch loss prom: 0.002049847040325403, batch loss ss: 0.024442043155431747, batch loss polya: 0.00012158608296886086\n",
      "batch loss 0.017056869342923164, batch loss prom: 0.0026192902587354183, batch loss ss: 0.014070123434066772, batch loss polya: 0.00036745471879839897\n",
      "batch loss 0.001727756578475237, batch loss prom: 0.0005362979718483984, batch loss ss: 0.0007981451926752925, batch loss polya: 0.0003933132975362241\n",
      "batch loss 0.005017692223191261, batch loss prom: 0.002054129960015416, batch loss ss: 0.0028794039972126484, batch loss polya: 8.415821503149346e-05\n",
      "batch loss 0.041513923555612564, batch loss prom: 0.012289750389754772, batch loss ss: 0.029222385957837105, batch loss polya: 1.7881377516459906e-06\n",
      "batch loss 0.030627112835645676, batch loss prom: 0.0014218707801774144, batch loss ss: 0.028949927538633347, batch loss polya: 0.0002553137019276619\n",
      "batch loss 0.009919071570038795, batch loss prom: 0.006449835374951363, batch loss ss: 0.003265170380473137, batch loss polya: 0.0002040654799202457\n",
      "batch loss 0.0017058640951290727, batch loss prom: 0.0006935574929229915, batch loss ss: 0.0005347490659914911, batch loss polya: 0.00047755756531842053\n",
      "batch loss 0.009222482331097126, batch loss prom: 0.00242594419978559, batch loss ss: 0.0066412207670509815, batch loss polya: 0.00015531764074694365\n",
      "batch loss 2.512519598007202, batch loss prom: 0.0013359201839193702, batch loss ss: 2.5111632347106934, batch loss polya: 2.062299427052494e-05\n",
      "batch loss 0.001703600282780826, batch loss prom: 0.0006958208978176117, batch loss ss: 0.0005231918767094612, batch loss polya: 0.00048458753735758364\n",
      "batch loss 0.0015585985966026783, batch loss prom: 0.0006357794045470655, batch loss ss: 0.0005345107638277113, batch loss polya: 0.0003883084573317319\n",
      "batch loss 1.7058534622192383, batch loss prom: 1.6747064590454102, batch loss ss: 0.03111191838979721, batch loss polya: 3.504691630951129e-05\n",
      "batch loss 0.0016869077226147056, batch loss prom: 0.0006065912893973291, batch loss ss: 0.0006946296198293567, batch loss polya: 0.0003856868715956807\n",
      "batch loss 0.0015967206563800573, batch loss prom: 0.0006512666586786509, batch loss ss: 0.0005715643637813628, batch loss polya: 0.0003738896339200437\n",
      "batch loss 0.0407654345035553, batch loss prom: 0.01696913130581379, batch loss ss: 0.023786885663866997, batch loss polya: 9.417489309271332e-06\n",
      "batch loss 0.00904492661356926, batch loss prom: 0.0008509114268235862, batch loss ss: 0.008139061741530895, batch loss polya: 5.495397272170521e-05\n",
      "batch loss 3.8608899116516113, batch loss prom: 0.003734045661985874, batch loss ss: 3.8568360805511475, batch loss polya: 0.0003197873884346336\n",
      "batch loss 0.00786325242370367, batch loss prom: 0.0009248746791854501, batch loss ss: 0.006803680211305618, batch loss polya: 0.00013469743134919554\n",
      "batch loss 0.01621079444885254, batch loss prom: 0.005368933547288179, batch loss ss: 0.010776654817163944, batch loss polya: 6.5205356804654e-05\n",
      "batch loss 0.7085691690444946, batch loss prom: 0.6522291302680969, batch loss ss: 0.056317880749702454, batch loss polya: 2.2172682292875834e-05\n",
      "batch loss 0.001906209741719067, batch loss prom: 0.0008936702506616712, batch loss ss: 0.0005850272136740386, batch loss polya: 0.0004275123355910182\n",
      "batch loss 0.15804708003997803, batch loss prom: 0.06589395552873611, batch loss ss: 0.09212201833724976, batch loss polya: 3.111314072157256e-05\n",
      "batch loss 0.008148953318595886, batch loss prom: 0.002198066795244813, batch loss ss: 0.005839312914758921, batch loss polya: 0.00011157367407577112\n",
      "batch loss 0.008340404368937016, batch loss prom: 0.0016208856832236052, batch loss ss: 0.00666218064725399, batch loss polya: 5.7338023907504976e-05\n",
      "batch loss 0.04123718664050102, batch loss prom: 0.028374776244163513, batch loss ss: 0.012829032726585865, batch loss polya: 3.3378044463461265e-05\n",
      "batch loss 0.006846209056675434, batch loss prom: 0.0024210684932768345, batch loss ss: 0.004314281977713108, batch loss polya: 0.00011085849109804258\n",
      "batch loss 2.1061151027679443, batch loss prom: 0.0014552014181390405, batch loss ss: 2.1046574115753174, batch loss polya: 2.50339189733495e-06\n",
      "batch loss 0.31751886010169983, batch loss prom: 0.3133113384246826, batch loss ss: 0.004101912025362253, batch loss polya: 0.00010561384988250211\n",
      "batch loss 0.001976181287318468, batch loss prom: 0.0008010039455257356, batch loss ss: 0.0006012300727888942, batch loss polya: 0.0005739472107961774\n",
      "batch loss 0.23020878434181213, batch loss prom: 0.17930443584918976, batch loss ss: 0.050817687064409256, batch loss polya: 8.666139910928905e-05\n",
      "batch loss 0.0018435809761285782, batch loss prom: 0.000662822334561497, batch loss ss: 0.000726197671610862, batch loss polya: 0.0004545609117485583\n",
      "batch loss 0.0018821596167981625, batch loss prom: 0.0006548406090587378, batch loss ss: 0.0008155357209034264, batch loss polya: 0.0004117832868359983\n",
      "batch loss 0.04500989243388176, batch loss prom: 0.037706028670072556, batch loss ss: 0.007246165070682764, batch loss polya: 5.769562994828448e-05\n",
      "batch loss 0.0018507076893001795, batch loss prom: 0.0007021345663815737, batch loss ss: 0.0007641970878466964, batch loss polya: 0.0003843760641757399\n",
      "batch loss 0.0019953595474362373, batch loss prom: 0.0007186928996816278, batch loss ss: 0.0007608617888763547, batch loss polya: 0.0005158047424629331\n",
      "batch loss 0.002850934863090515, batch loss prom: 0.0015376898227259517, batch loss ss: 0.0005566716426983476, batch loss polya: 0.0007565735140815377\n",
      "batch loss 0.0700388252735138, batch loss prom: 0.06315448880195618, batch loss ss: 0.0068110208958387375, batch loss polya: 7.331102824537084e-05\n",
      "batch loss 0.20100511610507965, batch loss prom: 0.005482636857777834, batch loss ss: 0.19551734626293182, batch loss polya: 5.125986263010418e-06\n",
      "batch loss 0.02413680963218212, batch loss prom: 0.0030145461205393076, batch loss ss: 0.021094726398587227, batch loss polya: 2.753696753643453e-05\n",
      "batch loss 0.21980221569538116, batch loss prom: 0.006417736876755953, batch loss ss: 0.2133612334728241, batch loss polya: 2.3245540432981215e-05\n",
      "batch loss 0.4722694158554077, batch loss prom: 0.46584922075271606, batch loss ss: 0.006370830815285444, batch loss polya: 4.935142715112306e-05\n",
      "batch loss 0.002061717212200165, batch loss prom: 0.00056429672986269, batch loss ss: 0.0010979106882587075, batch loss polya: 0.0003995097358711064\n",
      "batch loss 0.023726852610707283, batch loss prom: 0.0034824698232114315, batch loss ss: 0.02012816071510315, batch loss polya: 0.00011622230522334576\n",
      "batch loss 0.11249765753746033, batch loss prom: 0.0006725909770466387, batch loss ss: 0.11180825531482697, batch loss polya: 1.680836794548668e-05\n",
      "batch loss 0.24869394302368164, batch loss prom: 0.23303499817848206, batch loss ss: 0.01557073649019003, batch loss polya: 8.821098163025454e-05\n",
      "batch loss 0.32598912715911865, batch loss prom: 0.0008231588872149587, batch loss ss: 0.32515189051628113, batch loss polya: 1.4066597032069694e-05\n",
      "batch loss 0.0020229374058544636, batch loss prom: 0.0009224927052855492, batch loss ss: 0.000726316764485091, batch loss polya: 0.0003741279651876539\n",
      "batch loss 0.015595510601997375, batch loss prom: 0.0023520919494330883, batch loss ss: 0.013236861675977707, batch loss polya: 6.556489552167477e-06\n",
      "batch loss 0.5178748965263367, batch loss prom: 0.0009971652179956436, batch loss ss: 0.5168493390083313, batch loss polya: 2.8371408916427754e-05\n",
      "batch loss 0.3415442705154419, batch loss prom: 0.31163859367370605, batch loss ss: 0.02986346371471882, batch loss polya: 4.2199197196168825e-05\n",
      "batch loss 0.07251500338315964, batch loss prom: 0.005396797321736813, batch loss ss: 0.06709424406290054, batch loss polya: 2.396077979938127e-05\n",
      "batch loss 0.0335240513086319, batch loss prom: 0.005385296419262886, batch loss ss: 0.028133034706115723, batch loss polya: 5.722029527532868e-06\n",
      "batch loss 0.22168292105197906, batch loss prom: 0.1977856457233429, batch loss ss: 0.023731358349323273, batch loss polya: 0.00016592556494288146\n",
      "batch loss 0.0019781074952334166, batch loss prom: 0.0005671561229974031, batch loss ss: 0.0010340826120227575, batch loss polya: 0.0003768687602132559\n",
      "batch loss 0.18025325238704681, batch loss prom: 0.01605159230530262, batch loss ss: 0.16419069468975067, batch loss polya: 1.0967194612021558e-05\n",
      "batch loss 0.6936993598937988, batch loss prom: 0.6769037842750549, batch loss ss: 0.016785338521003723, batch loss polya: 1.0251946150674485e-05\n",
      "batch loss 0.001954729203134775, batch loss prom: 0.0007982643437571824, batch loss ss: 0.0006669919239357114, batch loss polya: 0.0004894727608188987\n",
      "batch loss 0.001904860488139093, batch loss prom: 0.0005760917556472123, batch loss ss: 0.0009684640099294484, batch loss polya: 0.00036030475166626275\n",
      "batch loss 0.0023531788028776646, batch loss prom: 0.0010093123419210315, batch loss ss: 0.0006008726777508855, batch loss polya: 0.0007429938414134085\n",
      "batch loss 0.21801818907260895, batch loss prom: 0.21222282946109772, batch loss ss: 0.005578308366239071, batch loss polya: 0.00021705655672121793\n",
      "batch loss 0.22186076641082764, batch loss prom: 0.21458162367343903, batch loss ss: 0.007168998476117849, batch loss polya: 0.00011014331539627165\n",
      "batch loss 0.2500324547290802, batch loss prom: 0.2425650805234909, batch loss ss: 0.007300012279301882, batch loss polya: 0.00016735584358684719\n",
      "batch loss 0.29616671800613403, batch loss prom: 0.29139435291290283, batch loss ss: 0.004693325143307447, batch loss polya: 7.903263758635148e-05\n",
      "batch loss 0.20793037116527557, batch loss prom: 0.0020874394103884697, batch loss ss: 0.20576520264148712, batch loss polya: 7.772143726469949e-05\n",
      "batch loss 0.0017812582664191723, batch loss prom: 0.0005972985527478158, batch loss ss: 0.000776347063947469, batch loss polya: 0.0004076126788277179\n",
      "batch loss 0.08771218359470367, batch loss prom: 0.053937025368213654, batch loss ss: 0.033773016184568405, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 0.3948228359222412, batch loss prom: 0.3833717703819275, batch loss ss: 0.011071204207837582, batch loss polya: 0.0003798478574026376\n",
      "batch loss 0.28055745363235474, batch loss prom: 0.26731637120246887, batch loss ss: 0.013224862515926361, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.0018865312449634075, batch loss prom: 0.000892121868673712, batch loss ss: 0.0006575806182809174, batch loss polya: 0.00033682872890494764\n",
      "batch loss 0.29494479298591614, batch loss prom: 0.039763618260622025, batch loss ss: 0.25515374541282654, batch loss polya: 2.7417760065873154e-05\n",
      "batch loss 0.0017848138231784105, batch loss prom: 0.0005934861255809665, batch loss ss: 0.0008250646642409265, batch loss polya: 0.000366263062460348\n",
      "batch loss 0.1730322539806366, batch loss prom: 0.16664381325244904, batch loss ss: 0.006221569608896971, batch loss polya: 0.0001668790791882202\n",
      "batch loss 0.0408785380423069, batch loss prom: 0.0033350344747304916, batch loss ss: 0.03747985139489174, batch loss polya: 6.365573790390044e-05\n",
      "batch loss 0.03225485980510712, batch loss prom: 0.006821084767580032, batch loss ss: 0.02539980225265026, batch loss polya: 3.397406908334233e-05\n",
      "batch loss 0.08701186627149582, batch loss prom: 0.0021302644163370132, batch loss ss: 0.08484870195388794, batch loss polya: 3.290122185717337e-05\n",
      "batch loss 0.654101550579071, batch loss prom: 0.000865680689457804, batch loss ss: 0.6532207131385803, batch loss polya: 1.5139465176616795e-05\n",
      "batch loss 0.055208638310432434, batch loss prom: 0.005731102544814348, batch loss ss: 0.049352969974279404, batch loss polya: 0.0001245659514097497\n",
      "batch loss 0.03296786546707153, batch loss prom: 0.023530641570687294, batch loss ss: 0.009426017291843891, batch loss polya: 1.1205610462639015e-05\n",
      "batch loss 0.08139736205339432, batch loss prom: 0.010431528091430664, batch loss ss: 0.07096201926469803, batch loss polya: 3.814689989667386e-06\n",
      "batch loss 0.053684692829847336, batch loss prom: 0.0010838593589141965, batch loss ss: 0.05254349485039711, batch loss polya: 5.7338023907504976e-05\n",
      "batch loss 0.0016572505701333284, batch loss prom: 0.0006211258587427437, batch loss ss: 0.0006294653285294771, batch loss polya: 0.00040665941196493804\n",
      "batch loss 0.506910502910614, batch loss prom: 0.4266444444656372, batch loss ss: 0.0802638977766037, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 0.007935152389109135, batch loss prom: 0.003824540413916111, batch loss ss: 0.004043618217110634, batch loss polya: 6.69933797325939e-05\n",
      "batch loss 1.211011290550232, batch loss prom: 1.0733731985092163, batch loss ss: 0.13760189712047577, batch loss polya: 3.6238969187252223e-05\n",
      "batch loss 0.0020959684625267982, batch loss prom: 0.0011936451774090528, batch loss ss: 0.0005322470096871257, batch loss polya: 0.0003700763627421111\n",
      "batch loss 2.148808717727661, batch loss prom: 2.1450133323669434, batch loss ss: 0.003544597653672099, batch loss polya: 0.00025090406415984035\n",
      "batch loss 0.0016096850158646703, batch loss prom: 0.0005803807871416211, batch loss ss: 0.0007183355046436191, batch loss polya: 0.00031096869497559965\n",
      "batch loss 0.001571816741488874, batch loss prom: 0.0005906267906539142, batch loss ss: 0.0006295844214037061, batch loss polya: 0.0003516055876389146\n",
      "batch loss 0.016913089901208878, batch loss prom: 0.011644018813967705, batch loss ss: 0.004857050254940987, batch loss polya: 0.0004120216181036085\n",
      "batch loss 0.0015725257107988, batch loss prom: 0.0006889115320518613, batch loss ss: 0.0005326044629327953, batch loss polya: 0.0003510097449179739\n",
      "batch loss 0.005850851070135832, batch loss prom: 0.0016395710408687592, batch loss ss: 0.004087071865797043, batch loss polya: 0.00012420836719684303\n",
      "batch loss 1.7066878080368042, batch loss prom: 1.6785808801651, batch loss ss: 0.028098957613110542, batch loss polya: 7.986990567587782e-06\n",
      "batch loss 0.0016200719401240349, batch loss prom: 0.0006482883472926915, batch loss ss: 0.0005992047372274101, batch loss polya: 0.0003725788265001029\n",
      "batch loss 0.37405043840408325, batch loss prom: 0.3703262507915497, batch loss ss: 0.003626320045441389, batch loss polya: 9.786603914108127e-05\n",
      "batch loss 0.32379284501075745, batch loss prom: 0.002061267616227269, batch loss ss: 0.32161450386047363, batch loss polya: 0.00011705666838679463\n",
      "batch loss 0.02174580842256546, batch loss prom: 0.0039366381242871284, batch loss ss: 0.017087381333112717, batch loss polya: 0.0007217901293188334\n",
      "batch loss 0.001557634910568595, batch loss prom: 0.0006358985556289554, batch loss ss: 0.0005862186080776155, batch loss polya: 0.0003355178632773459\n",
      "batch loss 0.001645892160013318, batch loss prom: 0.0008083889842964709, batch loss ss: 0.0004905451205559075, batch loss polya: 0.0003469580551609397\n",
      "batch loss 0.09074991941452026, batch loss prom: 0.025156525894999504, batch loss ss: 0.0655839741230011, batch loss polya: 9.417489309271332e-06\n",
      "batch loss 0.032472070306539536, batch loss prom: 0.0020736397709697485, batch loss ss: 0.030251337215304375, batch loss polya: 0.00014709345123264939\n",
      "batch loss 0.001664983108639717, batch loss prom: 0.0006389960180968046, batch loss ss: 0.0006624649395234883, batch loss polya: 0.00036352223833091557\n",
      "batch loss 0.014101704582571983, batch loss prom: 0.010325347073376179, batch loss ss: 0.0027808588929474354, batch loss polya: 0.0009954979177564383\n",
      "batch loss 0.012629845179617405, batch loss prom: 0.0009257083875127137, batch loss ss: 0.011589344590902328, batch loss polya: 0.0001147919538198039\n",
      "batch loss 0.012092390097677708, batch loss prom: 0.00472180126234889, batch loss ss: 0.007299065589904785, batch loss polya: 7.152301259338856e-05\n",
      "batch loss 0.018324976786971092, batch loss prom: 0.015759563073515892, batch loss ss: 0.0024240415077656507, batch loss polya: 0.00014137222024146467\n",
      "batch loss 0.041925810277462006, batch loss prom: 0.03149434179067612, batch loss ss: 0.010333959944546223, batch loss polya: 9.7508447652217e-05\n",
      "batch loss 0.11548838019371033, batch loss prom: 0.0016513533191755414, batch loss ss: 0.11118456721305847, batch loss polya: 0.0026524621061980724\n",
      "batch loss 0.02106173150241375, batch loss prom: 0.018138840794563293, batch loss ss: 0.0028017812874168158, batch loss polya: 0.00012110930401831865\n",
      "batch loss 0.015811195597052574, batch loss prom: 0.0019234981155022979, batch loss ss: 0.013843591324985027, batch loss polya: 4.410646579344757e-05\n",
      "batch loss 1.6246669292449951, batch loss prom: 1.6206774711608887, batch loss ss: 0.003708392148837447, batch loss polya: 0.0002810560108628124\n",
      "batch loss 0.4894259572029114, batch loss prom: 0.46549850702285767, batch loss ss: 0.02388547919690609, batch loss polya: 4.1960789531003684e-05\n",
      "batch loss 0.0018026870675384998, batch loss prom: 0.0005758534534834325, batch loss ss: 0.0008361419313587248, batch loss polya: 0.0003906917118001729\n",
      "batch loss 0.0016959569184109569, batch loss prom: 0.0007687236065976322, batch loss ss: 0.0004674295778386295, batch loss polya: 0.00045980370487086475\n",
      "batch loss 1.2376697063446045, batch loss prom: 0.0008467426523566246, batch loss ss: 1.2368080615997314, batch loss polya: 1.490105023549404e-05\n",
      "batch loss 0.021608740091323853, batch loss prom: 0.0059081679210066795, batch loss ss: 0.015690678730607033, batch loss polya: 9.894321920000948e-06\n",
      "batch loss 0.029634688049554825, batch loss prom: 0.00702968193218112, batch loss ss: 0.022494981065392494, batch loss polya: 0.00011002412065863609\n",
      "batch loss 0.0037665539421141148, batch loss prom: 0.0017401328077539802, batch loss ss: 0.0018249776912853122, batch loss polya: 0.00020144341397099197\n",
      "batch loss 0.0015158213209360838, batch loss prom: 0.0005409446312114596, batch loss ss: 0.000620768463704735, batch loss polya: 0.0003541081096045673\n",
      "batch loss 0.22959253191947937, batch loss prom: 0.0009915679693222046, batch loss ss: 0.228574737906456, batch loss polya: 2.6225699912174605e-05\n",
      "batch loss 0.10037019848823547, batch loss prom: 0.08860522508621216, batch loss ss: 0.007616409100592136, batch loss polya: 0.004148568492382765\n",
      "batch loss 0.0022334305103868246, batch loss prom: 0.0009740613750182092, batch loss ss: 0.0008247073274105787, batch loss polya: 0.00043466180795803666\n",
      "batch loss 0.0016295671230182052, batch loss prom: 0.0005115154199302197, batch loss ss: 0.0007983834366314113, batch loss polya: 0.0003196682082489133\n",
      "batch loss 0.002307802438735962, batch loss prom: 0.0011797142215073109, batch loss ss: 0.00039414744242094457, batch loss polya: 0.0007339406292885542\n",
      "batch loss 0.019541511312127113, batch loss prom: 0.004696410149335861, batch loss ss: 0.014799804426729679, batch loss polya: 4.5298504119273275e-05\n",
      "batch loss 0.039310112595558167, batch loss prom: 0.002892717020586133, batch loss ss: 0.036398082971572876, batch loss polya: 1.9311717551317997e-05\n",
      "batch loss 0.05838467925786972, batch loss prom: 0.0075484998524188995, batch loss ss: 0.05083105340600014, batch loss polya: 5.125986263010418e-06\n",
      "batch loss 0.04438497871160507, batch loss prom: 0.019640961661934853, batch loss ss: 0.024714570492506027, batch loss polya: 2.9444261599564925e-05\n",
      "batch loss 2.989452600479126, batch loss prom: 0.01458236575126648, batch loss ss: 2.9748666286468506, batch loss polya: 3.576272320060525e-06\n",
      "batch loss 0.1254974603652954, batch loss prom: 0.0874444767832756, batch loss ss: 0.03802890703082085, batch loss polya: 2.407998726994265e-05\n",
      "batch loss 0.008740829303860664, batch loss prom: 0.0017249004449695349, batch loss ss: 0.005040438380092382, batch loss polya: 0.001975491177290678\n",
      "batch loss 0.018715975806117058, batch loss prom: 0.005787164904177189, batch loss ss: 0.012809966690838337, batch loss polya: 0.00011884459672728553\n",
      "batch loss 0.0017433434259146452, batch loss prom: 0.000583597575314343, batch loss ss: 0.0008301864145323634, batch loss polya: 0.0003295593778602779\n",
      "batch loss 0.13683784008026123, batch loss prom: 0.07403241842985153, batch loss ss: 0.06279899179935455, batch loss polya: 6.437280717364047e-06\n",
      "batch loss 0.02141330949962139, batch loss prom: 0.001068616984412074, batch loss ss: 0.019340740516781807, batch loss polya: 0.0010039533954113722\n",
      "batch loss 0.0016622133553028107, batch loss prom: 0.0005538121913559735, batch loss ss: 0.0007932615117169917, batch loss polya: 0.00031513971043750644\n",
      "batch loss 0.6495875716209412, batch loss prom: 0.6102499961853027, batch loss ss: 0.03932899236679077, batch loss polya: 8.583032467868179e-06\n",
      "batch loss 0.001714607235044241, batch loss prom: 0.0005229535745456815, batch loss ss: 0.0008859285153448582, batch loss polya: 0.0003057250869460404\n",
      "batch loss 0.3377799689769745, batch loss prom: 0.060379330068826675, batch loss ss: 0.2773992121219635, batch loss polya: 1.4305104514278355e-06\n",
      "batch loss 0.22496706247329712, batch loss prom: 0.15354004502296448, batch loss ss: 0.07135370373725891, batch loss polya: 7.331102824537084e-05\n",
      "batch loss 0.5923730134963989, batch loss prom: 0.5751878619194031, batch loss ss: 0.01708609238266945, batch loss polya: 9.905801562126726e-05\n",
      "batch loss 1.3900222778320312, batch loss prom: 1.293022871017456, batch loss ss: 0.09690535813570023, batch loss polya: 9.405170567333698e-05\n",
      "batch loss 0.0024984648916870356, batch loss prom: 0.0006014683749526739, batch loss ss: 0.0014705568319186568, batch loss polya: 0.000426439888542518\n",
      "batch loss 0.02730153128504753, batch loss prom: 0.007309360895305872, batch loss ss: 0.01995605044066906, batch loss polya: 3.611976353568025e-05\n",
      "batch loss 0.7114715576171875, batch loss prom: 0.7057406306266785, batch loss ss: 0.005673851817846298, batch loss polya: 5.709961988031864e-05\n",
      "batch loss 0.22106774151325226, batch loss prom: 0.21690809726715088, batch loss ss: 0.0039727347902953625, batch loss polya: 0.00018690270371735096\n",
      "batch loss 0.023369772359728813, batch loss prom: 0.00305317179299891, batch loss ss: 0.02022886648774147, batch loss polya: 8.77341881277971e-05\n",
      "batch loss 0.0703023374080658, batch loss prom: 0.0653635710477829, batch loss ss: 0.004550577607005835, batch loss polya: 0.00038818930624984205\n",
      "batch loss 0.02704126387834549, batch loss prom: 0.012473898939788342, batch loss ss: 0.014564743265509605, batch loss polya: 2.622600959512056e-06\n",
      "batch loss 0.0016594778280705214, batch loss prom: 0.000460876093711704, batch loss ss: 0.0008138681878335774, batch loss polya: 0.0003847335756290704\n",
      "batch loss 0.277608722448349, batch loss prom: 0.0025969373527914286, batch loss ss: 0.27500200271606445, batch loss polya: 9.775113539944869e-06\n",
      "batch loss 0.07083877921104431, batch loss prom: 0.0018473479431122541, batch loss ss: 0.06898916512727737, batch loss polya: 2.264974000354414e-06\n",
      "batch loss 2.017395496368408, batch loss prom: 0.34495803713798523, batch loss ss: 1.6724259853363037, batch loss polya: 1.156323378381785e-05\n",
      "batch loss 0.035081394016742706, batch loss prom: 0.003858859883621335, batch loss ss: 0.031206440180540085, batch loss polya: 1.6093124941107817e-05\n",
      "batch loss 0.20260804891586304, batch loss prom: 0.003819077741354704, batch loss ss: 0.19878658652305603, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.3422369360923767, batch loss prom: 0.004040650092065334, batch loss ss: 0.3351937234401703, batch loss polya: 0.003002542071044445\n",
      "batch loss 0.7430037260055542, batch loss prom: 0.7137432098388672, batch loss ss: 0.0292509812861681, batch loss polya: 9.536697689327411e-06\n",
      "batch loss 0.011118360795080662, batch loss prom: 0.0008621074957773089, batch loss ss: 0.010169949382543564, batch loss polya: 8.630380034446716e-05\n",
      "batch loss 0.00994404498487711, batch loss prom: 0.0015475689433515072, batch loss ss: 0.008349984884262085, batch loss polya: 4.649054244509898e-05\n",
      "batch loss 0.36948519945144653, batch loss prom: 0.0007745603215880692, batch loss ss: 0.36869359016418457, batch loss polya: 1.7046782886609435e-05\n",
      "batch loss 0.863029420375824, batch loss prom: 0.8092639446258545, batch loss ss: 0.05371697247028351, batch loss polya: 4.851700214203447e-05\n",
      "batch loss 0.0017545019509270787, batch loss prom: 0.00047565114800818264, batch loss ss: 0.0009464313625358045, batch loss polya: 0.00033241944038309157\n",
      "batch loss 0.0015180767513811588, batch loss prom: 0.000520570669323206, batch loss ss: 0.0006625840906053782, batch loss polya: 0.0003349220205564052\n",
      "batch loss 0.0021854585502296686, batch loss prom: 0.0004932855372317135, batch loss ss: 0.0013362773461267352, batch loss polya: 0.00035589560866355896\n",
      "batch loss 0.006889944430440664, batch loss prom: 0.0012859179405495524, batch loss ss: 0.005583880003541708, batch loss polya: 2.0146166207268834e-05\n",
      "batch loss 0.08094363659620285, batch loss prom: 0.0020227227360010147, batch loss ss: 0.07890219986438751, batch loss polya: 1.8715683836489916e-05\n",
      "batch loss 0.0016323138261213899, batch loss prom: 0.0004260824352968484, batch loss ss: 0.0008062449633143842, batch loss polya: 0.0003999863693024963\n",
      "batch loss 1.5841357707977295, batch loss prom: 1.5304380655288696, batch loss ss: 0.05369607359170914, batch loss polya: 1.6689286894688848e-06\n",
      "batch loss 0.0016179194208234549, batch loss prom: 0.0006165986997075379, batch loss ss: 0.0006588910473510623, batch loss polya: 0.0003424296446610242\n",
      "batch loss 0.01457846350967884, batch loss prom: 0.011646964587271214, batch loss ss: 0.00292017450556159, batch loss polya: 1.1324817933200393e-05\n",
      "batch loss 0.3871650993824005, batch loss prom: 0.38447093963623047, batch loss ss: 0.0019991667941212654, batch loss polya: 0.0006949870148673654\n",
      "batch loss 0.7378158569335938, batch loss prom: 0.021966835483908653, batch loss ss: 0.7158346176147461, batch loss polya: 1.4424220353248529e-05\n",
      "batch loss 0.0023931425530463457, batch loss prom: 0.000502817565575242, batch loss ss: 0.0014693664852529764, batch loss polya: 0.0004209585895296186\n",
      "batch loss 0.001666697091422975, batch loss prom: 0.0004539651272352785, batch loss ss: 0.0009116546134464443, batch loss polya: 0.0003010773507412523\n",
      "batch loss 0.019598448649048805, batch loss prom: 0.004223950207233429, batch loss ss: 0.015233482234179974, batch loss polya: 0.00014101465058047324\n",
      "batch loss 2.245001792907715, batch loss prom: 0.004082678817212582, batch loss ss: 2.240912914276123, batch loss polya: 6.198863957251888e-06\n",
      "batch loss 0.03672506660223007, batch loss prom: 0.004760360810905695, batch loss ss: 0.03192465007305145, batch loss polya: 4.005352093372494e-05\n",
      "batch loss 0.00164860300719738, batch loss prom: 0.0004503904783632606, batch loss ss: 0.0008783058729022741, batch loss polya: 0.00031990656862035394\n",
      "batch loss 0.1497058868408203, batch loss prom: 0.004600417334586382, batch loss ss: 0.14509044587612152, batch loss polya: 1.5020257706055418e-05\n",
      "batch loss 0.22138163447380066, batch loss prom: 0.20576238632202148, batch loss ss: 0.015283731743693352, batch loss polya: 0.0003355178632773459\n",
      "batch loss 0.1756896823644638, batch loss prom: 0.057656314224004745, batch loss ss: 0.11802693456411362, batch loss polya: 6.437280717364047e-06\n",
      "batch loss 0.05711659416556358, batch loss prom: 0.009427552111446857, batch loss ss: 0.04768165200948715, batch loss polya: 7.390948667307384e-06\n",
      "batch loss 1.5984976291656494, batch loss prom: 0.03665553405880928, batch loss ss: 1.5618324279785156, batch loss polya: 9.65590606938349e-06\n",
      "batch loss 0.1349170058965683, batch loss prom: 0.049253109842538834, batch loss ss: 0.0856625884771347, batch loss polya: 1.311301275563892e-06\n",
      "batch loss 0.008369038812816143, batch loss prom: 0.001209242851473391, batch loss ss: 0.007088630460202694, batch loss polya: 7.116541382856667e-05\n",
      "batch loss 0.0017444391269236803, batch loss prom: 0.0008079125545918941, batch loss ss: 0.0004413345886860043, batch loss polya: 0.0004951919545419514\n",
      "batch loss 0.22247400879859924, batch loss prom: 0.21517857909202576, batch loss ss: 0.007224388420581818, batch loss polya: 7.10462118149735e-05\n",
      "batch loss 0.0021519626025110483, batch loss prom: 0.0010102650849148631, batch loss ss: 0.0006101653561927378, batch loss polya: 0.0005315321614034474\n",
      "batch loss 0.0740426704287529, batch loss prom: 0.01975013129413128, batch loss ss: 0.054285865277051926, batch loss polya: 6.6756979322235566e-06\n",
      "batch loss 0.001999720698222518, batch loss prom: 0.0008817598572932184, batch loss ss: 0.0007290565990842879, batch loss polya: 0.00038890427094884217\n",
      "batch loss 0.001508647226728499, batch loss prom: 0.0007208371534943581, batch loss ss: 0.00048411093303002417, batch loss polya: 0.0003036991402041167\n",
      "batch loss 0.12012399733066559, batch loss prom: 0.01578209176659584, batch loss ss: 0.10433833301067352, batch loss polya: 3.576272320060525e-06\n",
      "batch loss 0.0015939942095428705, batch loss prom: 0.0005975367967039347, batch loss ss: 0.0004409771354403347, batch loss polya: 0.0005554801900871098\n",
      "batch loss 0.8835974335670471, batch loss prom: 0.8815312385559082, batch loss ss: 0.001927543431520462, batch loss polya: 0.00013863079948350787\n",
      "batch loss 0.006727592088282108, batch loss prom: 0.004151061177253723, batch loss ss: 0.0025592453312128782, batch loss polya: 1.728519782773219e-05\n",
      "batch loss 1.6526952981948853, batch loss prom: 1.647618293762207, batch loss ss: 0.004998212214559317, batch loss polya: 7.879423355916515e-05\n",
      "batch loss 0.034165263175964355, batch loss prom: 0.004288761876523495, batch loss ss: 0.029850274324417114, batch loss polya: 2.6225699912174605e-05\n",
      "batch loss 0.027220549061894417, batch loss prom: 0.0015811334596946836, batch loss ss: 0.0256350040435791, batch loss polya: 4.410734163684538e-06\n",
      "batch loss 0.05342985317111015, batch loss prom: 0.011367435567080975, batch loss ss: 0.042042866349220276, batch loss polya: 1.9550132492440753e-05\n",
      "batch loss 0.012534555047750473, batch loss prom: 0.008134331554174423, batch loss ss: 0.00425825547426939, batch loss polya: 0.0001419681793777272\n",
      "batch loss 0.001515216426923871, batch loss prom: 0.0005615564878098667, batch loss ss: 0.0006361367995850742, batch loss polya: 0.0003175231395289302\n",
      "batch loss 0.0014863797696307302, batch loss prom: 0.0004895919119007885, batch loss ss: 0.0006721144891344011, batch loss polya: 0.000324673397699371\n",
      "batch loss 0.6909624934196472, batch loss prom: 0.0010412277188152075, batch loss ss: 0.6899054050445557, batch loss polya: 1.585470999998506e-05\n",
      "batch loss 2.622804641723633, batch loss prom: 0.2438841611146927, batch loss ss: 2.3789172172546387, batch loss polya: 3.3378546504536644e-06\n",
      "batch loss 0.5443204641342163, batch loss prom: 0.5337059497833252, batch loss ss: 0.010556924156844616, batch loss polya: 5.757642793469131e-05\n",
      "batch loss 0.24830693006515503, batch loss prom: 0.2390429824590683, batch loss ss: 0.00919016171246767, batch loss polya: 7.378782902378589e-05\n",
      "batch loss 0.0910583883523941, batch loss prom: 0.00046528480015695095, batch loss ss: 0.09053445607423782, batch loss polya: 5.864924969500862e-05\n",
      "batch loss 0.7435235381126404, batch loss prom: 0.003349886042997241, batch loss ss: 0.740164577960968, batch loss polya: 9.059865078597795e-06\n",
      "batch loss 0.01582993008196354, batch loss prom: 0.010209833271801472, batch loss ss: 0.00558802904561162, batch loss polya: 3.2066785934148356e-05\n",
      "batch loss 0.1709435135126114, batch loss prom: 0.001053731539286673, batch loss ss: 0.169837087392807, batch loss polya: 5.2689116273541003e-05\n",
      "batch loss 0.06457285583019257, batch loss prom: 0.0030953611712902784, batch loss ss: 0.06146843731403351, batch loss polya: 9.059865078597795e-06\n",
      "batch loss 0.3014669418334961, batch loss prom: 0.29574280977249146, batch loss ss: 0.005720197688788176, batch loss polya: 3.933898824470816e-06\n",
      "batch loss 0.009711201302707195, batch loss prom: 0.005119547713547945, batch loss ss: 0.004426443483680487, batch loss polya: 0.0001652104256208986\n",
      "batch loss 0.009305911138653755, batch loss prom: 0.0004260824352968484, batch loss ss: 0.008457320742309093, batch loss polya: 0.00042250767000950873\n",
      "batch loss 0.0054752035066485405, batch loss prom: 0.0021534604020416737, batch loss ss: 0.003166425507515669, batch loss polya: 0.00015531764074694365\n",
      "batch loss 0.03902300074696541, batch loss prom: 0.004216471221297979, batch loss ss: 0.03478233143687248, batch loss polya: 2.4199192921514623e-05\n",
      "batch loss 0.010883287526667118, batch loss prom: 0.0015792291378602386, batch loss ss: 0.009261621162295341, batch loss polya: 4.2437604861333966e-05\n",
      "batch loss 0.026458699256181717, batch loss prom: 0.0024183334317058325, batch loss ss: 0.023987319320440292, batch loss polya: 5.304672595229931e-05\n",
      "batch loss 0.22555428743362427, batch loss prom: 0.1620892435312271, batch loss ss: 0.05270737409591675, batch loss polya: 0.010757667943835258\n",
      "batch loss 0.42871496081352234, batch loss prom: 0.41718941926956177, batch loss ss: 0.01150980219244957, batch loss polya: 1.5735502529423684e-05\n",
      "batch loss 0.0013933267910033464, batch loss prom: 0.0004003438516519964, batch loss ss: 0.0006462631281465292, batch loss polya: 0.00034671969478949904\n",
      "batch loss 0.02515706978738308, batch loss prom: 0.002661735750734806, batch loss ss: 0.022421663627028465, batch loss polya: 7.366862701019272e-05\n",
      "batch loss 0.6189626455307007, batch loss prom: 0.6049538850784302, batch loss ss: 0.014002063311636448, batch loss polya: 6.6756979322235566e-06\n",
      "batch loss 0.04176749289035797, batch loss prom: 0.0013183006085455418, batch loss ss: 0.04038744419813156, batch loss polya: 6.174850568640977e-05\n",
      "batch loss 0.008319268934428692, batch loss prom: 0.004959780257195234, batch loss ss: 0.0025850471574813128, batch loss polya: 0.0007744412287138402\n",
      "batch loss 0.3527238667011261, batch loss prom: 0.0005983707960695028, batch loss ss: 0.3520502746105194, batch loss polya: 7.521823135903105e-05\n",
      "batch loss 0.7194518446922302, batch loss prom: 0.0010206258157268167, batch loss ss: 0.7184264659881592, batch loss polya: 4.768360213347478e-06\n",
      "batch loss 0.008864814415574074, batch loss prom: 0.0008424547268077731, batch loss ss: 0.008006147108972073, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.00831111054867506, batch loss prom: 0.0016449266113340855, batch loss ss: 0.006633759941905737, batch loss polya: 3.242440288886428e-05\n",
      "batch loss 0.6720969080924988, batch loss prom: 0.005668399389833212, batch loss ss: 0.6664276719093323, batch loss polya: 8.344646857949556e-07\n",
      "batch loss 0.044651445001363754, batch loss prom: 0.009691095910966396, batch loss ss: 0.03494926169514656, batch loss polya: 1.1086402082582936e-05\n",
      "batch loss 0.020712988451123238, batch loss prom: 0.004853847436606884, batch loss ss: 0.015802040696144104, batch loss polya: 5.709961988031864e-05\n",
      "batch loss 0.0013643737183883786, batch loss prom: 0.0004011779965367168, batch loss ss: 0.0006289887824095786, batch loss polya: 0.00033420699764974415\n",
      "batch loss 0.0017068355809897184, batch loss prom: 0.000416907190810889, batch loss ss: 0.000954768096562475, batch loss polya: 0.0003351603518240154\n",
      "batch loss 0.005404871888458729, batch loss prom: 0.0018691227305680513, batch loss ss: 0.003047229489311576, batch loss polya: 0.0004885195521637797\n",
      "batch loss 0.13617977499961853, batch loss prom: 0.06251604110002518, batch loss ss: 0.07365883886814117, batch loss polya: 4.887569048150908e-06\n",
      "batch loss 0.0019335912074893713, batch loss prom: 0.0009496469865553081, batch loss ss: 0.0004175029753241688, batch loss polya: 0.0005664412747137249\n",
      "batch loss 0.7483446598052979, batch loss prom: 0.7179760932922363, batch loss ss: 0.030346402898430824, batch loss polya: 2.2172682292875834e-05\n",
      "batch loss 0.029332663863897324, batch loss prom: 0.002639264799654484, batch loss ss: 0.026663240045309067, batch loss polya: 3.015949550899677e-05\n",
      "batch loss 0.001356523483991623, batch loss prom: 0.00044550508027896285, batch loss ss: 0.0005555993411689997, batch loss polya: 0.0003554189461283386\n",
      "batch loss 0.28530943393707275, batch loss prom: 0.2818623185157776, batch loss ss: 0.0033611729741096497, batch loss polya: 8.594620157964528e-05\n",
      "batch loss 0.6150282621383667, batch loss prom: 0.6088384985923767, batch loss ss: 0.006157593801617622, batch loss polya: 3.218599158572033e-05\n",
      "batch loss 0.024505216628313065, batch loss prom: 0.0031749813351780176, batch loss ss: 0.021208172664046288, batch loss polya: 0.00012206286191940308\n",
      "batch loss 0.4592784345149994, batch loss prom: 0.028651446104049683, batch loss ss: 0.4305543899536133, batch loss polya: 7.259582343976945e-05\n",
      "batch loss 5.902059078216553, batch loss prom: 5.869510173797607, batch loss ss: 0.03254253789782524, batch loss polya: 6.318072337307967e-06\n",
      "batch loss 0.0013972606975585222, batch loss prom: 0.00048780461656861007, batch loss ss: 0.0006070678355172276, batch loss polya: 0.0003023882454726845\n",
      "batch loss 0.03621778264641762, batch loss prom: 0.0030425945296883583, batch loss ss: 0.0331704206764698, batch loss polya: 4.768360213347478e-06\n",
      "batch loss 0.027061935514211655, batch loss prom: 0.006287555210292339, batch loss ss: 0.020757930353283882, batch loss polya: 1.645074735279195e-05\n",
      "batch loss 0.025538142770528793, batch loss prom: 0.00785169005393982, batch loss ss: 0.017622677609324455, batch loss polya: 6.3774932641536e-05\n",
      "batch loss 0.025243278592824936, batch loss prom: 0.0008836655179038644, batch loss ss: 0.010142453946173191, batch loss polya: 0.01421715971082449\n",
      "batch loss 0.020461322739720345, batch loss prom: 0.0027708730194717646, batch loss ss: 0.017496991902589798, batch loss polya: 0.0001934579631779343\n",
      "batch loss 0.23262786865234375, batch loss prom: 0.2177327573299408, batch loss ss: 0.014811667613685131, batch loss polya: 8.34430247778073e-05\n",
      "batch loss 0.020691603422164917, batch loss prom: 0.005258182529360056, batch loss ss: 0.01539408229291439, batch loss polya: 3.93382906622719e-05\n",
      "batch loss 1.8252977132797241, batch loss prom: 1.8195730447769165, batch loss ss: 0.005620865151286125, batch loss polya: 0.00010382589971413836\n",
      "batch loss 0.023573530837893486, batch loss prom: 0.005358499474823475, batch loss ss: 0.018105125054717064, batch loss polya: 0.00010990492592100054\n",
      "batch loss 0.06497972458600998, batch loss prom: 0.0019396792631596327, batch loss ss: 0.06297877430915833, batch loss polya: 6.12716976320371e-05\n",
      "batch loss 0.004829793237149715, batch loss prom: 0.0022888195235282183, batch loss ss: 0.002476959954947233, batch loss polya: 6.401333666872233e-05\n",
      "batch loss 0.032272130250930786, batch loss prom: 0.008756926283240318, batch loss ss: 0.023513060063123703, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 1.3287254571914673, batch loss prom: 1.3224842548370361, batch loss ss: 0.006164584308862686, batch loss polya: 7.664863369427621e-05\n",
      "batch loss 1.4660221338272095, batch loss prom: 1.4604188203811646, batch loss ss: 0.005561474710702896, batch loss polya: 4.184158387943171e-05\n",
      "batch loss 0.0014657900901511312, batch loss prom: 0.0005048430757597089, batch loss ss: 0.0005615564878098667, batch loss polya: 0.00039939055568538606\n",
      "batch loss 0.022495698183774948, batch loss prom: 0.018740030005574226, batch loss ss: 0.0037218127399683, batch loss polya: 3.3854863431770355e-05\n",
      "batch loss 0.0875842422246933, batch loss prom: 0.0034920922480523586, batch loss ss: 0.08408916741609573, batch loss polya: 2.9802276912960224e-06\n",
      "batch loss 2.792274236679077, batch loss prom: 0.0869181901216507, batch loss ss: 2.705352306365967, batch loss polya: 3.814689989667386e-06\n",
      "batch loss 0.0015378608368337154, batch loss prom: 0.0005934861255809665, batch loss ss: 0.0006017066189087927, batch loss polya: 0.0003426679759286344\n",
      "batch loss 0.1474100947380066, batch loss prom: 0.003159176791086793, batch loss ss: 0.14424924552440643, batch loss polya: 1.6689286894688848e-06\n",
      "batch loss 0.4458825886249542, batch loss prom: 0.42935073375701904, batch loss ss: 0.016504662111401558, batch loss polya: 2.7179348762729205e-05\n",
      "batch loss 0.028363659977912903, batch loss prom: 0.008821799419820309, batch loss ss: 0.019449476152658463, batch loss polya: 9.238292841473594e-05\n",
      "batch loss 0.017396850511431694, batch loss prom: 0.004581905901432037, batch loss ss: 0.012756532989442348, batch loss polya: 5.8410845667822286e-05\n",
      "batch loss 0.029916316270828247, batch loss prom: 0.005726005882024765, batch loss ss: 0.024169210344552994, batch loss polya: 2.109982233378105e-05\n",
      "batch loss 0.017742516472935677, batch loss prom: 0.006776092108339071, batch loss ss: 0.010919577442109585, batch loss polya: 4.684815212385729e-05\n",
      "batch loss 0.11741238832473755, batch loss prom: 0.015356048010289669, batch loss ss: 0.10199172794818878, batch loss polya: 6.460934673668817e-05\n",
      "batch loss 0.0018249466083943844, batch loss prom: 0.000713213172275573, batch loss ss: 0.0008027906878851354, batch loss polya: 0.00030894274823367596\n",
      "batch loss 0.0016872768756002188, batch loss prom: 0.0006106419023126364, batch loss ss: 0.0006473353132605553, batch loss polya: 0.0004292996891308576\n",
      "batch loss 0.7498958110809326, batch loss prom: 0.4949662983417511, batch loss ss: 0.25492021441459656, batch loss polya: 9.298280929215252e-06\n",
      "batch loss 0.46119368076324463, batch loss prom: 0.37924978137016296, batch loss ss: 0.08189288526773453, batch loss polya: 5.1020273531321436e-05\n",
      "batch loss 0.002113569527864456, batch loss prom: 0.0006767605082131922, batch loss ss: 0.0010350352386012673, batch loss polya: 0.0004017737810499966\n",
      "batch loss 0.0017881745006889105, batch loss prom: 0.0007271506474353373, batch loss ss: 0.0006528153317049146, batch loss polya: 0.00040820849244482815\n",
      "batch loss 0.21965810656547546, batch loss prom: 0.19222232699394226, batch loss ss: 0.026981692761182785, batch loss polya: 0.00045408427831716835\n",
      "batch loss 0.014678051695227623, batch loss prom: 0.004074486903846264, batch loss ss: 0.01052000280469656, batch loss polya: 8.356221951544285e-05\n",
      "batch loss 0.018227772787213326, batch loss prom: 0.009500411339104176, batch loss ss: 0.00844904687255621, batch loss polya: 0.0002783149539027363\n",
      "batch loss 0.5142092108726501, batch loss prom: 0.26767873764038086, batch loss ss: 0.24646705389022827, batch loss polya: 6.341733387671411e-05\n",
      "batch loss 0.01805758662521839, batch loss prom: 0.005182285793125629, batch loss ss: 0.012818558141589165, batch loss polya: 5.674201020156033e-05\n",
      "batch loss 0.0020235301926732063, batch loss prom: 0.0011893587652593851, batch loss ss: 0.0004337085410952568, batch loss polya: 0.00040046300273388624\n",
      "batch loss 0.03899286687374115, batch loss prom: 0.01622871682047844, batch loss ss: 0.02200566977262497, batch loss polya: 0.0007584794075228274\n",
      "batch loss 0.19998960196971893, batch loss prom: 0.18360595405101776, batch loss ss: 0.015968533232808113, batch loss polya: 0.0004151197790633887\n",
      "batch loss 0.01791735365986824, batch loss prom: 0.007629304192960262, batch loss ss: 0.010004967451095581, batch loss polya: 0.00028308198670856655\n",
      "batch loss 0.020357685163617134, batch loss prom: 0.009665712714195251, batch loss ss: 0.010591603815555573, batch loss polya: 0.0001003691868390888\n",
      "batch loss 0.0016481820493936539, batch loss prom: 0.0005391574813984334, batch loss ss: 0.0007260785205289721, batch loss polya: 0.0003829461056739092\n",
      "batch loss 0.1238246038556099, batch loss prom: 0.0037905762437731028, batch loss ss: 0.1199602335691452, batch loss polya: 7.378782902378589e-05\n",
      "batch loss 0.024671485647559166, batch loss prom: 0.0026336766313761473, batch loss ss: 0.021840179339051247, batch loss polya: 0.00019762947340495884\n",
      "batch loss 0.002209900412708521, batch loss prom: 0.0006799769471399486, batch loss ss: 0.0011368485866114497, batch loss polya: 0.00039307496626861393\n",
      "batch loss 0.0017969855107367039, batch loss prom: 0.0006482883472926915, batch loss ss: 0.0007509748684242368, batch loss polya: 0.00039772229501977563\n",
      "batch loss 1.7336665391921997, batch loss prom: 1.7257689237594604, batch loss ss: 0.00753264594823122, batch loss polya: 0.00036507140612229705\n",
      "batch loss 0.82610684633255, batch loss prom: 0.8186808824539185, batch loss ss: 0.007292556576430798, batch loss polya: 0.0001333863037871197\n",
      "batch loss 0.4853097200393677, batch loss prom: 0.0015509016811847687, batch loss ss: 0.4837402105331421, batch loss polya: 1.8596476365928538e-05\n",
      "batch loss 0.002541124587878585, batch loss prom: 0.0012257928028702736, batch loss ss: 0.00039748396375216544, batch loss polya: 0.0009178477921523154\n",
      "batch loss 0.10559303313493729, batch loss prom: 0.007062944583594799, batch loss ss: 0.0985216274857521, batch loss polya: 8.4638240878121e-06\n",
      "batch loss 0.16599717736244202, batch loss prom: 0.1504477709531784, batch loss ss: 0.015339730307459831, batch loss polya: 0.00020966715237591416\n",
      "batch loss 0.0019394573755562305, batch loss prom: 0.0011127954348921776, batch loss ss: 0.00046623803791590035, batch loss polya: 0.00036042393185198307\n",
      "batch loss 0.02130214497447014, batch loss prom: 0.0034109526313841343, batch loss ss: 0.017806081101298332, batch loss polya: 8.511180931236595e-05\n",
      "batch loss 0.0027486267499625683, batch loss prom: 0.0017270424868911505, batch loss ss: 0.0003805628512054682, batch loss polya: 0.0006410212954506278\n",
      "batch loss 0.017310822382569313, batch loss prom: 0.005993015132844448, batch loss ss: 0.011234006844460964, batch loss polya: 8.380061626667157e-05\n",
      "batch loss 0.0015918300487101078, batch loss prom: 0.0006370898918248713, batch loss ss: 0.0006096888100728393, batch loss polya: 0.00034505134681239724\n",
      "batch loss 0.01812140643596649, batch loss prom: 0.004932734649628401, batch loss ss: 0.013122154399752617, batch loss polya: 6.651657167822123e-05\n",
      "batch loss 0.015186788514256477, batch loss prom: 0.0034522954374551773, batch loss ss: 0.011695154942572117, batch loss polya: 3.93382906622719e-05\n",
      "batch loss 0.0015986055368557572, batch loss prom: 0.0006003961316309869, batch loss ss: 0.0006952252588234842, batch loss polya: 0.00030298411729745567\n",
      "batch loss 0.02393140085041523, batch loss prom: 0.009881153702735901, batch loss ss: 0.014017345383763313, batch loss polya: 3.290122185717337e-05\n",
      "batch loss 0.017654482275247574, batch loss prom: 0.015015081502497196, batch loss ss: 0.002633082214742899, batch loss polya: 6.318072337307967e-06\n",
      "batch loss 0.012790380977094173, batch loss prom: 0.0028225842397660017, batch loss ss: 0.009858844801783562, batch loss polya: 0.00010895135346800089\n",
      "batch loss 0.002597499405965209, batch loss prom: 0.0015686361584812403, batch loss ss: 0.0005922947311773896, batch loss polya: 0.0004365683125797659\n",
      "batch loss 0.040257252752780914, batch loss prom: 0.003012406872585416, batch loss ss: 0.037233639508485794, batch loss polya: 1.1205610462639015e-05\n",
      "batch loss 0.08510344475507736, batch loss prom: 0.011889191344380379, batch loss ss: 0.07318063825368881, batch loss polya: 3.361645576660521e-05\n",
      "batch loss 0.2554780840873718, batch loss prom: 0.20931856334209442, batch loss ss: 0.046157240867614746, batch loss polya: 2.264974000354414e-06\n",
      "batch loss 0.0014471850590780377, batch loss prom: 0.0006363751017488539, batch loss ss: 0.0004857790481764823, batch loss polya: 0.0003250309091527015\n",
      "batch loss 0.031432636082172394, batch loss prom: 0.008347856812179089, batch loss ss: 0.023076433688402176, batch loss polya: 8.34461570775602e-06\n",
      "batch loss 0.025340793654322624, batch loss prom: 0.0030081281438469887, batch loss ss: 0.02213265374302864, batch loss polya: 0.00020001317898277193\n",
      "batch loss 0.01119824405759573, batch loss prom: 0.0019704941660165787, batch loss ss: 0.008891040459275246, batch loss polya: 0.0003367095487192273\n",
      "batch loss 0.02422533929347992, batch loss prom: 0.008268646895885468, batch loss ss: 0.015806499868631363, batch loss polya: 0.0001501924270996824\n",
      "batch loss 0.41132283210754395, batch loss prom: 0.40255358815193176, batch loss ss: 0.00865777675062418, batch loss polya: 0.00011145447206217796\n",
      "batch loss 0.01772015541791916, batch loss prom: 0.0010213402565568686, batch loss ss: 0.016592366620898247, batch loss polya: 0.00010644822759786621\n",
      "batch loss 0.02358066290616989, batch loss prom: 0.0038309532683342695, batch loss ss: 0.019747326150536537, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.026106303557753563, batch loss prom: 0.006834937259554863, batch loss ss: 0.01925479620695114, batch loss polya: 1.6569954823353328e-05\n",
      "batch loss 0.02207796461880207, batch loss prom: 0.006651167757809162, batch loss ss: 0.015413803048431873, batch loss polya: 1.2993727978027891e-05\n",
      "batch loss 0.001432655262760818, batch loss prom: 0.0005975367967039347, batch loss ss: 0.0004991239402443171, batch loss polya: 0.0003359945258125663\n",
      "batch loss 0.0015495395055040717, batch loss prom: 0.0005335576133802533, batch loss ss: 0.0006466205231845379, batch loss polya: 0.0003693613689392805\n",
      "batch loss 0.04172585904598236, batch loss prom: 0.03757423534989357, batch loss ss: 0.004130048677325249, batch loss polya: 2.1576648578047752e-05\n",
      "batch loss 0.06341198831796646, batch loss prom: 0.0020004753023386, batch loss ss: 0.0612884946167469, batch loss polya: 0.0001230164198204875\n",
      "batch loss 0.002278781495988369, batch loss prom: 0.001142087858170271, batch loss ss: 0.000606710382271558, batch loss polya: 0.00052998325554654\n",
      "batch loss 0.0017972703790292144, batch loss prom: 0.0009565545478835702, batch loss ss: 0.000321336614433676, batch loss polya: 0.0005193791585043073\n",
      "batch loss 0.013476605527102947, batch loss prom: 0.004977098666131496, batch loss ss: 0.008315464481711388, batch loss polya: 0.00018404220463708043\n",
      "batch loss 0.012376460246741772, batch loss prom: 0.002393835224211216, batch loss ss: 0.009962478652596474, batch loss polya: 2.0146166207268834e-05\n",
      "batch loss 0.027524447068572044, batch loss prom: 0.0035849844571202993, batch loss ss: 0.023930521681904793, batch loss polya: 8.940656698541716e-06\n",
      "batch loss 0.04014153033494949, batch loss prom: 0.010844227857887745, batch loss ss: 0.02926475927233696, batch loss polya: 3.2543604902457446e-05\n",
      "batch loss 0.031632199883461, batch loss prom: 0.013019906356930733, batch loss ss: 0.01859775185585022, batch loss polya: 1.4543427823809907e-05\n",
      "batch loss 0.0013718887930735946, batch loss prom: 0.0005718026659451425, batch loss ss: 0.0004757702990900725, batch loss polya: 0.00032431588624604046\n",
      "batch loss 0.007151897065341473, batch loss prom: 0.0032943999394774437, batch loss ss: 0.0038412846624851227, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.014383929781615734, batch loss prom: 0.006175365298986435, batch loss ss: 0.007973034866154194, batch loss polya: 0.00023552982020191848\n",
      "batch loss 0.011953230947256088, batch loss prom: 0.006550980266183615, batch loss ss: 0.0053130853921175, batch loss polya: 8.916457591112703e-05\n",
      "batch loss 0.2916887700557709, batch loss prom: 0.0173320434987545, batch loss ss: 0.27432167530059814, batch loss polya: 3.504691630951129e-05\n",
      "batch loss 0.03459569811820984, batch loss prom: 0.002795242937281728, batch loss ss: 0.03179878741502762, batch loss polya: 1.6689286894688848e-06\n",
      "batch loss 0.03130112588405609, batch loss prom: 0.01578209176659584, batch loss ss: 0.015507472679018974, batch loss polya: 1.156323378381785e-05\n",
      "batch loss 0.013986612670123577, batch loss prom: 0.004653101786971092, batch loss ss: 0.009116334840655327, batch loss polya: 0.00021717573690693825\n",
      "batch loss 1.0878530740737915, batch loss prom: 1.0753450393676758, batch loss ss: 0.012481669895350933, batch loss polya: 2.634490556374658e-05\n",
      "batch loss 0.001371287857182324, batch loss prom: 0.0006192197324708104, batch loss ss: 0.00040975757292471826, batch loss polya: 0.00034231049357913435\n",
      "batch loss 0.01027728896588087, batch loss prom: 0.002270027529448271, batch loss ss: 0.007577722892165184, batch loss polya: 0.0004295380203984678\n",
      "batch loss 0.7419649958610535, batch loss prom: 0.7253575325012207, batch loss ss: 0.016573138535022736, batch loss polya: 3.433168603805825e-05\n",
      "batch loss 0.010723778046667576, batch loss prom: 0.0016338583081960678, batch loss ss: 0.008787650614976883, batch loss polya: 0.0003022690652869642\n",
      "batch loss 0.3347074091434479, batch loss prom: 0.3290662467479706, batch loss ss: 0.005486905109137297, batch loss polya: 0.00015424491721205413\n",
      "batch loss 0.462740033864975, batch loss prom: 0.4585726857185364, batch loss ss: 0.004104998894035816, batch loss polya: 6.23445157543756e-05\n",
      "batch loss 0.003308414714410901, batch loss prom: 0.0016218378441408277, batch loss ss: 0.000847933697514236, batch loss polya: 0.0008386432309634984\n",
      "batch loss 0.019920343533158302, batch loss prom: 0.0012460333527997136, batch loss ss: 0.018596231937408447, batch loss polya: 7.807903602952138e-05\n",
      "batch loss 0.025106942281126976, batch loss prom: 0.020101288333535194, batch loss ss: 0.004004080779850483, batch loss polya: 0.001001571537926793\n",
      "batch loss 0.04195950925350189, batch loss prom: 0.0025933701545000076, batch loss ss: 0.03933311626315117, batch loss polya: 3.302042750874534e-05\n",
      "batch loss 0.012676581740379333, batch loss prom: 0.0034566910471767187, batch loss ss: 0.009066837839782238, batch loss polya: 0.0001530530134914443\n",
      "batch loss 0.024370048195123672, batch loss prom: 0.010986433364450932, batch loss ss: 0.013361083343625069, batch loss polya: 2.253030106658116e-05\n",
      "batch loss 1.011182188987732, batch loss prom: 0.052537161856889725, batch loss ss: 0.9586422443389893, batch loss polya: 2.7418097943154862e-06\n",
      "batch loss 0.039432592689991, batch loss prom: 0.004069500602781773, batch loss ss: 0.035324349999427795, batch loss polya: 3.8742269680369645e-05\n",
      "batch loss 0.6101516485214233, batch loss prom: 0.5954898595809937, batch loss ss: 0.01458671223372221, batch loss polya: 7.509902934543788e-05\n",
      "batch loss 0.02981950342655182, batch loss prom: 0.0012515101116150618, batch loss ss: 0.028408147394657135, batch loss polya: 0.00015984688070602715\n",
      "batch loss 0.022808631882071495, batch loss prom: 0.004591754637658596, batch loss ss: 0.018160613253712654, batch loss polya: 5.6265202147187665e-05\n",
      "batch loss 0.12418464571237564, batch loss prom: 0.001836162875406444, batch loss ss: 0.12234442681074142, batch loss polya: 4.0531076592742465e-06\n",
      "batch loss 0.014326573349535465, batch loss prom: 0.0043351720087230206, batch loss ss: 0.009858490899205208, batch loss polya: 0.00013290952483657748\n",
      "batch loss 0.0732545554637909, batch loss prom: 0.04811221361160278, batch loss ss: 0.025095609948039055, batch loss polya: 4.672895011026412e-05\n",
      "batch loss 0.028242092579603195, batch loss prom: 0.022306255996227264, batch loss ss: 0.005844764411449432, batch loss polya: 9.107174992095679e-05\n",
      "batch loss 0.42381563782691956, batch loss prom: 0.4140525162220001, batch loss ss: 0.009737610816955566, batch loss polya: 2.5510462364763953e-05\n",
      "batch loss 0.018527142703533173, batch loss prom: 0.01646268367767334, batch loss ss: 0.0018856617389246821, batch loss polya: 0.0001787979417713359\n",
      "batch loss 0.014549119397997856, batch loss prom: 0.00265852571465075, batch loss ss: 0.011801190674304962, batch loss polya: 8.940297266235575e-05\n",
      "batch loss 0.0014131201896816492, batch loss prom: 0.0005738280597142875, batch loss ss: 0.00047946401173248887, batch loss polya: 0.00035982808913104236\n",
      "batch loss 0.6120458841323853, batch loss prom: 0.005247153807431459, batch loss ss: 0.6062226295471191, batch loss polya: 0.0005760917556472123\n",
      "-----\n",
      "prom acc: 93.75, prom loss: 0.2564758360385895\n",
      "ss acc: 77.5, ss loss: 0.660895049571991\n",
      "polya acc: 100.0, polya loss: 0.0002482919080648571\n",
      "-----\n",
      "batch loss 0.18475233018398285, batch loss prom: 0.010721499100327492, batch loss ss: 0.17386919260025024, batch loss polya: 0.0001616353401914239\n",
      "batch loss 0.0013986751437187195, batch loss prom: 0.000686767278239131, batch loss ss: 0.00040570611599832773, batch loss polya: 0.00030620177858509123\n",
      "batch loss 0.04961273446679115, batch loss prom: 0.009029743261635303, batch loss ss: 0.04039167985320091, batch loss polya: 0.00019131260341964662\n",
      "batch loss 0.2676149308681488, batch loss prom: 0.25878649950027466, batch loss ss: 0.008690749295055866, batch loss polya: 0.00013767725613433868\n",
      "batch loss 0.0014811400324106216, batch loss prom: 0.0005913416389375925, batch loss ss: 0.0005870526074431837, batch loss polya: 0.000302745756926015\n",
      "batch loss 0.001356399618089199, batch loss prom: 0.0005023409612476826, batch loss ss: 0.0005392765742726624, batch loss polya: 0.0003147821989841759\n",
      "batch loss 0.013751121237874031, batch loss prom: 0.010927596129477024, batch loss ss: 0.002493488835170865, batch loss polya: 0.0003300360403954983\n",
      "batch loss 0.01958337053656578, batch loss prom: 0.003782975720241666, batch loss ss: 0.01575557328760624, batch loss polya: 4.482168878894299e-05\n",
      "batch loss 0.02103014662861824, batch loss prom: 0.0024346255231648684, batch loss ss: 0.018570605665445328, batch loss polya: 2.4914430468925275e-05\n",
      "batch loss 0.372672975063324, batch loss prom: 0.3691572844982147, batch loss ss: 0.003069453639909625, batch loss polya: 0.0004462200158741325\n",
      "batch loss 0.002239764668047428, batch loss prom: 0.0011460172245278955, batch loss ss: 0.00031001531169749796, batch loss polya: 0.000783732277341187\n",
      "batch loss 0.013800510205328465, batch loss prom: 0.006025601178407669, batch loss ss: 0.007761676795780659, batch loss polya: 1.3232143828645349e-05\n",
      "batch loss 0.020107857882976532, batch loss prom: 0.0016144587425515056, batch loss ss: 0.018434273079037666, batch loss polya: 5.9126061387360096e-05\n",
      "batch loss 0.013512568548321724, batch loss prom: 0.000902007392141968, batch loss ss: 0.012555130757391453, batch loss polya: 5.543078441405669e-05\n",
      "batch loss 0.0015041151782497764, batch loss prom: 0.0007292948430404067, batch loss ss: 0.000291662581730634, batch loss polya: 0.00048315772437490523\n",
      "batch loss 0.027599617838859558, batch loss prom: 0.0011592342052608728, batch loss ss: 0.02638578787446022, batch loss polya: 5.4596363042946905e-05\n",
      "batch loss 0.060893457382917404, batch loss prom: 0.00758908037096262, batch loss ss: 0.053189467638731, batch loss polya: 0.00011491115583339706\n",
      "batch loss 0.0013768663629889488, batch loss prom: 0.0006935574929229915, batch loss ss: 0.0003067976504098624, batch loss polya: 0.00037651124875992537\n",
      "batch loss 0.07752716541290283, batch loss prom: 0.018638823181390762, batch loss ss: 0.05888214334845543, batch loss polya: 6.198863957251888e-06\n",
      "batch loss 0.0012172262649983168, batch loss prom: 0.0005264088395051658, batch loss ss: 0.00036149643710814416, batch loss polya: 0.0003293210465926677\n",
      "batch loss 0.0012446343898773193, batch loss prom: 0.0005303407087922096, batch loss ss: 0.00035291642416268587, batch loss polya: 0.00036137725692242384\n",
      "batch loss 0.003128359094262123, batch loss prom: 0.0015606615925207734, batch loss ss: 0.0007104733376763761, batch loss polya: 0.0008572241058573127\n",
      "batch loss 0.01081801950931549, batch loss prom: 0.007497742306441069, batch loss ss: 0.0032916669733822346, batch loss polya: 2.8609820219571702e-05\n",
      "batch loss 0.08573813736438751, batch loss prom: 0.0011587579501792789, batch loss ss: 0.08452120423316956, batch loss polya: 5.817244164063595e-05\n",
      "batch loss 0.014484236016869545, batch loss prom: 0.011056585237383842, batch loss ss: 0.0032613680232316256, batch loss polya: 0.0001662831346038729\n",
      "batch loss 0.015302124433219433, batch loss prom: 0.007998697459697723, batch loss ss: 0.007223678287118673, batch loss polya: 7.974783511599526e-05\n",
      "batch loss 0.0013998625800013542, batch loss prom: 0.0007023728103376925, batch loss ss: 0.000311802898067981, batch loss polya: 0.0003856868715956807\n",
      "batch loss 0.004359012935310602, batch loss prom: 0.0013578252401202917, batch loss ss: 0.002025577938184142, batch loss polya: 0.0009756095823831856\n",
      "batch loss 0.001259875949472189, batch loss prom: 0.0005813338793814182, batch loss ss: 0.0003033416287507862, batch loss polya: 0.00037520044133998454\n",
      "batch loss 0.19040486216545105, batch loss prom: 0.15469011664390564, batch loss ss: 0.03566133975982666, batch loss polya: 5.340433563105762e-05\n",
      "batch loss 0.004368994850665331, batch loss prom: 0.0014260371681302786, batch loss ss: 0.0028733417857438326, batch loss polya: 6.961580220377073e-05\n",
      "batch loss 0.0012166168307885528, batch loss prom: 0.0005827635759487748, batch loss ss: 0.0003524397616274655, batch loss polya: 0.0002814135223161429\n",
      "batch loss 0.4944544732570648, batch loss prom: 0.49239057302474976, batch loss ss: 0.001496029901318252, batch loss polya: 0.0005678709712810814\n",
      "batch loss 0.5953490734100342, batch loss prom: 0.5812675952911377, batch loss ss: 0.013931060209870338, batch loss polya: 0.00015043080202303827\n",
      "batch loss 0.018532603979110718, batch loss prom: 0.004278672393411398, batch loss ss: 0.013931999914348125, batch loss polya: 0.0003219324571546167\n",
      "batch loss 0.03295622766017914, batch loss prom: 0.03066229820251465, batch loss ss: 0.0022431467659771442, batch loss polya: 5.07818695041351e-05\n",
      "batch loss 0.0013467457611113787, batch loss prom: 0.000570253818295896, batch loss ss: 0.0004651656490750611, batch loss polya: 0.00031132620642893016\n",
      "batch loss 0.06299757957458496, batch loss prom: 0.0026032389141619205, batch loss ss: 0.06031816452741623, batch loss polya: 7.617183291586116e-05\n",
      "batch loss 0.0134135065600276, batch loss prom: 0.003996481653302908, batch loss ss: 0.009304139763116837, batch loss polya: 0.00011288482346571982\n",
      "batch loss 0.7165066003799438, batch loss prom: 0.7085942625999451, batch loss ss: 0.007887409068644047, batch loss polya: 2.4914430468925275e-05\n",
      "batch loss 0.2665627598762512, batch loss prom: 0.26288512349128723, batch loss ss: 0.0034322182182222605, batch loss polya: 0.0002454218047205359\n",
      "batch loss 0.019077613949775696, batch loss prom: 0.01715359091758728, batch loss ss: 0.0016826532082632184, batch loss polya: 0.00024136967840604484\n",
      "batch loss 0.01754739135503769, batch loss prom: 0.0062945447862148285, batch loss ss: 0.010940448381006718, batch loss polya: 0.0003123987407889217\n",
      "batch loss 0.03904716670513153, batch loss prom: 0.03419209271669388, batch loss ss: 0.004846373572945595, batch loss polya: 8.702239938429557e-06\n",
      "batch loss 0.011433093808591366, batch loss prom: 0.0028839209116995335, batch loss ss: 0.008506138809025288, batch loss polya: 4.303362584323622e-05\n",
      "batch loss 0.046395350247621536, batch loss prom: 0.038882363587617874, batch loss ss: 0.007499872241169214, batch loss polya: 1.3112935448589269e-05\n",
      "batch loss 0.016703372821211815, batch loss prom: 0.0017519139219075441, batch loss ss: 0.014878028072416782, batch loss polya: 7.343022298300639e-05\n",
      "batch loss 0.05879100412130356, batch loss prom: 0.02800031751394272, batch loss ss: 0.0307846050709486, batch loss polya: 6.079655122448457e-06\n",
      "batch loss 0.009995848871767521, batch loss prom: 0.007045662496238947, batch loss ss: 0.0019349202048033476, batch loss polya: 0.0010152667528018355\n",
      "batch loss 0.0031354990787804127, batch loss prom: 0.002102428348734975, batch loss ss: 0.0002203936892328784, batch loss polya: 0.0008126770262606442\n",
      "batch loss 0.31893646717071533, batch loss prom: 0.3160465359687805, batch loss ss: 0.002130740089341998, batch loss polya: 0.0007591941393911839\n",
      "batch loss 0.009462694637477398, batch loss prom: 0.003772762371227145, batch loss ss: 0.0055027916096150875, batch loss polya: 0.00018714107864070684\n",
      "batch loss 0.0131918890401721, batch loss prom: 0.004911145195364952, batch loss ss: 0.008218399249017239, batch loss polya: 6.23445157543756e-05\n",
      "batch loss 0.19961507618427277, batch loss prom: 0.19469955563545227, batch loss ss: 0.004495395813137293, batch loss polya: 0.00042012447374872863\n",
      "batch loss 0.013784185983240604, batch loss prom: 0.0015403084689751267, batch loss ss: 0.012210499495267868, batch loss polya: 3.3378044463461265e-05\n",
      "batch loss 0.0011849324218928814, batch loss prom: 0.0005204515182413161, batch loss ss: 0.0003530356043484062, batch loss polya: 0.00031144535751082003\n",
      "batch loss 0.014384894631803036, batch loss prom: 0.012681555934250355, batch loss ss: 0.0014760324265807867, batch loss polya: 0.0002273062855238095\n",
      "batch loss 0.020598534494638443, batch loss prom: 0.004354637581855059, batch loss ss: 0.01624079793691635, batch loss polya: 3.099436753473128e-06\n",
      "batch loss 0.06938670575618744, batch loss prom: 0.006702560465782881, batch loss ss: 0.06263384222984314, batch loss polya: 5.030505417380482e-05\n",
      "batch loss 0.028517019003629684, batch loss prom: 0.025363773107528687, batch loss ss: 0.002655553398653865, batch loss polya: 0.0004976941272616386\n",
      "batch loss 0.00488401111215353, batch loss prom: 0.0032157397363334894, batch loss ss: 0.0014966250164434314, batch loss polya: 0.0001716466504149139\n",
      "batch loss 0.0013401902979239821, batch loss prom: 0.0005619138828478754, batch loss ss: 0.0004829194222111255, batch loss polya: 0.0002953569928649813\n",
      "batch loss 0.0012148375390097499, batch loss prom: 0.0005541696446016431, batch loss ss: 0.00031871485407464206, batch loss polya: 0.00034195298212580383\n",
      "batch loss 0.03379904106259346, batch loss prom: 0.018232136964797974, batch loss ss: 0.015541394241154194, batch loss polya: 2.5510462364763953e-05\n",
      "batch loss 0.0030826053116470575, batch loss prom: 0.0015334049239754677, batch loss ss: 0.001492816023528576, batch loss polya: 5.638440416078083e-05\n",
      "batch loss 0.9555767178535461, batch loss prom: 0.908770740032196, batch loss ss: 0.046801432967185974, batch loss polya: 4.529942543740617e-06\n",
      "batch loss 0.015514768660068512, batch loss prom: 0.004297901410609484, batch loss ss: 0.011199939996004105, batch loss polya: 1.6927575416048057e-05\n",
      "batch loss 0.1910809874534607, batch loss prom: 0.18615911900997162, batch loss ss: 0.003944000229239464, batch loss polya: 0.0009778724052011967\n",
      "batch loss 0.25262829661369324, batch loss prom: 0.24816501140594482, batch loss ss: 0.004198309034109116, batch loss polya: 0.0002649671514518559\n",
      "batch loss 0.007011303678154945, batch loss prom: 0.0026914584450423717, batch loss ss: 0.004295646212995052, batch loss polya: 2.4199192921514623e-05\n",
      "batch loss 0.9121116399765015, batch loss prom: 0.9039695262908936, batch loss ss: 0.008041270077228546, batch loss polya: 0.00010084597306558862\n",
      "batch loss 0.012367330491542816, batch loss prom: 0.005656071472913027, batch loss ss: 0.006204628385603428, batch loss polya: 0.0005066303419880569\n",
      "batch loss 0.025605902075767517, batch loss prom: 0.004214453510940075, batch loss ss: 0.02102387510240078, batch loss polya: 0.0003675738989841193\n",
      "batch loss 0.001221738406457007, batch loss prom: 0.0005975367967039347, batch loss ss: 0.00031263710116036236, batch loss polya: 0.00031156453769654036\n",
      "batch loss 0.007045896258205175, batch loss prom: 0.003529155161231756, batch loss ss: 0.003394201397895813, batch loss polya: 0.0001225396408699453\n",
      "batch loss 0.009538944810628891, batch loss prom: 0.002063052263110876, batch loss ss: 0.007223915308713913, batch loss polya: 0.00025197668583132327\n",
      "batch loss 0.005951619707047939, batch loss prom: 0.0024946779012680054, batch loss ss: 0.0031918552704155445, batch loss polya: 0.0002650863316375762\n",
      "batch loss 0.020364748314023018, batch loss prom: 0.0024261821527034044, batch loss ss: 0.01790304109454155, batch loss polya: 3.5523738915799186e-05\n",
      "batch loss 0.012053785845637321, batch loss prom: 0.002200088929384947, batch loss ss: 0.00978849083185196, batch loss polya: 6.5205356804654e-05\n",
      "batch loss 0.13804839551448822, batch loss prom: 0.12958131730556488, batch loss ss: 0.008046472445130348, batch loss polya: 0.00042060110718011856\n",
      "batch loss 0.01050115842372179, batch loss prom: 0.007827797904610634, batch loss ss: 0.002638432662934065, batch loss polya: 3.4927710657939315e-05\n",
      "batch loss 0.00295824371278286, batch loss prom: 0.0015564957866445184, batch loss ss: 0.0001931004080688581, batch loss polya: 0.0012086475035175681\n",
      "batch loss 0.009205395355820656, batch loss prom: 0.001379848807118833, batch loss ss: 0.007733879145234823, batch loss polya: 9.16677454370074e-05\n",
      "batch loss 0.020683418959379196, batch loss prom: 0.001623980118893087, batch loss ss: 0.019006511196494102, batch loss polya: 5.2927523938706145e-05\n",
      "batch loss 0.001279424992389977, batch loss prom: 0.0005597693379968405, batch loss ss: 0.00033539868309162557, batch loss polya: 0.00038425691309385\n",
      "batch loss 0.18262626230716705, batch loss prom: 0.17084266245365143, batch loss ss: 0.011776568368077278, batch loss polya: 7.033323527139146e-06\n",
      "batch loss 0.023412754759192467, batch loss prom: 0.016429731622338295, batch loss ss: 0.0067389123141765594, batch loss polya: 0.0002441108226776123\n",
      "batch loss 0.04344813525676727, batch loss prom: 0.024136977270245552, batch loss ss: 0.01930507831275463, batch loss polya: 6.079655122448457e-06\n",
      "batch loss 0.0012136339209973812, batch loss prom: 0.0005976559477858245, batch loss ss: 0.00027926836628466845, batch loss polya: 0.0003367095487192273\n",
      "batch loss 0.17301857471466064, batch loss prom: 0.14459426701068878, batch loss ss: 0.028146594762802124, batch loss polya: 0.00027771908207796514\n",
      "batch loss 0.0013247034512460232, batch loss prom: 0.0005837167263962328, batch loss ss: 0.0003618539194576442, batch loss polya: 0.000379132863599807\n",
      "batch loss 0.014488455839455128, batch loss prom: 0.0050238328985869884, batch loss ss: 0.00942778866738081, batch loss polya: 3.683499380713329e-05\n",
      "batch loss 0.260577917098999, batch loss prom: 0.15038049221038818, batch loss ss: 0.11018194258213043, batch loss polya: 1.549708758830093e-05\n",
      "batch loss 0.0107995280995965, batch loss prom: 0.004189168103039265, batch loss ss: 0.006320842541754246, batch loss polya: 0.00028951745480298996\n",
      "batch loss 0.2111288160085678, batch loss prom: 0.20440144836902618, batch loss ss: 0.006647615227848291, batch loss polya: 7.974783511599526e-05\n",
      "batch loss 0.017130998894572258, batch loss prom: 0.014210696332156658, batch loss ss: 0.002596223959699273, batch loss polya: 0.0003240775258745998\n",
      "batch loss 0.016362885013222694, batch loss prom: 0.0019264726433902979, batch loss ss: 0.014397311955690384, batch loss polya: 3.909988299710676e-05\n",
      "batch loss 0.01995963416993618, batch loss prom: 0.004512128420174122, batch loss ss: 0.015385161153972149, batch loss polya: 6.23445157543756e-05\n",
      "batch loss 0.009262259118258953, batch loss prom: 0.005131408106535673, batch loss ss: 0.004079591948539019, batch loss polya: 5.125868119648658e-05\n",
      "batch loss 0.009895979426801205, batch loss prom: 0.005604743491858244, batch loss ss: 0.0028229409363120794, batch loss polya: 0.001468295231461525\n",
      "batch loss 0.0012435547541826963, batch loss prom: 0.0005660838796757162, batch loss ss: 0.0003392120997887105, batch loss polya: 0.00033825874561443925\n",
      "batch loss 0.0012343863490968943, batch loss prom: 0.00046957432641647756, batch loss ss: 0.00047052756417542696, batch loss polya: 0.0002942844294011593\n",
      "batch loss 0.0230729840695858, batch loss prom: 0.012248889543116093, batch loss ss: 0.010777008719742298, batch loss polya: 4.708655978902243e-05\n",
      "batch loss 0.0013020611368119717, batch loss prom: 0.0005129451747052372, batch loss ss: 0.0005087750032544136, batch loss polya: 0.0002803409588523209\n",
      "batch loss 0.011678239330649376, batch loss prom: 0.002452701097354293, batch loss ss: 0.009167246520519257, batch loss polya: 5.829164365422912e-05\n",
      "batch loss 0.0015397632960230112, batch loss prom: 0.0006613928126171231, batch loss ss: 0.00034362133010290563, batch loss polya: 0.0005347490659914911\n",
      "batch loss 0.007005646824836731, batch loss prom: 0.002376947784796357, batch loss ss: 0.00461987778544426, batch loss polya: 8.821448318485636e-06\n",
      "batch loss 1.8667492866516113, batch loss prom: 1.7144877910614014, batch loss ss: 0.15225833654403687, batch loss polya: 3.099436753473128e-06\n",
      "batch loss 0.17648184299468994, batch loss prom: 0.15777644515037537, batch loss ss: 0.018585465848445892, batch loss polya: 0.00011991735664196312\n",
      "batch loss 0.006679965648800135, batch loss prom: 0.001279965159483254, batch loss ss: 0.005355298053473234, batch loss polya: 4.470248313737102e-05\n",
      "batch loss 0.028973715379834175, batch loss prom: 0.018646780401468277, batch loss ss: 0.009749888442456722, batch loss polya: 0.0005770448478870094\n",
      "batch loss 0.26246607303619385, batch loss prom: 0.24847403168678284, batch loss ss: 0.013952572830021381, batch loss polya: 3.9457496313843876e-05\n",
      "batch loss 0.009291555732488632, batch loss prom: 0.0062645734287798405, batch loss ss: 0.0029611808713525534, batch loss polya: 6.580135959666222e-05\n",
      "batch loss 0.010624420829117298, batch loss prom: 0.00495088379830122, batch loss ss: 0.0054477802477777, batch loss polya: 0.00022575691400561482\n",
      "batch loss 0.27238187193870544, batch loss prom: 0.25782620906829834, batch loss ss: 0.014376983046531677, batch loss polya: 0.00017867876158561558\n",
      "batch loss 0.08438549935817719, batch loss prom: 0.06722142547369003, batch loss ss: 0.0171404667198658, batch loss polya: 2.3603161025675945e-05\n",
      "batch loss 0.01766604371368885, batch loss prom: 0.0015044810716062784, batch loss ss: 0.016040096059441566, batch loss polya: 0.00012146688823122531\n",
      "batch loss 0.11468185484409332, batch loss prom: 0.09699331969022751, batch loss ss: 0.017679717391729355, batch loss polya: 8.821448318485636e-06\n",
      "batch loss 0.1294112652540207, batch loss prom: 0.11160623282194138, batch loss ss: 0.016249241307377815, batch loss polya: 0.001555781695060432\n",
      "batch loss 0.033008474856615067, batch loss prom: 0.011005298234522343, batch loss ss: 0.007855593226850033, batch loss polya: 0.014147582463920116\n",
      "batch loss 0.06504631787538528, batch loss prom: 0.04296062886714935, batch loss ss: 0.022063041105866432, batch loss polya: 2.2649508537142538e-05\n",
      "batch loss 0.0017892846371978521, batch loss prom: 0.0011367294937372208, batch loss ss: 0.00023016665363684297, batch loss polya: 0.0004223884898237884\n",
      "batch loss 0.0014079090906307101, batch loss prom: 0.000832449528388679, batch loss ss: 0.0002928543253801763, batch loss polya: 0.0002826052950695157\n",
      "batch loss 0.23055139183998108, batch loss prom: 0.2251494973897934, batch loss ss: 0.005335970316082239, batch loss polya: 6.592056161025539e-05\n",
      "batch loss 0.008203963749110699, batch loss prom: 0.006402693688869476, batch loss ss: 0.0016762267332524061, batch loss polya: 0.0001250427303602919\n",
      "batch loss 0.0012050706427544355, batch loss prom: 0.0005278385942801833, batch loss ss: 0.0003610197745729238, batch loss polya: 0.000316212244797498\n",
      "batch loss 0.04518936946988106, batch loss prom: 0.0036651596892625093, batch loss ss: 0.04151705652475357, batch loss polya: 7.152531907195225e-06\n",
      "batch loss 0.008204016834497452, batch loss prom: 0.005006752442568541, batch loss ss: 0.003177952254191041, batch loss polya: 1.9311717551317997e-05\n",
      "batch loss 0.0048715644516050816, batch loss prom: 0.0025070447009056807, batch loss ss: 0.0020443748217076063, batch loss polya: 0.00032014489988796413\n",
      "batch loss 0.1067434549331665, batch loss prom: 0.08995618671178818, batch loss ss: 0.016512049362063408, batch loss polya: 0.0002752163854893297\n",
      "batch loss 0.0036465292796492577, batch loss prom: 0.0022261380217969418, batch loss ss: 0.0011551857460290194, batch loss polya: 0.00026520551182329655\n",
      "batch loss 0.019770735874772072, batch loss prom: 0.012719221413135529, batch loss ss: 0.006853051949292421, batch loss polya: 0.0001984637783607468\n",
      "batch loss 0.05093884840607643, batch loss prom: 0.03972695767879486, batch loss ss: 0.010385635308921337, batch loss polya: 0.0008262557676061988\n",
      "batch loss 0.009920786134898663, batch loss prom: 0.0018438971601426601, batch loss ss: 0.007999525405466557, batch loss polya: 7.73638384998776e-05\n",
      "batch loss 0.04253658279776573, batch loss prom: 0.018227221444249153, batch loss ss: 0.0242972020059824, batch loss polya: 1.2159273865108844e-05\n",
      "batch loss 0.001733992830850184, batch loss prom: 0.0009716795175336301, batch loss ss: 0.00031799983116798103, batch loss polya: 0.00044431351125240326\n",
      "batch loss 0.004041904583573341, batch loss prom: 0.0024819541722536087, batch loss ss: 0.0014774608425796032, batch loss polya: 8.248942322097719e-05\n",
      "batch loss 0.1234288439154625, batch loss prom: 0.1152435690164566, batch loss ss: 0.007948790676891804, batch loss polya: 0.00023648326168768108\n",
      "batch loss 0.002306598937138915, batch loss prom: 0.0012298409128561616, batch loss ss: 0.0010345588671043515, batch loss polya: 4.2199197196168825e-05\n",
      "batch loss 0.0011945872101932764, batch loss prom: 0.00051115796668455, batch loss ss: 0.0003475538978818804, batch loss polya: 0.0003358753747306764\n",
      "batch loss 0.026440374553203583, batch loss prom: 0.01692834310233593, batch loss ss: 0.00941881351172924, batch loss polya: 9.321732068201527e-05\n",
      "batch loss 0.01810559257864952, batch loss prom: 0.001735848723910749, batch loss ss: 0.016337556764483452, batch loss polya: 3.218599158572033e-05\n",
      "batch loss 0.0045023150742053986, batch loss prom: 0.0026739814784377813, batch loss ss: 0.0017463208641856909, batch loss polya: 8.201262971851975e-05\n",
      "batch loss 0.022826075553894043, batch loss prom: 0.004062851890921593, batch loss ss: 0.0187553558498621, batch loss polya: 7.867782187531702e-06\n",
      "batch loss 0.06783853471279144, batch loss prom: 0.06420525163412094, batch loss ss: 0.0035443599335849285, batch loss polya: 8.892617915989831e-05\n",
      "batch loss 0.00894998386502266, batch loss prom: 0.0021915247198194265, batch loss ss: 0.006576324347406626, batch loss polya: 0.0001821352052502334\n",
      "batch loss 0.01347455196082592, batch loss prom: 0.008382848463952541, batch loss ss: 0.005086339078843594, batch loss polya: 5.364403477869928e-06\n",
      "batch loss 0.0011297652963548899, batch loss prom: 0.00047136162174865603, batch loss ss: 0.0003281293320469558, batch loss polya: 0.0003302744007669389\n",
      "batch loss 0.13063864409923553, batch loss prom: 0.12678082287311554, batch loss ss: 0.003472728654742241, batch loss polya: 0.00038509105797857046\n",
      "batch loss 0.010273032821714878, batch loss prom: 0.0034740353003144264, batch loss ss: 0.0067558446899056435, batch loss polya: 4.31528314948082e-05\n",
      "batch loss 0.5823176503181458, batch loss prom: 0.13556618988513947, batch loss ss: 0.44672951102256775, batch loss polya: 2.1934269170742482e-05\n",
      "batch loss 0.06462009996175766, batch loss prom: 0.06358414888381958, batch loss ss: 0.0009465504554100335, batch loss polya: 8.940297266235575e-05\n",
      "batch loss 0.013220849446952343, batch loss prom: 0.007235868368297815, batch loss ss: 0.005643624812364578, batch loss polya: 0.0003413571394048631\n",
      "batch loss 0.01574637182056904, batch loss prom: 0.009830868802964687, batch loss ss: 0.00589738367125392, batch loss polya: 1.811964830267243e-05\n",
      "batch loss 0.010397454723715782, batch loss prom: 0.0008111285860650241, batch loss ss: 0.002481597475707531, batch loss polya: 0.0071047283709049225\n",
      "batch loss 0.006159495562314987, batch loss prom: 0.004053947515785694, batch loss ss: 0.0020929116290062666, batch loss polya: 1.2636104656849056e-05\n",
      "batch loss 0.00758639071136713, batch loss prom: 0.0033072319347411394, batch loss ss: 0.0040093050338327885, batch loss polya: 0.0002698534226510674\n",
      "batch loss 0.00405461248010397, batch loss prom: 0.0011982887517660856, batch loss ss: 0.0027777680661529303, batch loss polya: 7.855583680793643e-05\n",
      "batch loss 0.0011651595123112202, batch loss prom: 0.0004368066438473761, batch loss ss: 0.0003152588615193963, batch loss polya: 0.00041309406515210867\n",
      "batch loss 0.007355221547186375, batch loss prom: 0.0023836076725274324, batch loss ss: 0.00482976483181119, batch loss polya: 0.00014184899919200689\n",
      "batch loss 0.20523758232593536, batch loss prom: 0.19216890633106232, batch loss ss: 0.012926003895699978, batch loss polya: 0.0001426833332516253\n",
      "batch loss 0.0011628991924226284, batch loss prom: 0.00037102968781255186, batch loss ss: 0.00038092033355496824, batch loss polya: 0.0004109491710551083\n",
      "batch loss 0.0011628989595919847, batch loss prom: 0.00037424711626954377, batch loss ss: 0.00041571559268049896, batch loss polya: 0.00037293630884960294\n",
      "batch loss 0.007081450428813696, batch loss prom: 0.0029747304506599903, batch loss ss: 0.0038101710379123688, batch loss polya: 0.0002965487365145236\n",
      "batch loss 0.12199708819389343, batch loss prom: 0.11567489057779312, batch loss ss: 0.00603887252509594, batch loss polya: 0.0002833203470800072\n",
      "batch loss 0.015548482537269592, batch loss prom: 0.009698651731014252, batch loss ss: 0.005834572017192841, batch loss polya: 1.5258672647178173e-05\n",
      "batch loss 0.0373910516500473, batch loss prom: 0.03349972143769264, batch loss ss: 0.0038783347699791193, batch loss polya: 1.2993727978027891e-05\n",
      "batch loss 0.04043865203857422, batch loss prom: 0.01856381818652153, batch loss ss: 0.021874235942959785, batch loss polya: 5.960462772236497e-07\n",
      "batch loss 0.19967548549175262, batch loss prom: 0.19566096365451813, batch loss ss: 0.003622400341555476, batch loss polya: 0.0003921216703020036\n",
      "batch loss 0.001183990971185267, batch loss prom: 0.0004172646440565586, batch loss ss: 0.000388665939681232, batch loss polya: 0.0003780603874474764\n",
      "batch loss 0.0033775281626731157, batch loss prom: 0.0008519833791069686, batch loss ss: 0.0024978886358439922, batch loss polya: 2.7656173188006505e-05\n",
      "batch loss 0.018799861893057823, batch loss prom: 0.0006461439770646393, batch loss ss: 0.018061572685837746, batch loss polya: 9.214453893946484e-05\n",
      "batch loss 0.02940315194427967, batch loss prom: 0.004520198330283165, batch loss ss: 0.02485470101237297, batch loss polya: 2.825220326485578e-05\n",
      "batch loss 0.009273555129766464, batch loss prom: 0.003999687731266022, batch loss ss: 0.004850525874644518, batch loss polya: 0.0004233417857903987\n",
      "batch loss 0.15589964389801025, batch loss prom: 0.1527380347251892, batch loss ss: 0.002899730112403631, batch loss polya: 0.0002618685248307884\n",
      "batch loss 0.0011717138113453984, batch loss prom: 0.00043823651503771544, batch loss ss: 0.00032062159152701497, batch loss polya: 0.0004128557338844985\n",
      "batch loss 0.0071999914944171906, batch loss prom: 0.005565267987549305, batch loss ss: 0.0016150538576766849, batch loss polya: 1.966933996300213e-05\n",
      "batch loss 1.8859162330627441, batch loss prom: 1.882741928100586, batch loss ss: 0.0028208012226969004, batch loss polya: 0.0003535122668836266\n",
      "batch loss 0.19585756957530975, batch loss prom: 0.03464968875050545, batch loss ss: 0.1611475646495819, batch loss polya: 6.031808152329177e-05\n",
      "batch loss 0.026281367987394333, batch loss prom: 0.004295171704143286, batch loss ss: 0.021943161264061928, batch loss polya: 4.303362584323622e-05\n",
      "batch loss 0.005639256443828344, batch loss prom: 0.004204006865620613, batch loss ss: 0.0010507544502615929, batch loss polya: 0.0003844952443614602\n",
      "batch loss 0.0016136111225932837, batch loss prom: 0.0005645350320264697, batch loss ss: 0.0003051292151212692, batch loss polya: 0.0007439468172378838\n",
      "batch loss 0.01087111420929432, batch loss prom: 0.009724978357553482, batch loss ss: 0.0010312244994565845, batch loss polya: 0.00011491115583339706\n",
      "batch loss 0.003753830213099718, batch loss prom: 0.0017497718799859285, batch loss ss: 0.0019971441943198442, batch loss polya: 6.9141146923357155e-06\n",
      "batch loss 0.0012589192483574152, batch loss prom: 0.0005161621957086027, batch loss ss: 0.00023993951617740095, batch loss polya: 0.000502817565575242\n",
      "batch loss 0.015331989154219627, batch loss prom: 0.001750604948028922, batch loss ss: 0.01301672961562872, batch loss polya: 0.0005646541831083596\n",
      "batch loss 0.00907297432422638, batch loss prom: 0.005815254058688879, batch loss ss: 0.003246634267270565, batch loss polya: 1.1086402082582936e-05\n",
      "batch loss 0.0011569411726668477, batch loss prom: 0.0004070168943144381, batch loss ss: 0.0003743662964552641, batch loss polya: 0.00037555795279331505\n",
      "batch loss 0.0031458684243261814, batch loss prom: 0.001341753639280796, batch loss ss: 0.0010406322544440627, batch loss polya: 0.0007634824141860008\n",
      "batch loss 0.18232984840869904, batch loss prom: 0.18046477437019348, batch loss ss: 0.001465200330130756, batch loss polya: 0.00039986721822060645\n",
      "batch loss 0.0063828048296272755, batch loss prom: 0.0021470370702445507, batch loss ss: 0.003812902607023716, batch loss polya: 0.0004228651523590088\n",
      "batch loss 0.2012537121772766, batch loss prom: 0.19941666722297668, batch loss ss: 0.0013662775745615363, batch loss polya: 0.0004707658663392067\n",
      "batch loss 0.012157563120126724, batch loss prom: 0.0016765836626291275, batch loss ss: 0.010223520919680595, batch loss polya: 0.0002574589161667973\n",
      "batch loss 1.0256303548812866, batch loss prom: 1.0240366458892822, batch loss ss: 0.0013579442165791988, batch loss polya: 0.00023576818057335913\n",
      "batch loss 0.05893717706203461, batch loss prom: 0.055336397141218185, batch loss ss: 0.0034994573798030615, batch loss polya: 0.00010132275929208845\n",
      "batch loss 0.015374595299363136, batch loss prom: 0.0032282164320349693, batch loss ss: 0.012102033942937851, batch loss polya: 4.434487345861271e-05\n",
      "batch loss 0.010680624283850193, batch loss prom: 0.005568231921643019, batch loss ss: 0.005073173902928829, batch loss polya: 3.9219088648678735e-05\n",
      "batch loss 0.0012571531115099788, batch loss prom: 0.0004001055203843862, batch loss ss: 0.0004807746736332774, batch loss polya: 0.0003762729174923152\n",
      "batch loss 0.010688400827348232, batch loss prom: 0.007161068730056286, batch loss ss: 0.0034704713616520166, batch loss polya: 5.686121585313231e-05\n",
      "batch loss 0.010150060057640076, batch loss prom: 0.006540203001350164, batch loss ss: 0.0035631281789392233, batch loss polya: 4.672895011026412e-05\n",
      "batch loss 0.12647411227226257, batch loss prom: 0.12577049434185028, batch loss ss: 0.0006243425305001438, batch loss polya: 7.92710343375802e-05\n",
      "batch loss 0.015394169837236404, batch loss prom: 0.0018379476387053728, batch loss ss: 0.013378139585256577, batch loss polya: 0.00017808281700126827\n",
      "batch loss 0.01131673064082861, batch loss prom: 0.004851593170315027, batch loss ss: 0.005851993802934885, batch loss polya: 0.000613143783994019\n",
      "batch loss 0.0011079628020524979, batch loss prom: 0.0004172646440565586, batch loss ss: 0.00032443503732793033, batch loss polya: 0.000366263062460348\n",
      "batch loss 0.014201312325894833, batch loss prom: 0.009121532551944256, batch loss ss: 0.004476882051676512, batch loss polya: 0.0006028980133123696\n",
      "batch loss 0.0037842283491045237, batch loss prom: 0.0011367294937372208, batch loss ss: 0.0025898031890392303, batch loss polya: 5.769562994828448e-05\n",
      "batch loss 0.009363881312310696, batch loss prom: 0.0017828536219894886, batch loss ss: 0.00691212946549058, batch loss polya: 0.0006688979919999838\n",
      "batch loss 0.15388546884059906, batch loss prom: 0.14763247966766357, batch loss ss: 0.006012092810124159, batch loss polya: 0.00024089295766316354\n",
      "batch loss 0.0015857338439673185, batch loss prom: 0.000756216119043529, batch loss ss: 0.00033206192892976105, batch loss polya: 0.0004974558250978589\n",
      "batch loss 0.14203567802906036, batch loss prom: 0.13883757591247559, batch loss ss: 0.0023689798545092344, batch loss polya: 0.0008291144040413201\n",
      "batch loss 0.0012215097667649388, batch loss prom: 0.0005105622112751007, batch loss ss: 0.0002584123576525599, batch loss polya: 0.00045253525604493916\n",
      "batch loss 0.0011074852664023638, batch loss prom: 0.000387831823900342, batch loss ss: 0.00041166413575410843, batch loss polya: 0.0003079893649555743\n",
      "batch loss 0.009969010017812252, batch loss prom: 0.007900655269622803, batch loss ss: 0.002034857403486967, batch loss polya: 3.349725011503324e-05\n",
      "batch loss 0.0012156713055446744, batch loss prom: 0.0005085367010906339, batch loss ss: 0.00025817399728111923, batch loss polya: 0.0004489606071729213\n",
      "batch loss 0.017038162797689438, batch loss prom: 0.0041714804247021675, batch loss ss: 0.012858336791396141, batch loss polya: 8.34461570775602e-06\n",
      "batch loss 0.18363478779792786, batch loss prom: 0.18207649886608124, batch loss ss: 0.001135776867158711, batch loss polya: 0.00042250767000950873\n",
      "batch loss 0.006180450785905123, batch loss prom: 0.003812665119767189, batch loss ss: 0.002318315440788865, batch loss polya: 4.9470632802695036e-05\n",
      "batch loss 0.00374243943952024, batch loss prom: 0.002715235808864236, batch loss ss: 0.0009990707039833069, batch loss polya: 2.8132995794294402e-05\n",
      "batch loss 0.1598823517560959, batch loss prom: 0.15818552672863007, batch loss ss: 0.0014398456551134586, batch loss polya: 0.000256982195423916\n",
      "batch loss 0.0015142039628699422, batch loss prom: 0.0008027906878851354, batch loss ss: 0.0002127659390680492, batch loss polya: 0.0004986473359167576\n",
      "batch loss 0.0077396114356815815, batch loss prom: 0.0038773848209530115, batch loss ss: 0.0026204793248325586, batch loss polya: 0.0012417471734806895\n",
      "batch loss 0.004488768521696329, batch loss prom: 0.0020051151514053345, batch loss ss: 0.002420355100184679, batch loss polya: 6.329813186312094e-05\n",
      "batch loss 0.010630777105689049, batch loss prom: 0.002867873990908265, batch loss ss: 0.0074544367380440235, batch loss polya: 0.0003084660565946251\n",
      "batch loss 0.0652729794383049, batch loss prom: 0.0379655547440052, batch loss ss: 0.02728322520852089, batch loss polya: 2.4199192921514623e-05\n",
      "batch loss 0.010145039297640324, batch loss prom: 0.00442003458738327, batch loss ss: 0.0054967449977993965, batch loss polya: 0.00022825974156148732\n",
      "batch loss 0.0014667590148746967, batch loss prom: 0.0008437649230472744, batch loss ss: 0.0001858300092862919, batch loss polya: 0.0004371640970930457\n",
      "batch loss 0.06537927687168121, batch loss prom: 0.05239565297961235, batch loss ss: 0.012941301800310612, batch loss polya: 4.23184028477408e-05\n",
      "batch loss 0.16070453822612762, batch loss prom: 0.15850451588630676, batch loss ss: 0.0020575798116624355, batch loss polya: 0.00014244495832826942\n",
      "batch loss 0.008327900432050228, batch loss prom: 0.0017810686258599162, batch loss ss: 0.006473878864198923, batch loss polya: 7.295342220459133e-05\n",
      "batch loss 0.027858499437570572, batch loss prom: 0.0008451942121610045, batch loss ss: 0.02701139822602272, batch loss polya: 1.9073468138230965e-06\n",
      "batch loss 0.10367840528488159, batch loss prom: 0.10005882382392883, batch loss ss: 0.002323905238881707, batch loss polya: 0.0012956805294379592\n",
      "batch loss 0.014288715086877346, batch loss prom: 0.00883657019585371, batch loss ss: 0.005412211176007986, batch loss polya: 3.9934315282152966e-05\n",
      "batch loss 1.0161280632019043, batch loss prom: 1.0038281679153442, batch loss ss: 0.012248889543116093, batch loss polya: 5.1020273531321436e-05\n",
      "batch loss 0.37576448917388916, batch loss prom: 0.3702613115310669, batch loss ss: 0.0054971007630229, batch loss polya: 6.079655122448457e-06\n",
      "batch loss 0.05251365154981613, batch loss prom: 0.00649235537275672, batch loss ss: 0.04601915180683136, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 0.0312601700425148, batch loss prom: 0.0009319015080109239, batch loss ss: 0.030195357277989388, batch loss polya: 0.00013290952483657748\n",
      "batch loss 0.01081087626516819, batch loss prom: 0.0016469499096274376, batch loss ss: 0.009087039157748222, batch loss polya: 7.688703772146255e-05\n",
      "batch loss 0.10367493331432343, batch loss prom: 0.10102854669094086, batch loss ss: 0.002605498069897294, batch loss polya: 4.088794958079234e-05\n",
      "batch loss 0.006105826701968908, batch loss prom: 0.0017081208061426878, batch loss ss: 0.003915739711374044, batch loss polya: 0.00048196621355600655\n",
      "batch loss 0.11315134167671204, batch loss prom: 0.1007406935095787, batch loss ss: 0.012355336919426918, batch loss polya: 5.531158240046352e-05\n",
      "batch loss 0.003190248738974333, batch loss prom: 0.0012550819665193558, batch loss ss: 0.001797847100533545, batch loss polya: 0.00013731967192143202\n",
      "batch loss 0.0010437333257868886, batch loss prom: 0.00037079135654494166, batch loss ss: 0.000356253091013059, batch loss polya: 0.00031668893643654883\n",
      "batch loss 0.03389369323849678, batch loss prom: 0.002545333234593272, batch loss ss: 0.03133965656161308, batch loss polya: 8.702239938429557e-06\n",
      "batch loss 0.0010287179611623287, batch loss prom: 0.0003682888636831194, batch loss ss: 0.0003084660565946251, batch loss polya: 0.0003519630990922451\n",
      "batch loss 0.006407546810805798, batch loss prom: 0.004982910584658384, batch loss ss: 0.001312467036768794, batch loss polya: 0.00011216964776394889\n",
      "batch loss 0.0010539774084463716, batch loss prom: 0.0003293210465926677, batch loss ss: 0.0004320403386373073, batch loss polya: 0.0002926159941125661\n",
      "batch loss 0.035586100071668625, batch loss prom: 0.004814342129975557, batch loss ss: 0.03076472319662571, batch loss polya: 7.033323527139146e-06\n",
      "batch loss 0.010540775954723358, batch loss prom: 0.006906209979206324, batch loss ss: 0.0033340840600430965, batch loss polya: 0.00030048147891648114\n",
      "batch loss 0.005178177263587713, batch loss prom: 0.004211010877043009, batch loss ss: 0.0008030288736335933, batch loss polya: 0.0001641377166379243\n",
      "batch loss 0.013808587566018105, batch loss prom: 0.005769860465079546, batch loss ss: 0.008031454868614674, batch loss polya: 7.271740287251305e-06\n",
      "batch loss 0.009143712930381298, batch loss prom: 0.0022574197500944138, batch loss ss: 0.006855538114905357, batch loss polya: 3.075552376685664e-05\n",
      "batch loss 0.005555982701480389, batch loss prom: 0.0019242119742557406, batch loss ss: 0.003427228657528758, batch loss polya: 0.00020454221521504223\n",
      "batch loss 0.0033257482573390007, batch loss prom: 0.0016452836571261287, batch loss ss: 0.0014687713701277971, batch loss polya: 0.00021169328829273582\n",
      "batch loss 0.001963027287274599, batch loss prom: 0.0008430502493865788, batch loss ss: 0.001085764612071216, batch loss polya: 3.421248038648628e-05\n",
      "batch loss 0.0069855921901762486, batch loss prom: 0.0018120075110346079, batch loss ss: 0.004991807043552399, batch loss polya: 0.0001817776501411572\n",
      "batch loss 0.09631094336509705, batch loss prom: 0.0859910249710083, batch loss ss: 0.009900393895804882, batch loss polya: 0.00041952868923544884\n",
      "batch loss 0.010266710072755814, batch loss prom: 0.0018854237860068679, batch loss ss: 0.008312863297760487, batch loss polya: 6.842378934379667e-05\n",
      "batch loss 0.11701291799545288, batch loss prom: 0.10219484567642212, batch loss ss: 0.013341204263269901, batch loss polya: 0.001476865611039102\n",
      "batch loss 0.001014414243400097, batch loss prom: 0.0003800861886702478, batch loss ss: 0.00026067672297358513, batch loss polya: 0.0003736513026524335\n",
      "batch loss 0.06419222056865692, batch loss prom: 0.06316792219877243, batch loss ss: 0.000708090839907527, batch loss polya: 0.000316212244797498\n",
      "batch loss 0.864542543888092, batch loss prom: 0.0008044582791626453, batch loss ss: 0.8636772632598877, batch loss polya: 6.0794889577664435e-05\n",
      "batch loss 0.011063048616051674, batch loss prom: 0.010060200467705727, batch loss ss: 0.0009082006872631609, batch loss polya: 9.464769391342998e-05\n",
      "batch loss 0.1560654640197754, batch loss prom: 0.15402700006961823, batch loss ss: 0.001963712740689516, batch loss polya: 7.4741430580616e-05\n",
      "batch loss 0.19595395028591156, batch loss prom: 0.053746458142995834, batch loss ss: 0.1420215368270874, batch loss polya: 0.00018594920402392745\n",
      "batch loss 0.0012641586363315582, batch loss prom: 0.0004956685588695109, batch loss ss: 0.0002299282787134871, batch loss polya: 0.0005385617259889841\n",
      "batch loss 0.012132286094129086, batch loss prom: 0.001148874987848103, batch loss ss: 0.010870288126170635, batch loss polya: 0.00011312322021694854\n",
      "batch loss 0.08379945158958435, batch loss prom: 0.0008163695456460118, batch loss ss: 0.0829663947224617, batch loss polya: 1.6689160474925302e-05\n",
      "batch loss 1.405113697052002, batch loss prom: 1.4023873805999756, batch loss ss: 0.0025148927234113216, batch loss polya: 0.00021145492792129517\n",
      "batch loss 0.0009769992902874947, batch loss prom: 0.0003163314249832183, batch loss ss: 0.00032240914879366755, batch loss polya: 0.00033825874561443925\n",
      "batch loss 0.06151464208960533, batch loss prom: 0.0008497203234583139, batch loss ss: 0.060660749673843384, batch loss polya: 4.172316494077677e-06\n",
      "batch loss 0.10602933913469315, batch loss prom: 0.0960809737443924, batch loss ss: 0.009264810010790825, batch loss polya: 0.0006835508393123746\n",
      "batch loss 0.13529811799526215, batch loss prom: 0.12883417308330536, batch loss ss: 0.005782779306173325, batch loss polya: 0.0006811682251282036\n",
      "batch loss 0.17504744231700897, batch loss prom: 0.000704159727320075, batch loss ss: 0.17433315515518188, batch loss polya: 1.0132738680113107e-05\n",
      "batch loss 0.0035054446198046207, batch loss prom: 0.0007681279676035047, batch loss ss: 0.001353420433588326, batch loss polya: 0.001383896335028112\n",
      "batch loss 0.02861146442592144, batch loss prom: 0.0007668177131563425, batch loss ss: 0.027746424078941345, batch loss polya: 9.822363062994555e-05\n",
      "batch loss 0.002459641546010971, batch loss prom: 0.0014587724581360817, batch loss ss: 0.000498289882671088, batch loss polya: 0.0005025792634114623\n",
      "batch loss 0.005710636731237173, batch loss prom: 0.003239861223846674, batch loss ss: 0.0017018134240061045, batch loss polya: 0.0007689617923460901\n",
      "batch loss 0.01666129007935524, batch loss prom: 0.0012230543652549386, batch loss ss: 0.015282322652637959, batch loss polya: 0.0001559135998832062\n",
      "batch loss 0.008781698532402515, batch loss prom: 0.0020736397709697485, batch loss ss: 0.006664667744189501, batch loss polya: 4.339123915997334e-05\n",
      "batch loss 0.0038449186831712723, batch loss prom: 0.002952741924673319, batch loss ss: 0.0008254220010712743, batch loss polya: 6.675497570540756e-05\n",
      "batch loss 0.03225225955247879, batch loss prom: 0.0008828318095766008, batch loss ss: 0.0310683511197567, batch loss polya: 0.0003010773507412523\n",
      "batch loss 0.002602297579869628, batch loss prom: 0.0008431693422608078, batch loss ss: 0.0017157370457425714, batch loss polya: 4.339123915997334e-05\n",
      "batch loss 0.0015341658145189285, batch loss prom: 0.0009152276325039566, batch loss ss: 0.00016842853801790625, batch loss polya: 0.0004505096294451505\n",
      "batch loss 0.24133257567882538, batch loss prom: 0.23823712766170502, batch loss ss: 0.003065412864089012, batch loss polya: 3.0040289857424796e-05\n",
      "batch loss 0.0010704012820497155, batch loss prom: 0.0005204515182413161, batch loss ss: 0.00019572250312194228, batch loss polya: 0.00035422726068645716\n",
      "batch loss 0.0023801540955901146, batch loss prom: 0.0015626850072294474, batch loss ss: 0.000782183778937906, batch loss polya: 3.528532761265524e-05\n",
      "batch loss 0.19300639629364014, batch loss prom: 0.1913752555847168, batch loss ss: 0.0012325793504714966, batch loss polya: 0.0003985564399044961\n",
      "batch loss 0.002150038257241249, batch loss prom: 0.0017270424868911505, batch loss ss: 0.00039402826223522425, batch loss polya: 2.8967437174287625e-05\n",
      "batch loss 0.003563541453331709, batch loss prom: 0.0007011815905570984, batch loss ss: 0.00069165148306638, batch loss polya: 0.0021707084961235523\n",
      "batch loss 0.0009723465191200376, batch loss prom: 0.00039772229501977563, batch loss ss: 0.0002525725867599249, batch loss polya: 0.00032205163734033704\n",
      "batch loss 0.0022431460674852133, batch loss prom: 0.001117201172746718, batch loss ss: 0.0010783816687762737, batch loss polya: 4.756337511935271e-05\n",
      "batch loss 0.06222454085946083, batch loss prom: 0.000935950840357691, batch loss ss: 0.06087108701467514, batch loss polya: 0.0004175029753241688\n",
      "batch loss 0.005789459683001041, batch loss prom: 0.003126378171145916, batch loss ss: 0.002648895373567939, batch loss polya: 1.4185804502631072e-05\n",
      "batch loss 0.09379494190216064, batch loss prom: 0.08802332729101181, batch loss ss: 0.005692935548722744, batch loss polya: 7.86750388215296e-05\n",
      "batch loss 0.009261016733944416, batch loss prom: 0.007869194261729717, batch loss ss: 0.0012390087358653545, batch loss polya: 0.0001528146385680884\n",
      "batch loss 0.009688958525657654, batch loss prom: 0.003204094711691141, batch loss ss: 0.006301059853285551, batch loss polya: 0.00018380382971372455\n",
      "batch loss 0.13833193480968475, batch loss prom: 0.13650843501091003, batch loss ss: 0.001636000582948327, batch loss polya: 0.00018749863374978304\n",
      "batch loss 0.019644908607006073, batch loss prom: 0.0033102023880928755, batch loss ss: 0.016293341293931007, batch loss polya: 4.136476854910143e-05\n",
      "batch loss 0.008079921826720238, batch loss prom: 0.002029741881415248, batch loss ss: 0.005982113536447287, batch loss polya: 6.806619057897478e-05\n",
      "batch loss 0.047657933086156845, batch loss prom: 0.001256510615348816, batch loss ss: 0.046370308846235275, batch loss polya: 3.111314072157256e-05\n",
      "batch loss 0.0026883366517722607, batch loss prom: 0.0006843847222626209, batch loss ss: 0.001789517467841506, batch loss polya: 0.00021443451987579465\n",
      "batch loss 0.004045974928885698, batch loss prom: 0.0010711177019402385, batch loss ss: 0.002931585069745779, batch loss polya: 4.327203714638017e-05\n",
      "batch loss 0.0017360718920826912, batch loss prom: 0.0006130246329121292, batch loss ss: 0.0009915679693222046, batch loss polya: 0.00013147920253686607\n",
      "batch loss 0.07980954647064209, batch loss prom: 0.07498610764741898, batch loss ss: 0.004516638349741697, batch loss polya: 0.0003067976504098624\n",
      "batch loss 0.026044504716992378, batch loss prom: 0.0009099871967919171, batch loss ss: 0.0247217807918787, batch loss polya: 0.0004127365828026086\n",
      "batch loss 0.025094324722886086, batch loss prom: 0.004182995297014713, batch loss ss: 0.020804166793823242, batch loss polya: 0.00010716341057559475\n",
      "batch loss 0.17397437989711761, batch loss prom: 0.17277218401432037, batch loss ss: 0.0011201781453564763, batch loss polya: 8.201262971851975e-05\n",
      "batch loss 0.013219505548477173, batch loss prom: 0.012847273610532284, batch loss ss: 0.00034254882484674454, batch loss polya: 2.9682672902708873e-05\n",
      "batch loss 0.011365002021193504, batch loss prom: 0.004143938422203064, batch loss ss: 0.007122601382434368, batch loss polya: 9.846202738117427e-05\n",
      "batch loss 0.03363786265254021, batch loss prom: 0.002611799631267786, batch loss ss: 0.030949892476201057, batch loss polya: 7.617183291586116e-05\n",
      "batch loss 0.0012219611089676619, batch loss prom: 0.0005678709712810814, batch loss ss: 0.00017414960893802345, batch loss polya: 0.00047994061606004834\n",
      "batch loss 1.0465482473373413, batch loss prom: 0.0015994624700397253, batch loss ss: 1.0449436902999878, batch loss polya: 5.125986263010418e-06\n",
      "batch loss 0.008303861133754253, batch loss prom: 0.007609429303556681, batch loss ss: 0.0006304183625616133, batch loss polya: 6.401333666872233e-05\n",
      "batch loss 0.0010595653438940644, batch loss prom: 0.0004040378553327173, batch loss ss: 0.00020072828920092434, batch loss polya: 0.000454799213912338\n",
      "batch loss 0.010330019518733025, batch loss prom: 0.0040573906153440475, batch loss ss: 0.00597417401149869, batch loss polya: 0.00029845553217455745\n",
      "batch loss 0.0009271836606785655, batch loss prom: 0.00033742457162588835, batch loss ss: 0.00025662468397058547, batch loss polya: 0.0003331344632897526\n",
      "batch loss 0.0010077382903546095, batch loss prom: 0.000364713923772797, batch loss ss: 0.00024136967840604484, batch loss polya: 0.00040165462996810675\n",
      "batch loss 0.1038089245557785, batch loss prom: 0.09001578390598297, batch loss ss: 0.012962954118847847, batch loss polya: 0.0008301864145323634\n",
      "batch loss 0.04440796375274658, batch loss prom: 0.002967599080875516, batch loss ss: 0.04143643006682396, batch loss polya: 3.933898824470816e-06\n",
      "batch loss 0.001121886889450252, batch loss prom: 0.00044967554276809096, batch loss ss: 0.0002094287920044735, batch loss polya: 0.0004627825692296028\n",
      "batch loss 0.002829783596098423, batch loss prom: 0.0019036282319575548, batch loss ss: 0.000816250394564122, batch loss polya: 0.00010990492592100054\n",
      "batch loss 0.0017074078787118196, batch loss prom: 0.0008874768391251564, batch loss ss: 0.00016330339713022113, batch loss polya: 0.0006566275842487812\n",
      "batch loss 1.8628605604171753, batch loss prom: 0.0015401893761008978, batch loss ss: 1.8613088130950928, batch loss polya: 1.156323378381785e-05\n",
      "batch loss 0.017349431291222572, batch loss prom: 0.01561603881418705, batch loss ss: 0.0015520919114351273, batch loss polya: 0.00018130090029444546\n",
      "batch loss 0.005642107222229242, batch loss prom: 0.0046082488261163235, batch loss ss: 0.0008827127167023718, batch loss polya: 0.00015114595589693636\n",
      "batch loss 0.0042383610270917416, batch loss prom: 0.00229904823936522, batch loss ss: 0.00048458753735758364, batch loss polya: 0.0014547251630574465\n",
      "batch loss 0.001165370224043727, batch loss prom: 0.00043752157944254577, batch loss ss: 0.00019059749320149422, batch loss polya: 0.0005372511222958565\n",
      "batch loss 0.07223846018314362, batch loss prom: 0.06870095431804657, batch loss ss: 0.002800117013975978, batch loss polya: 0.0007373951375484467\n",
      "batch loss 0.0015854302328079939, batch loss prom: 0.0007142852991819382, batch loss ss: 0.0001438752660760656, batch loss polya: 0.0007272697403095663\n",
      "batch loss 0.1430351883172989, batch loss prom: 0.14102059602737427, batch loss ss: 0.0019739444833248854, batch loss polya: 4.0649541915627196e-05\n",
      "batch loss 0.013683873228728771, batch loss prom: 0.0034113090950995684, batch loss ss: 0.01017183717340231, batch loss polya: 0.00010072677832795307\n",
      "batch loss 0.15185873210430145, batch loss prom: 0.1482953131198883, batch loss ss: 0.0034483750350773335, batch loss polya: 0.00011503035057103261\n",
      "batch loss 0.002307212445884943, batch loss prom: 0.0011311330599710345, batch loss ss: 0.0008147019543685019, batch loss polya: 0.00036137725692242384\n",
      "batch loss 1.0443816184997559, batch loss prom: 1.0386009216308594, batch loss ss: 0.005247035529464483, batch loss polya: 0.0005336767644621432\n",
      "batch loss 0.010627093724906445, batch loss prom: 0.006196098402142525, batch loss ss: 0.0038664599414914846, batch loss polya: 0.0005645350320264697\n",
      "batch loss 0.6932047009468079, batch loss prom: 0.6924865245819092, batch loss ss: 0.0005916990339756012, batch loss polya: 0.0001264730526600033\n",
      "batch loss 0.0011465530842542648, batch loss prom: 0.0004148814477957785, batch loss ss: 0.00022349244682118297, batch loss polya: 0.0005081792478449643\n",
      "batch loss 0.001038246788084507, batch loss prom: 0.00038235029205679893, batch loss ss: 0.0002598424907773733, batch loss polya: 0.0003960540343541652\n",
      "batch loss 0.0037147863768041134, batch loss prom: 0.0029870914295315742, batch loss ss: 0.0006176709430292249, batch loss polya: 0.00011002412065863609\n",
      "batch loss 0.012430048547685146, batch loss prom: 0.011592879891395569, batch loss ss: 0.0007376333815045655, batch loss polya: 9.953480184776708e-05\n",
      "batch loss 0.0014250932727009058, batch loss prom: 0.0006837890832684934, batch loss ss: 0.00017033556650858372, batch loss polya: 0.0005709686665795743\n",
      "batch loss 0.003148226998746395, batch loss prom: 0.001976561965420842, batch loss ss: 0.0008253029081970453, batch loss polya: 0.000346362212439999\n",
      "batch loss 0.011210811324417591, batch loss prom: 0.004547255113720894, batch loss ss: 0.006616589147597551, batch loss polya: 4.6967357775429264e-05\n",
      "batch loss 0.14663563668727875, batch loss prom: 0.10737394541501999, batch loss ss: 0.038045432418584824, batch loss polya: 0.0012162677012383938\n",
      "batch loss 0.0010588576551526785, batch loss prom: 0.0004103533865418285, batch loss ss: 0.0002330270071979612, batch loss polya: 0.00041547726141288877\n",
      "batch loss 0.28555119037628174, batch loss prom: 0.2741054594516754, batch loss ss: 0.010556334629654884, batch loss polya: 0.0008893824997358024\n",
      "batch loss 0.007909385487437248, batch loss prom: 0.0012656782055273652, batch loss ss: 0.006497329566627741, batch loss polya: 0.0001463782973587513\n",
      "batch loss 0.008593856357038021, batch loss prom: 0.0012815127847716212, batch loss ss: 0.007176573388278484, batch loss polya: 0.0001357701694360003\n",
      "batch loss 0.0016579623334109783, batch loss prom: 0.0005768066039308906, batch loss ss: 0.000169382052263245, batch loss polya: 0.0009117737063206732\n",
      "batch loss 0.18138673901557922, batch loss prom: 0.00045468006283044815, batch loss ss: 0.18085803091526031, batch loss polya: 7.402622577501461e-05\n",
      "batch loss 0.013622567057609558, batch loss prom: 0.002247785683721304, batch loss ss: 0.011360952630639076, batch loss polya: 1.3828182090946939e-05\n",
      "batch loss 0.0021968979854136705, batch loss prom: 0.0008923601126298308, batch loss ss: 0.0012672259472310543, batch loss polya: 3.731181277544238e-05\n",
      "batch loss 0.0021890222560614347, batch loss prom: 0.0005790702416561544, batch loss ss: 0.00017736769223120064, batch loss polya: 0.0014325842494145036\n",
      "batch loss 0.004526377189904451, batch loss prom: 0.00405976502224803, batch loss ss: 0.00042703570215962827, batch loss polya: 3.957670196541585e-05\n",
      "batch loss 0.03176744654774666, batch loss prom: 0.004309652838855982, batch loss ss: 0.027453383430838585, batch loss polya: 4.410734163684538e-06\n",
      "batch loss 0.0038887241389602423, batch loss prom: 0.0028140253853052855, batch loss ss: 0.0007419217727147043, batch loss polya: 0.0003327769518364221\n",
      "batch loss 0.005065946374088526, batch loss prom: 0.0014759134501218796, batch loss ss: 0.003539608558639884, batch loss polya: 5.0424259825376794e-05\n",
      "batch loss 0.013774629682302475, batch loss prom: 0.008290519006550312, batch loss ss: 0.005386363714933395, batch loss polya: 9.77468371274881e-05\n",
      "batch loss 2.1942005157470703, batch loss prom: 2.1880881786346436, batch loss ss: 0.006085912697017193, batch loss polya: 2.6464111215318553e-05\n",
      "batch loss 0.001081014284864068, batch loss prom: 0.0004801789182238281, batch loss ss: 0.00020859450160060078, batch loss polya: 0.0003922408213838935\n",
      "batch loss 0.03636391833424568, batch loss prom: 0.035053666681051254, batch loss ss: 0.0008075552177615464, batch loss polya: 0.0005026984144933522\n",
      "batch loss 0.03287491202354431, batch loss prom: 0.01433879230171442, batch loss ss: 0.01851513795554638, batch loss polya: 2.098061486321967e-05\n",
      "batch loss 0.0025379229336977005, batch loss prom: 0.0012987758964300156, batch loss ss: 0.0012232924345880747, batch loss polya: 1.585470999998506e-05\n",
      "batch loss 0.0077650644816458225, batch loss prom: 0.0019566931296139956, batch loss ss: 0.005684282630681992, batch loss polya: 0.00012408917245920748\n",
      "batch loss 0.0318404957652092, batch loss prom: 0.002721655648201704, batch loss ss: 0.02900667116045952, batch loss polya: 0.00011216964776394889\n",
      "batch loss 0.0009670985164120793, batch loss prom: 0.0004138090298511088, batch loss ss: 0.00021717573690693825, batch loss polya: 0.0003361137059982866\n",
      "batch loss 0.0011095015797764063, batch loss prom: 0.0004239375703036785, batch loss ss: 0.00024101213784888387, batch loss polya: 0.000444551813416183\n",
      "batch loss 0.13636934757232666, batch loss prom: 0.13511744141578674, batch loss ss: 0.0009676303598098457, batch loss polya: 0.00028427375946193933\n",
      "batch loss 0.012265730649232864, batch loss prom: 0.0021370449103415012, batch loss ss: 0.009847867302596569, batch loss polya: 0.00028081765049137175\n",
      "batch loss 0.0011846753768622875, batch loss prom: 0.00047017011092975736, batch loss ss: 0.0001935771433636546, batch loss polya: 0.0005209281225688756\n",
      "batch loss 0.0009436310501769185, batch loss prom: 0.00032944019767455757, batch loss ss: 0.00029047083808109164, batch loss polya: 0.0003237200144212693\n",
      "batch loss 0.001261760713532567, batch loss prom: 0.0005785936955362558, batch loss ss: 0.00018714107864070684, batch loss polya: 0.0004960260121151805\n",
      "batch loss 0.0010867465753108263, batch loss prom: 0.00040999590419232845, batch loss ss: 0.00026651646476238966, batch loss polya: 0.0004102342063561082\n",
      "batch loss 0.16413940489292145, batch loss prom: 0.16210395097732544, batch loss ss: 0.0019171921303495765, batch loss polya: 0.00011824862303910777\n",
      "batch loss 0.012183533050119877, batch loss prom: 0.002177012851461768, batch loss ss: 0.009992810897529125, batch loss polya: 1.3708974620385561e-05\n",
      "batch loss 2.507307767868042, batch loss prom: 0.0016891986597329378, batch loss ss: 2.5055510997772217, batch loss polya: 6.758938252460212e-05\n",
      "batch loss 0.009595174342393875, batch loss prom: 0.003991494886577129, batch loss ss: 0.00547291524708271, batch loss polya: 0.00013076403411105275\n",
      "batch loss 0.0010956712067127228, batch loss prom: 0.00043072958942502737, batch loss ss: 0.0002040654799202457, batch loss polya: 0.000460876093711704\n",
      "batch loss 0.015970351174473763, batch loss prom: 0.0013711584033444524, batch loss ss: 0.014589297585189342, batch loss polya: 9.894321920000948e-06\n",
      "batch loss 0.0010034418664872646, batch loss prom: 0.0004440752090886235, batch loss ss: 0.00021419614495243877, batch loss polya: 0.00034517052699811757\n",
      "batch loss 0.005702740512788296, batch loss prom: 0.004760123789310455, batch loss ss: 0.0007981451926752925, batch loss polya: 0.00014447122521232814\n",
      "batch loss 0.0071459137834608555, batch loss prom: 0.0056998105719685555, batch loss ss: 0.001397348241880536, batch loss polya: 4.875540980719961e-05\n",
      "batch loss 0.0010207218583673239, batch loss prom: 0.00041762212640605867, batch loss ss: 0.00021038226259406656, batch loss polya: 0.0003927174839191139\n",
      "batch loss 0.00692491652444005, batch loss prom: 0.004193916916847229, batch loss ss: 0.0022826348431408405, batch loss polya: 0.0004483648226596415\n",
      "batch loss 0.0011113935615867376, batch loss prom: 0.0005113962688483298, batch loss ss: 0.00018940561858471483, batch loss polya: 0.00041059168870560825\n",
      "batch loss 0.009645640850067139, batch loss prom: 0.006937700789421797, batch loss ss: 0.0025868306402117014, batch loss polya: 0.00012110930401831865\n",
      "batch loss 0.0011414361651986837, batch loss prom: 0.0004343043256085366, batch loss ss: 0.00024482590379193425, batch loss polya: 0.00046230596490204334\n",
      "batch loss 0.000966735533438623, batch loss prom: 0.0004599228559527546, batch loss ss: 0.00022182388056535274, batch loss polya: 0.0002849888114724308\n",
      "batch loss 0.0009736607898958027, batch loss prom: 0.0003670972364488989, batch loss ss: 0.0002798642381094396, batch loss polya: 0.00032669928623363376\n",
      "batch loss 0.001089356024749577, batch loss prom: 0.0004120216181036085, batch loss ss: 0.00020716428116429597, batch loss polya: 0.00047017011092975736\n",
      "batch loss 0.006060977932065725, batch loss prom: 0.0013344916515052319, batch loss ss: 0.00468869786709547, batch loss polya: 3.7788631743751466e-05\n",
      "batch loss 0.002773511689156294, batch loss prom: 0.0011080323019996285, batch loss ss: 0.0004661188868340105, batch loss polya: 0.0011993603548035026\n",
      "batch loss 2.058823585510254, batch loss prom: 2.056206464767456, batch loss ss: 0.002526664873585105, batch loss polya: 9.047575440490618e-05\n",
      "batch loss 0.004997601732611656, batch loss prom: 0.00149555376265198, batch loss ss: 0.0034743917640298605, batch loss polya: 2.7656173188006505e-05\n",
      "batch loss 0.0021397038362920284, batch loss prom: 0.0007577646756544709, batch loss ss: 0.0001510267611593008, batch loss polya: 0.0012309125158935785\n",
      "batch loss 0.08720178157091141, batch loss prom: 0.0827220231294632, batch loss ss: 0.0043909563682973385, batch loss polya: 8.880697714630514e-05\n",
      "batch loss 0.0009300343226641417, batch loss prom: 0.00041261743172071874, batch loss ss: 0.00019774865359067917, batch loss polya: 0.0003196682082489133\n",
      "batch loss 0.04017772898077965, batch loss prom: 0.0008187517523765564, batch loss ss: 0.039324406534433365, batch loss polya: 3.45700973412022e-05\n",
      "batch loss 0.0139511339366436, batch loss prom: 0.002454246859997511, batch loss ss: 0.01129329763352871, batch loss polya: 0.00020358874462544918\n",
      "batch loss 0.010413561947643757, batch loss prom: 0.0008593680104240775, batch loss ss: 0.009473016485571861, batch loss polya: 8.11782301752828e-05\n",
      "batch loss 0.018979400396347046, batch loss prom: 0.007745116483420134, batch loss ss: 0.011209369637072086, batch loss polya: 2.4914430468925275e-05\n",
      "batch loss 0.003759238636121154, batch loss prom: 0.0024289172142744064, batch loss ss: 0.0012367465533316135, batch loss polya: 9.357491217087954e-05\n",
      "batch loss 0.0009636492468416691, batch loss prom: 0.00035768310772255063, batch loss ss: 0.00025781645672395825, batch loss polya: 0.00034814971149899065\n",
      "batch loss 0.012675908394157887, batch loss prom: 0.004273330792784691, batch loss ss: 0.008245829492807388, batch loss polya: 0.0001567479339428246\n",
      "batch loss 0.0021637901663780212, batch loss prom: 0.0012393658980727196, batch loss ss: 0.0008954567601904273, batch loss polya: 2.8967437174287625e-05\n",
      "batch loss 0.0011259375605732203, batch loss prom: 0.0004477690381463617, batch loss ss: 0.00020752183627337217, batch loss polya: 0.00047064671525731683\n",
      "batch loss 0.02721465937793255, batch loss prom: 0.0020399729255586863, batch loss ss: 0.025150248780846596, batch loss polya: 2.4437606043647975e-05\n",
      "batch loss 0.001145694637671113, batch loss prom: 0.0006050424999557436, batch loss ss: 0.00018046658078674227, batch loss polya: 0.0003601856005843729\n",
      "batch loss 0.11683424562215805, batch loss prom: 0.11475732922554016, batch loss ss: 0.0018506796332076192, batch loss polya: 0.00022623363474849612\n",
      "batch loss 0.011623449623584747, batch loss prom: 0.0035631281789392233, batch loss ss: 0.008043989539146423, batch loss polya: 1.6331539882230572e-05\n",
      "batch loss 0.1298423558473587, batch loss prom: 0.12696626782417297, batch loss ss: 0.0027416283264756203, batch loss polya: 0.00013445904187392443\n",
      "batch loss 0.45055410265922546, batch loss prom: 0.00395813025534153, batch loss ss: 0.4465869069099426, batch loss polya: 9.059865078597795e-06\n",
      "batch loss 0.014277955517172813, batch loss prom: 0.0010425376240164042, batch loss ss: 0.012945185415446758, batch loss polya: 0.00029023250681348145\n",
      "batch loss 0.0009427868062630296, batch loss prom: 0.00039414744242094457, batch loss ss: 0.00019870213873218745, batch loss polya: 0.0003499372396618128\n",
      "batch loss 0.009339440613985062, batch loss prom: 0.007743342313915491, batch loss ss: 0.0015391181223094463, batch loss polya: 5.6980417866725475e-05\n",
      "batch loss 0.023545414209365845, batch loss prom: 0.00206055399030447, batch loss ss: 0.021473297849297523, batch loss polya: 1.156323378381785e-05\n",
      "batch loss 0.020208554342389107, batch loss prom: 0.01623469777405262, batch loss ss: 0.0029466801788657904, batch loss polya: 0.0010271755745634437\n",
      "batch loss 0.09653452783823013, batch loss prom: 0.08839169144630432, batch loss ss: 0.007761676795780659, batch loss polya: 0.00038115866482257843\n",
      "batch loss 0.004993337672203779, batch loss prom: 0.0038467473350465298, batch loss ss: 0.0009090343955904245, batch loss polya: 0.00023755589791107923\n",
      "batch loss 0.0045015281066298485, batch loss prom: 0.0010552796302363276, batch loss ss: 0.0009634620510041714, batch loss polya: 0.0024827865418046713\n",
      "batch loss 0.0060744150541722775, batch loss prom: 0.004813630133867264, batch loss ss: 0.0008588915807195008, batch loss polya: 0.00040189296123571694\n",
      "batch loss 0.1235644593834877, batch loss prom: 0.12162932008504868, batch loss ss: 0.0018137923907488585, batch loss polya: 0.00012134769349358976\n",
      "batch loss 0.0009216931648552418, batch loss prom: 0.0004262015863787383, batch loss ss: 0.00023850933939684182, batch loss polya: 0.000256982195423916\n",
      "batch loss 0.002839948982000351, batch loss prom: 0.0021729685831815004, batch loss ss: 0.0003937899600714445, batch loss polya: 0.0002731903805397451\n",
      "batch loss 1.0933218002319336, batch loss prom: 1.0917150974273682, batch loss ss: 0.001505790394730866, batch loss polya: 0.00010096516780322418\n",
      "batch loss 0.0014709563693031669, batch loss prom: 0.0007672941428609192, batch loss ss: 0.00019178935326635838, batch loss polya: 0.0005118728731758893\n",
      "batch loss 0.0017780326306819916, batch loss prom: 0.0006743779522366822, batch loss ss: 0.00015555603022221476, batch loss polya: 0.0009480987209826708\n",
      "batch loss 0.0009578126482665539, batch loss prom: 0.0003369478799868375, batch loss ss: 0.0003045333724003285, batch loss polya: 0.0003163314249832183\n",
      "batch loss 0.0010089302668347955, batch loss prom: 0.00034671969478949904, batch loss ss: 0.0002499506517779082, batch loss polya: 0.0004122599493712187\n",
      "batch loss 0.011047426611185074, batch loss prom: 0.007526138331741095, batch loss ss: 0.0034601360093802214, batch loss polya: 6.115249561844394e-05\n",
      "batch loss 0.003787245601415634, batch loss prom: 0.0010188394226133823, batch loss ss: 0.0024668520782142878, batch loss polya: 0.00030155404238030314\n",
      "batch loss 0.12205137312412262, batch loss prom: 0.11921273916959763, batch loss ss: 0.002659833524376154, batch loss polya: 0.0001787979417713359\n",
      "batch loss 0.010204656049609184, batch loss prom: 0.001908744452521205, batch loss ss: 0.0082295136526227, batch loss polya: 6.639736966462806e-05\n",
      "batch loss 0.0009383849101141095, batch loss prom: 0.00037091050762683153, batch loss ss: 0.0003046525234822184, batch loss polya: 0.0002628219372127205\n",
      "batch loss 0.003307199804112315, batch loss prom: 0.0025933701545000076, batch loss ss: 0.0006833125371485949, batch loss polya: 3.0517112463712692e-05\n",
      "batch loss 0.18074218928813934, batch loss prom: 0.17793522775173187, batch loss ss: 0.0027393694035708904, batch loss polya: 6.758938252460212e-05\n",
      "batch loss 0.027720246464014053, batch loss prom: 0.0013608013978227973, batch loss ss: 0.026350026950240135, batch loss polya: 9.417489309271332e-06\n",
      "batch loss 0.007681503426283598, batch loss prom: 0.006361828185617924, batch loss ss: 0.0005466635921038687, batch loss polya: 0.0007730118231847882\n",
      "batch loss 0.0018069182988256216, batch loss prom: 0.0005133026279509068, batch loss ss: 0.000176652567461133, batch loss polya: 0.0011169631034135818\n",
      "batch loss 0.005710969213396311, batch loss prom: 0.002456030808389187, batch loss ss: 0.0031457485165446997, batch loss polya: 0.00010918975021922961\n",
      "batch loss 0.0009028684580698609, batch loss prom: 0.00036435641231946647, batch loss ss: 0.00021407696476671845, batch loss polya: 0.00032443503732793033\n",
      "batch loss 0.006368184462189674, batch loss prom: 0.0021807001903653145, batch loss ss: 0.004045992624014616, batch loss polya: 0.00014149141497910023\n",
      "batch loss 0.009185412898659706, batch loss prom: 0.007674850057810545, batch loss ss: 0.0015028145862743258, batch loss polya: 7.748573807475623e-06\n",
      "batch loss 0.011217602528631687, batch loss prom: 0.008281651884317398, batch loss ss: 0.0024661386851221323, batch loss polya: 0.0004698126285802573\n",
      "batch loss 0.005600859876722097, batch loss prom: 0.0019114810274913907, batch loss ss: 0.0036596960853785276, batch loss polya: 2.9682672902708873e-05\n",
      "batch loss 0.867926299571991, batch loss prom: 0.8630930185317993, batch loss ss: 0.00468869786709547, batch loss polya: 0.0001445904199499637\n",
      "batch loss 0.13736489415168762, batch loss prom: 0.13044342398643494, batch loss ss: 0.0062368521466851234, batch loss polya: 0.0006846229662187397\n",
      "batch loss 0.021384410560131073, batch loss prom: 0.0017353727016597986, batch loss ss: 0.019618401303887367, batch loss polya: 3.0636318115284666e-05\n",
      "batch loss 0.0009170480770990252, batch loss prom: 0.0003970073303207755, batch loss ss: 0.00021836756786797196, batch loss polya: 0.000301673193462193\n",
      "batch loss 0.10644625127315521, batch loss prom: 0.10334881395101547, batch loss ss: 0.0028247239533811808, batch loss polya: 0.0002727136597968638\n",
      "batch loss 0.010004603303968906, batch loss prom: 0.003693545935675502, batch loss ss: 0.005627029575407505, batch loss polya: 0.0006840273272246122\n",
      "batch loss 1.2074880599975586, batch loss prom: 1.2004419565200806, batch loss ss: 0.007012398913502693, batch loss polya: 3.373566141817719e-05\n",
      "batch loss 0.0009362340206280351, batch loss prom: 0.00038985759601928294, batch loss ss: 0.00020716428116429597, batch loss polya: 0.0003392120997887105\n",
      "batch loss 0.01797252893447876, batch loss prom: 0.0016994333127513528, batch loss ss: 0.016211943700909615, batch loss polya: 6.115249561844394e-05\n",
      "batch loss 0.0050576659850776196, batch loss prom: 0.002275260630995035, batch loss ss: 0.0027385372668504715, batch loss polya: 4.386805812828243e-05\n",
      "batch loss 2.0446994304656982, batch loss prom: 0.08912528306245804, batch loss ss: 1.9555667638778687, batch loss polya: 7.390948667307384e-06\n",
      "batch loss 0.005575595889240503, batch loss prom: 0.0014671048847958446, batch loss ss: 0.003881065873429179, batch loss polya: 0.00022742546570952982\n",
      "batch loss 0.005117692053318024, batch loss prom: 0.001450320822186768, batch loss ss: 0.0036472247447818518, batch loss polya: 2.0146166207268834e-05\n",
      "batch loss 0.013188297860324383, batch loss prom: 0.003814208786934614, batch loss ss: 0.009109956212341785, batch loss polya: 0.0002641328901518136\n",
      "batch loss 0.0009162192000076175, batch loss prom: 0.00036423723213374615, batch loss ss: 0.00026770823751576245, batch loss polya: 0.00028427375946193933\n",
      "batch loss 0.0009846148313954473, batch loss prom: 0.00040189296123571694, batch loss ss: 0.0002053765201708302, batch loss polya: 0.0003773453936446458\n",
      "batch loss 0.005811184179037809, batch loss prom: 0.0019406310748308897, batch loss ss: 0.0036944961175322533, batch loss polya: 0.0001760566228767857\n",
      "batch loss 0.0014011950697749853, batch loss prom: 0.000567275274079293, batch loss ss: 0.0007814691052772105, batch loss polya: 5.245071224635467e-05\n",
      "batch loss 0.010431881994009018, batch loss prom: 0.0008149401983246207, batch loss ss: 0.00958082266151905, batch loss polya: 3.611976353568025e-05\n",
      "batch loss 0.0010836493456736207, batch loss prom: 0.0004262015863787383, batch loss ss: 0.0003798478574026376, batch loss polya: 0.0002775999018922448\n",
      "batch loss 0.001135560916736722, batch loss prom: 0.0006182666402310133, batch loss ss: 0.00017414960893802345, batch loss polya: 0.00034314466756768525\n",
      "batch loss 0.01120406948029995, batch loss prom: 0.007617592345923185, batch loss ss: 0.003567642066627741, batch loss polya: 1.883488948806189e-05\n",
      "batch loss 0.0009129972313530743, batch loss prom: 0.00038628268521279097, batch loss ss: 0.00021944021864328533, batch loss polya: 0.00030727434204891324\n",
      "batch loss 0.006370557006448507, batch loss prom: 0.0015939876902848482, batch loss ss: 0.004467388149350882, batch loss polya: 0.0003091811086051166\n",
      "batch loss 0.004362897016108036, batch loss prom: 0.0008723505889065564, batch loss ss: 0.0034565723035484552, batch loss polya: 3.397406908334233e-05\n",
      "batch loss 2.2254700660705566, batch loss prom: 0.002639027079567313, batch loss ss: 2.222825527191162, batch loss polya: 5.483612312673358e-06\n",
      "batch loss 0.007849892601370811, batch loss prom: 0.0033257671166211367, batch loss ss: 0.004241162445396185, batch loss polya: 0.0002829628065228462\n",
      "batch loss 0.0032311943359673023, batch loss prom: 0.0007110689766705036, batch loss ss: 0.002369098598137498, batch loss polya: 0.0001510267611593008\n",
      "batch loss 0.008776054717600346, batch loss prom: 0.007547908462584019, batch loss ss: 0.001148755894973874, batch loss polya: 7.939023635117337e-05\n",
      "batch loss 0.0025013501290231943, batch loss prom: 0.0009841842111200094, batch loss ss: 0.00013529339048545808, batch loss polya: 0.0013818725710734725\n",
      "batch loss 0.022584419697523117, batch loss prom: 0.002842911286279559, batch loss ss: 0.019224394112825394, batch loss polya: 0.0005171154043637216\n",
      "batch loss 0.2309415191411972, batch loss prom: 0.22612877190113068, batch loss ss: 0.004799393936991692, batch loss polya: 1.3351351299206726e-05\n",
      "batch loss 0.001441057538613677, batch loss prom: 0.0007706294418312609, batch loss ss: 0.00022659118985757232, batch loss polya: 0.00044383687782101333\n",
      "batch loss 0.001155210891738534, batch loss prom: 0.0006700892699882388, batch loss ss: 0.00020692592079285532, batch loss polya: 0.000278195773717016\n",
      "batch loss 0.0009930719388648868, batch loss prom: 0.0004530118894763291, batch loss ss: 0.00020394629973452538, batch loss polya: 0.0003361137059982866\n",
      "batch loss 0.000923122453968972, batch loss prom: 0.00042834642226807773, batch loss ss: 0.00022420754248742014, batch loss polya: 0.00027056847466155887\n",
      "batch loss 0.014491465874016285, batch loss prom: 0.0009410720085725188, batch loss ss: 0.013483996503055096, batch loss polya: 6.639736966462806e-05\n",
      "batch loss 0.010823854245245457, batch loss prom: 0.0016445695655420423, batch loss ss: 0.008900374174118042, batch loss polya: 0.00027891082572750747\n",
      "batch loss 1.3072237968444824, batch loss prom: 0.013098035007715225, batch loss ss: 1.2941174507141113, batch loss polya: 8.34461570775602e-06\n",
      "batch loss 0.005247277207672596, batch loss prom: 0.0019016055157408118, batch loss ss: 0.003008247120305896, batch loss polya: 0.00033742457162588835\n",
      "batch loss 0.871522068977356, batch loss prom: 0.869920551776886, batch loss ss: 0.0015736351488158107, batch loss polya: 2.7894584491150454e-05\n",
      "batch loss 0.0009804547298699617, batch loss prom: 0.00035684893373399973, batch loss ss: 0.0003103728231508285, batch loss polya: 0.00031323294388130307\n",
      "batch loss 0.0017873040633276105, batch loss prom: 0.0009975224966183305, batch loss ss: 0.00014518637908622622, batch loss polya: 0.0006445952458307147\n",
      "batch loss 0.004204160533845425, batch loss prom: 0.0009173714206553996, batch loss ss: 0.0030122878961265087, batch loss polya: 0.00027450130437500775\n",
      "batch loss 0.007336857728660107, batch loss prom: 0.001657184911891818, batch loss ss: 0.005592296365648508, batch loss polya: 8.737658936297521e-05\n",
      "batch loss 0.0010159550001844764, batch loss prom: 0.00041130665340460837, batch loss ss: 0.00020787939138244838, batch loss polya: 0.0003967689990531653\n",
      "batch loss 0.285954087972641, batch loss prom: 0.2725841701030731, batch loss ss: 0.013171215541660786, batch loss polya: 0.00019870213873218745\n",
      "batch loss 0.007173910737037659, batch loss prom: 0.002543668495491147, batch loss ss: 0.004404961597174406, batch loss polya: 0.0002252801787108183\n",
      "batch loss 0.11413055658340454, batch loss prom: 0.10447558015584946, batch loss ss: 0.009605145081877708, batch loss polya: 4.9828242481453344e-05\n",
      "batch loss 0.0016656133811920881, batch loss prom: 0.0007976687629707158, batch loss ss: 0.00017271934484597296, batch loss polya: 0.0006952252588234842\n",
      "batch loss 0.0009040615987032652, batch loss prom: 0.0003796095261350274, batch loss ss: 0.0002585315378382802, batch loss polya: 0.00026592056383378804\n",
      "batch loss 0.035273171961307526, batch loss prom: 0.034644965082407, batch loss ss: 0.0005295066512189806, batch loss polya: 9.870042413240299e-05\n",
      "batch loss 0.0032367741223424673, batch loss prom: 0.00039641151670366526, batch loss ss: 0.0027287888806313276, batch loss polya: 0.00011157367407577112\n",
      "batch loss 0.0030470325145870447, batch loss prom: 0.0020881532691419125, batch loss ss: 0.0008893824997358024, batch loss polya: 6.949660019017756e-05\n",
      "batch loss 0.006923703942447901, batch loss prom: 0.0012185298837721348, batch loss ss: 0.005367510952055454, batch loss polya: 0.00033766290289349854\n",
      "batch loss 0.0012564004864543676, batch loss prom: 0.0005975367967039347, batch loss ss: 0.0001998939987970516, batch loss polya: 0.0004589696181938052\n",
      "batch loss 0.008563559502363205, batch loss prom: 0.0015582811320200562, batch loss ss: 0.00686962716281414, batch loss polya: 0.00013565097469836473\n",
      "batch loss 0.014749578200280666, batch loss prom: 0.005303124897181988, batch loss ss: 0.009420584887266159, batch loss polya: 2.586808113846928e-05\n",
      "batch loss 0.00113007053732872, batch loss prom: 0.0006548406090587378, batch loss ss: 0.00020418466010596603, batch loss polya: 0.00027104519540444016\n",
      "batch loss 0.008566316217184067, batch loss prom: 0.0028002357576042414, batch loss ss: 0.005637223832309246, batch loss polya: 0.00012885693286079913\n",
      "batch loss 0.01295703835785389, batch loss prom: 0.0015844660811126232, batch loss ss: 0.01128233503550291, batch loss polya: 9.023735765367746e-05\n",
      "batch loss 0.04577724263072014, batch loss prom: 0.04235440492630005, batch loss ss: 0.00342105096206069, batch loss polya: 1.7881377516459906e-06\n",
      "batch loss 0.0010737499687820673, batch loss prom: 0.0004503904783632606, batch loss ss: 0.0002227773511549458, batch loss polya: 0.00040058218291960657\n",
      "batch loss 0.02015276439487934, batch loss prom: 0.000645429186988622, batch loss ss: 0.01944725587964058, batch loss polya: 6.007967749610543e-05\n",
      "batch loss 0.011592986062169075, batch loss prom: 0.002118725562468171, batch loss ss: 0.009391652420163155, batch loss polya: 8.260862523457035e-05\n",
      "batch loss 1.445299744606018, batch loss prom: 1.4405972957611084, batch loss ss: 0.004689765628427267, batch loss polya: 1.2636104656849056e-05\n",
      "batch loss 0.0009596921154297888, batch loss prom: 0.0005049622268415987, batch loss ss: 0.00018416139937471598, batch loss polya: 0.00027056847466155887\n",
      "batch loss 0.08101475238800049, batch loss prom: 0.07519356906414032, batch loss ss: 0.005631415639072657, batch loss polya: 0.00018976318824570626\n",
      "batch loss 0.007494967896491289, batch loss prom: 0.006444031372666359, batch loss ss: 0.000832449528388679, batch loss polya: 0.0002184867626056075\n",
      "batch loss 0.06635991483926773, batch loss prom: 0.0563209243118763, batch loss ss: 0.008699494414031506, batch loss polya: 0.0013394916895776987\n",
      "batch loss 0.007150378078222275, batch loss prom: 0.0019011296099051833, batch loss ss: 0.005117650143802166, batch loss polya: 0.00013159839727450162\n",
      "batch loss 0.01003264170140028, batch loss prom: 0.00870776642113924, batch loss ss: 0.0013047285610809922, batch loss polya: 2.0146166207268834e-05\n",
      "batch loss 0.0022084438242018223, batch loss prom: 0.001737157697789371, batch loss ss: 0.00034397884155623615, batch loss polya: 0.00012730741582345217\n",
      "batch loss 0.0009303895058110356, batch loss prom: 0.0004234609368722886, batch loss ss: 0.00018845213344320655, batch loss polya: 0.0003184764937032014\n",
      "batch loss 0.014874929562211037, batch loss prom: 0.0014444880653172731, batch loss ss: 0.01337143499404192, batch loss polya: 5.900685573578812e-05\n",
      "batch loss 0.020697712898254395, batch loss prom: 0.0027138092555105686, batch loss ss: 0.017913930118083954, batch loss polya: 6.997340824455023e-05\n",
      "batch loss 0.012305617332458496, batch loss prom: 0.006124656647443771, batch loss ss: 0.0061378078535199165, batch loss polya: 4.31528314948082e-05\n",
      "batch loss 0.09840422868728638, batch loss prom: 0.07636198401451111, batch loss ss: 0.022017447277903557, batch loss polya: 2.47952248173533e-05\n",
      "batch loss 0.6115198731422424, batch loss prom: 0.5751330256462097, batch loss ss: 0.03638302534818649, batch loss polya: 3.814689989667386e-06\n",
      "batch loss 0.002271414967253804, batch loss prom: 0.0008148210472427309, batch loss ss: 0.00015555603022221476, batch loss polya: 0.0013010379625484347\n",
      "batch loss 0.010203592479228973, batch loss prom: 0.009189571253955364, batch loss ss: 0.0009464313625358045, batch loss polya: 6.758938252460212e-05\n",
      "batch loss 0.0009071609820239246, batch loss prom: 0.00037353215157054365, batch loss ss: 0.00026603974401950836, batch loss polya: 0.0002675890573300421\n",
      "batch loss 0.0009377745445817709, batch loss prom: 0.000460876093711704, batch loss ss: 0.00020597243565134704, batch loss polya: 0.00027092601521871984\n",
      "batch loss 0.0008740249322727323, batch loss prom: 0.0003854485403280705, batch loss ss: 0.0001915509783430025, batch loss polya: 0.00029702542815357447\n",
      "batch loss 0.11491768807172775, batch loss prom: 0.11020702868700027, batch loss ss: 0.004603858571499586, batch loss polya: 0.00010680581908673048\n",
      "batch loss 0.0008996495162136853, batch loss prom: 0.00039104922325350344, batch loss ss: 0.0002213471452705562, batch loss polya: 0.00028725311858579516\n",
      "batch loss 0.006667385343462229, batch loss prom: 0.0014360364293679595, batch loss ss: 0.0051218015141785145, batch loss polya: 0.00010954733443213627\n",
      "batch loss 0.0012363765854388475, batch loss prom: 0.0005260513862594962, batch loss ss: 0.00016532962035853416, batch loss polya: 0.0005449955351650715\n",
      "batch loss 0.007847615517675877, batch loss prom: 0.002118487609550357, batch loss ss: 0.005616005044430494, batch loss polya: 0.00011312322021694854\n",
      "batch loss 0.023443151265382767, batch loss prom: 0.0010996968485414982, batch loss ss: 0.022268950939178467, batch loss polya: 7.450303382938728e-05\n",
      "batch loss 0.007149908691644669, batch loss prom: 0.0016515913885086775, batch loss ss: 0.005145639646798372, batch loss polya: 0.0003526780928950757\n",
      "batch loss 0.008134102448821068, batch loss prom: 0.0014106809394434094, batch loss ss: 0.006666799075901508, batch loss polya: 5.6622808187967166e-05\n",
      "batch loss 0.0008952408097684383, batch loss prom: 0.00039081089198589325, batch loss ss: 0.00026472879108041525, batch loss polya: 0.0002397011558059603\n",
      "batch loss 0.0009203843073919415, batch loss prom: 0.0003906917118001729, batch loss ss: 0.00020716428116429597, batch loss polya: 0.0003225283289793879\n",
      "batch loss 0.7524698376655579, batch loss prom: 0.730497419834137, batch loss ss: 0.021962404251098633, batch loss polya: 1.0013530300057027e-05\n",
      "batch loss 0.006753371562808752, batch loss prom: 0.0028449322562664747, batch loss ss: 0.0037325017619878054, batch loss polya: 0.00017593742813915014\n",
      "batch loss 0.0008391106966882944, batch loss prom: 0.00036352223833091557, batch loss ss: 0.00023052419419400394, batch loss polya: 0.0002450642641633749\n",
      "batch loss 0.41934025287628174, batch loss prom: 0.41828516125679016, batch loss ss: 0.0010063351364806294, batch loss polya: 4.875540980719961e-05\n",
      "batch loss 0.006291643716394901, batch loss prom: 0.0019954785238951445, batch loss ss: 0.0042006829753518105, batch loss polya: 9.548207890475169e-05\n",
      "batch loss 0.006904658395797014, batch loss prom: 0.0019006537040695548, batch loss ss: 0.0049356999807059765, batch loss polya: 6.83045873302035e-05\n",
      "batch loss 0.0074675967916846275, batch loss prom: 0.0023855105973780155, batch loss ss: 0.00488386070355773, batch loss polya: 0.00019822540343739092\n",
      "batch loss 0.15418508648872375, batch loss prom: 0.10541988909244537, batch loss ss: 0.04874265938997269, batch loss polya: 2.253030106658116e-05\n",
      "batch loss 0.0009953207336366177, batch loss prom: 0.0005236684810370207, batch loss ss: 0.0001784403866622597, batch loss polya: 0.0002932118659373373\n",
      "batch loss 0.008531908504664898, batch loss prom: 0.0012378181563690305, batch loss ss: 0.007111001759767532, batch loss polya: 0.00018308870494365692\n",
      "batch loss 0.228831484913826, batch loss prom: 0.2245953232049942, batch loss ss: 0.004211010877043009, batch loss polya: 2.5152843591058627e-05\n",
      "batch loss 0.007173116784542799, batch loss prom: 0.0024016841780394316, batch loss ss: 0.004738411866128445, batch loss polya: 3.302042750874534e-05\n",
      "batch loss 0.00330174108967185, batch loss prom: 0.0020272433757781982, batch loss ss: 0.0011643542675301433, batch loss polya: 0.00011014331539627165\n",
      "batch loss 0.06414569914340973, batch loss prom: 0.001116129569709301, batch loss ss: 0.06302063167095184, batch loss polya: 8.940656698541716e-06\n",
      "batch loss 0.012754558585584164, batch loss prom: 0.006496145389974117, batch loss ss: 0.006122523918747902, batch loss polya: 0.0001358893496217206\n",
      "batch loss 0.0009782982524484396, batch loss prom: 0.0004256058018654585, batch loss ss: 0.00020859450160060078, batch loss polya: 0.00034409802174195647\n",
      "batch loss 0.0015628424007445574, batch loss prom: 0.000662703241687268, batch loss ss: 0.000856509490404278, batch loss polya: 4.362964682513848e-05\n",
      "batch loss 0.000977925257757306, batch loss prom: 0.0005060345865786076, batch loss ss: 0.0001793938863556832, batch loss polya: 0.0002924968139268458\n",
      "batch loss 0.0008898741798475385, batch loss prom: 0.00039545822073705494, batch loss ss: 0.00019238528329879045, batch loss polya: 0.000302030734019354\n",
      "batch loss 0.01190251111984253, batch loss prom: 0.001383539172820747, batch loss ss: 0.01047081220895052, batch loss polya: 4.815939246327616e-05\n",
      "batch loss 0.013586096465587616, batch loss prom: 0.011574379168450832, batch loss ss: 0.0010350352386012673, batch loss polya: 0.0009766814764589071\n",
      "batch loss 0.0008991635404527187, batch loss prom: 0.00044216870446689427, batch loss ss: 0.00019238528329879045, batch loss polya: 0.0002646096108946949\n",
      "batch loss 0.002520941197872162, batch loss prom: 0.0007889734115451574, batch loss ss: 0.0016305259196087718, batch loss polya: 0.00010144196130568162\n",
      "batch loss 0.0008790339343249798, batch loss prom: 0.00036090059438720345, batch loss ss: 0.0002113357331836596, batch loss polya: 0.0003067976504098624\n",
      "batch loss 0.018067266792058945, batch loss prom: 0.004152486100792885, batch loss ss: 0.013910369016230106, batch loss polya: 4.410734163684538e-06\n",
      "batch loss 0.004715668503195047, batch loss prom: 0.0018982740584760904, batch loss ss: 0.0027594605926424265, batch loss polya: 5.793403761344962e-05\n",
      "batch loss 0.00382969225756824, batch loss prom: 0.000595034915022552, batch loss ss: 0.003151452634483576, batch loss polya: 8.320462075062096e-05\n",
      "batch loss 0.004731489811092615, batch loss prom: 0.003349529579281807, batch loss ss: 0.00051115796668455, batch loss polya: 0.0008708022069185972\n",
      "batch loss 0.03730305656790733, batch loss prom: 0.0015961299650371075, batch loss ss: 0.03570263460278511, batch loss polya: 4.291525328881107e-06\n",
      "batch loss 0.028182484209537506, batch loss prom: 0.025461165234446526, batch loss ss: 0.002232323167845607, batch loss polya: 0.0004889961564913392\n",
      "batch loss 0.000858651997987181, batch loss prom: 0.0003936707798857242, batch loss ss: 0.00021872512297704816, batch loss polya: 0.00024625606602057815\n",
      "batch loss 1.1132045984268188, batch loss prom: 0.022322693839669228, batch loss ss: 1.0908795595169067, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.009413635358214378, batch loss prom: 0.0009793015196919441, batch loss ss: 0.007562579121440649, batch loss polya: 0.0008717550663277507\n",
      "batch loss 0.1427115499973297, batch loss prom: 0.12957346439361572, batch loss ss: 0.012997196987271309, batch loss polya: 0.0001408954558428377\n",
      "batch loss 0.001304843695834279, batch loss prom: 0.000647692708298564, batch loss ss: 0.0005758534534834325, batch loss polya: 8.129743218887597e-05\n",
      "batch loss 0.009371498599648476, batch loss prom: 0.0030885871965438128, batch loss ss: 0.006190767046064138, batch loss polya: 9.214453893946484e-05\n",
      "batch loss 0.0009572026319801807, batch loss prom: 0.00041476229671388865, batch loss ss: 0.00018404220463708043, batch loss polya: 0.0003583981015253812\n",
      "batch loss 0.024154052138328552, batch loss prom: 0.009231857024133205, batch loss ss: 0.014913849532604218, batch loss polya: 8.34461570775602e-06\n",
      "batch loss 0.012792634777724743, batch loss prom: 0.00047922570956870914, batch loss ss: 0.012294931337237358, batch loss polya: 1.847726889536716e-05\n",
      "batch loss 0.0018909632926806808, batch loss prom: 0.0010933857411146164, batch loss ss: 0.0007608617888763547, batch loss polya: 3.671578815556131e-05\n",
      "batch loss 0.001990628195926547, batch loss prom: 0.0007348936051130295, batch loss ss: 0.0012081712484359741, batch loss polya: 4.756337511935271e-05\n",
      "batch loss 0.0013852844713255763, batch loss prom: 0.0007414452848024666, batch loss ss: 0.00016139635408762842, batch loss polya: 0.000482442817883566\n",
      "batch loss 0.0024000215344130993, batch loss prom: 0.0018319981172680855, batch loss ss: 0.0005013877525925636, batch loss polya: 6.663577369181439e-05\n",
      "batch loss 0.11662238091230392, batch loss prom: 0.014705010689795017, batch loss ss: 0.10190366208553314, batch loss polya: 1.3708974620385561e-05\n",
      "batch loss 0.004455090034753084, batch loss prom: 0.0026949062012135983, batch loss ss: 0.0008472190820612013, batch loss polya: 0.0009129646932706237\n",
      "batch loss 0.0009034673566929996, batch loss prom: 0.0003626880934461951, batch loss ss: 0.00025674383505247533, batch loss polya: 0.0002840353990904987\n",
      "batch loss 0.0030240165069699287, batch loss prom: 0.0017008613795042038, batch loss ss: 0.0012490098597481847, batch loss polya: 7.414542778860778e-05\n",
      "batch loss 0.005306904669851065, batch loss prom: 0.003795682918280363, batch loss ss: 0.001459605642594397, batch loss polya: 5.1616290875244886e-05\n",
      "batch loss 0.18659192323684692, batch loss prom: 0.18399587273597717, batch loss ss: 0.002251710742712021, batch loss polya: 0.00034433635300956666\n",
      "batch loss 0.010948797687888145, batch loss prom: 0.001723591354675591, batch loss ss: 0.009085621684789658, batch loss polya: 0.00013958434283267707\n",
      "batch loss 0.0008839236106723547, batch loss prom: 0.00034505134681239724, batch loss ss: 0.00024971229140646756, batch loss polya: 0.000289159914245829\n",
      "batch loss 0.009905500337481499, batch loss prom: 0.0020137999672442675, batch loss ss: 0.007857130840420723, batch loss polya: 3.45700973412022e-05\n",
      "batch loss 0.019706429913640022, batch loss prom: 0.002531896810978651, batch loss ss: 0.017169645056128502, batch loss polya: 4.887569048150908e-06\n",
      "batch loss 0.008910593576729298, batch loss prom: 0.008065748028457165, batch loss ss: 0.0006466205231845379, batch loss polya: 0.00019822540343739092\n",
      "batch loss 0.0015498176217079163, batch loss prom: 0.0008238735608756542, batch loss ss: 0.0001958416833076626, batch loss polya: 0.0005301024066284299\n",
      "batch loss 0.031801819801330566, batch loss prom: 0.0014350840356200933, batch loss ss: 0.030344204977154732, batch loss polya: 2.253030106658116e-05\n",
      "batch loss 0.010091765783727169, batch loss prom: 0.009018165990710258, batch loss ss: 0.0009696549386717379, batch loss polya: 0.00010394509445177391\n",
      "batch loss 0.002331299241632223, batch loss prom: 0.0019621660467237234, batch loss ss: 0.00033945043105632067, batch loss polya: 2.9682672902708873e-05\n",
      "batch loss 0.002750799059867859, batch loss prom: 0.0017539369873702526, batch loss ss: 0.0009392855572514236, batch loss polya: 5.757642793469131e-05\n",
      "batch loss 0.20410878956317902, batch loss prom: 0.20224979519844055, batch loss ss: 0.0017283515771850944, batch loss polya: 0.00013064485392533243\n",
      "batch loss 0.000861279433593154, batch loss prom: 0.0003522014303598553, batch loss ss: 0.00024482590379193425, batch loss polya: 0.00026425207033753395\n",
      "batch loss 0.002455978887155652, batch loss prom: 0.001404966926202178, batch loss ss: 0.001032177242450416, batch loss polya: 1.883488948806189e-05\n",
      "batch loss 0.002154803369194269, batch loss prom: 0.000713213172275573, batch loss ss: 0.0001530530134914443, batch loss polya: 0.0012885371688753366\n",
      "batch loss 0.023493565618991852, batch loss prom: 0.022710122168064117, batch loss ss: 0.0006824786541983485, batch loss polya: 0.00010096516780322418\n",
      "batch loss 0.06060106307268143, batch loss prom: 0.007502830121666193, batch loss ss: 0.04904178902506828, batch loss polya: 0.00405644066631794\n",
      "batch loss 0.013282249681651592, batch loss prom: 0.003130062250420451, batch loss ss: 0.010134901851415634, batch loss polya: 1.728519782773219e-05\n",
      "batch loss 0.004120771307498217, batch loss prom: 0.0021244355011731386, batch loss ss: 0.0019840572495013475, batch loss polya: 1.2278481335670222e-05\n",
      "batch loss 0.0009551710681989789, batch loss prom: 0.0004412154376041144, batch loss ss: 0.00016318420239258558, batch loss polya: 0.0003507714136503637\n",
      "batch loss 0.020444510504603386, batch loss prom: 0.0009607228566892445, batch loss ss: 0.019450528547167778, batch loss polya: 3.325883881188929e-05\n",
      "batch loss 0.0008369654533453286, batch loss prom: 0.00034540885826572776, batch loss ss: 0.00019941726350225508, batch loss polya: 0.00029213930247351527\n",
      "batch loss 0.008044028654694557, batch loss prom: 0.006789826788008213, batch loss ss: 0.00119304982945323, batch loss polya: 6.115249561844394e-05\n",
      "batch loss 0.0009697118075564504, batch loss prom: 0.00044347942457534373, batch loss ss: 0.00017689094238448888, batch loss polya: 0.0003493413969408721\n",
      "batch loss 0.0015570961404591799, batch loss prom: 0.0008434075862169266, batch loss ss: 0.0004530118894763291, batch loss polya: 0.00026067672297358513\n",
      "batch loss 0.0012698362115770578, batch loss prom: 0.000686767278239131, batch loss ss: 0.00015758226800244302, batch loss polya: 0.00042548662167973816\n",
      "batch loss 0.010408391244709492, batch loss prom: 0.002638432662934065, batch loss ss: 0.007383794989436865, batch loss polya: 0.0003861635341309011\n",
      "batch loss 0.008573194034397602, batch loss prom: 0.0006001578294672072, batch loss ss: 0.007897698320448399, batch loss polya: 7.533743337262422e-05\n",
      "batch loss 0.0009829337941482663, batch loss prom: 0.0004773192631546408, batch loss ss: 0.00016675988445058465, batch loss polya: 0.00033885458833537996\n",
      "batch loss 0.0008405427797697484, batch loss prom: 0.00034648136352188885, batch loss ss: 0.00024029705673456192, batch loss polya: 0.00025376438861712813\n",
      "batch loss 0.01171877421438694, batch loss prom: 0.0011162485461682081, batch loss ss: 0.010573438368737698, batch loss polya: 2.90866428258596e-05\n",
      "batch loss 0.011891139671206474, batch loss prom: 0.0008268513483926654, batch loss ss: 0.01100683119148016, batch loss polya: 5.745722592109814e-05\n",
      "batch loss 0.0008764166850596666, batch loss prom: 0.0003296785580459982, batch loss ss: 0.0002609150833450258, batch loss polya: 0.0002858230145648122\n",
      "batch loss 0.0012142143677920103, batch loss prom: 0.000590865034610033, batch loss ss: 0.0001770101225702092, batch loss polya: 0.0004463391669560224\n",
      "batch loss 0.047092504799366, batch loss prom: 0.005551871843636036, batch loss ss: 0.041444435715675354, batch loss polya: 9.619726915843785e-05\n",
      "batch loss 0.07480523735284805, batch loss prom: 0.0695221945643425, batch loss ss: 0.00490248529240489, batch loss polya: 0.0003805628512054682\n",
      "batch loss 0.007160280831158161, batch loss prom: 0.004076267592608929, batch loss ss: 0.003024529432877898, batch loss polya: 5.94836674281396e-05\n",
      "batch loss 0.0008515036897733808, batch loss prom: 0.00034981805947609246, batch loss ss: 0.00019262365822214633, batch loss polya: 0.0003090619284193963\n",
      "batch loss 0.006609128322452307, batch loss prom: 0.003947918768972158, batch loss ss: 0.0023826563265174627, batch loss polya: 0.00027855331427417696\n",
      "batch loss 0.0009593459544703364, batch loss prom: 0.00043335105874575675, batch loss ss: 0.0001821352052502334, batch loss polya: 0.0003438596613705158\n",
      "batch loss 0.0009393214131705463, batch loss prom: 0.0004451475979294628, batch loss ss: 0.00016425691137555987, batch loss polya: 0.0003299168893136084\n",
      "batch loss 0.01134274248033762, batch loss prom: 0.0032834685407578945, batch loss ss: 0.008026015013456345, batch loss polya: 3.325883881188929e-05\n",
      "batch loss 0.5689629316329956, batch loss prom: 0.4221736192703247, batch loss ss: 0.1467561423778534, batch loss polya: 3.313963316031732e-05\n",
      "batch loss 0.005420419853180647, batch loss prom: 0.004624742548912764, batch loss ss: 0.0007509748684242368, batch loss polya: 4.470248313737102e-05\n",
      "batch loss 0.0022923084907233715, batch loss prom: 0.0013522299705073237, batch loss ss: 0.0008475763606838882, batch loss polya: 9.250213042832911e-05\n",
      "batch loss 0.022179191932082176, batch loss prom: 0.0009168949909508228, batch loss ss: 0.02124691940844059, batch loss polya: 1.537788011773955e-05\n",
      "batch loss 0.0009505212074145675, batch loss prom: 0.0004481264913920313, batch loss ss: 0.00015484087634831667, batch loss polya: 0.0003475538978818804\n",
      "batch loss 0.0644390881061554, batch loss prom: 0.062445268034935, batch loss ss: 0.00199167151004076, batch loss polya: 2.145764938177308e-06\n",
      "batch loss 0.0009495678241364658, batch loss prom: 0.00044800734031014144, batch loss ss: 0.00015448330668732524, batch loss polya: 0.00034707720624282956\n",
      "batch loss 0.12783214449882507, batch loss prom: 0.12585952877998352, batch loss ss: 0.0018490137299522758, batch loss polya: 0.00012361239350866526\n",
      "batch loss 0.0029484147671610117, batch loss prom: 0.0019054129952564836, batch loss ss: 0.0009279712685383856, batch loss polya: 0.00011503035057103261\n",
      "batch loss 0.0008722394704818726, batch loss prom: 0.0003592322755139321, batch loss ss: 0.00019488819816615433, batch loss polya: 0.0003181189822498709\n",
      "-----\n",
      "prom acc: 88.75, prom loss: 0.1979399025440216\n",
      "ss acc: 80.0, ss loss: 0.7250361442565918\n",
      "polya acc: 100.0, polya loss: 0.00018681841902434826\n",
      "-----\n",
      "batch loss 0.04836026579141617, batch loss prom: 0.010636702179908752, batch loss ss: 0.03599579259753227, batch loss polya: 0.001727768685668707\n",
      "batch loss 0.011639392003417015, batch loss prom: 0.0028525397647172213, batch loss ss: 0.008756335824728012, batch loss polya: 3.0517112463712692e-05\n",
      "batch loss 0.0011722143972292542, batch loss prom: 0.0006778326351195574, batch loss ss: 0.0004401430196594447, batch loss polya: 5.4238757002167404e-05\n",
      "batch loss 0.015555992722511292, batch loss prom: 0.006214224733412266, batch loss ss: 0.009308509528636932, batch loss polya: 3.325883881188929e-05\n",
      "batch loss 0.007521120831370354, batch loss prom: 0.0021785590797662735, batch loss ss: 0.005238378420472145, batch loss polya: 0.00010418349120300263\n",
      "batch loss 0.011725688353180885, batch loss prom: 0.0030242919456213713, batch loss ss: 0.008617476560175419, batch loss polya: 8.391981828026474e-05\n",
      "batch loss 0.001385234179906547, batch loss prom: 0.0008635367848910391, batch loss ss: 0.00014435203047469258, batch loss polya: 0.0003773453936446458\n",
      "batch loss 0.0701647698879242, batch loss prom: 0.059641629457473755, batch loss ss: 0.009505725465714931, batch loss polya: 0.0010174104245379567\n",
      "batch loss 0.000957194366492331, batch loss prom: 0.0004667146422434598, batch loss ss: 0.00016556799528189003, batch loss polya: 0.00032491172896698117\n",
      "batch loss 0.0008138431003317237, batch loss prom: 0.0003518439189065248, batch loss ss: 0.0001793938863556832, batch loss polya: 0.0002826052950695157\n",
      "batch loss 0.0009525483474135399, batch loss prom: 0.00045563330058939755, batch loss ss: 0.00016652150952722877, batch loss polya: 0.0003303935518488288\n",
      "batch loss 0.013257523998618126, batch loss prom: 0.011857031844556332, batch loss ss: 0.0011504229623824358, batch loss polya: 0.00025006983196362853\n",
      "batch loss 0.012750314548611641, batch loss prom: 0.0033658065367490053, batch loss ss: 0.009365434758365154, batch loss polya: 1.9073304429184645e-05\n",
      "batch loss 0.013922607526183128, batch loss prom: 0.004029964096844196, batch loss ss: 0.005783964414149523, batch loss polya: 0.004108679015189409\n",
      "batch loss 0.002669772831723094, batch loss prom: 0.0021541742607951164, batch loss ss: 0.0004430027911439538, batch loss polya: 7.259582343976945e-05\n",
      "batch loss 0.0014717919984832406, batch loss prom: 0.0006905793561600149, batch loss ss: 0.00016330339713022113, batch loss polya: 0.0006179092451930046\n",
      "batch loss 0.45691463351249695, batch loss prom: 0.0012184107908979058, batch loss ss: 0.4556170701980591, batch loss polya: 7.915183232398704e-05\n",
      "batch loss 0.0008189660729840398, batch loss prom: 0.00037281715776771307, batch loss ss: 0.0001820160250645131, batch loss polya: 0.0002641328901518136\n",
      "batch loss 0.014623936265707016, batch loss prom: 0.004521622322499752, batch loss ss: 0.010068697854876518, batch loss polya: 3.361645576660521e-05\n",
      "batch loss 0.009194818325340748, batch loss prom: 0.002481716452166438, batch loss ss: 0.006396889686584473, batch loss polya: 0.000316212244797498\n",
      "batch loss 0.0008977411780506372, batch loss prom: 0.0003854485403280705, batch loss ss: 0.00019905969384126365, batch loss polya: 0.00031323294388130307\n",
      "batch loss 0.0018247459083795547, batch loss prom: 0.0007049936102703214, batch loss ss: 0.0010725465836003423, batch loss polya: 4.7205765440594405e-05\n",
      "batch loss 0.020011965185403824, batch loss prom: 0.0030255992896854877, batch loss ss: 0.016978975385427475, batch loss polya: 7.390948667307384e-06\n",
      "batch loss 0.2950199246406555, batch loss prom: 0.29019734263420105, batch loss ss: 0.004786106292158365, batch loss polya: 3.6477376852417365e-05\n",
      "batch loss 0.002047824440523982, batch loss prom: 0.0006098079611547291, batch loss ss: 0.0012867513578385115, batch loss polya: 0.0001512651506345719\n",
      "batch loss 0.00917274784296751, batch loss prom: 0.000835903687402606, batch loss ss: 0.008267228491604328, batch loss polya: 6.961580220377073e-05\n",
      "batch loss 0.0009309861343353987, batch loss prom: 0.00040236959466710687, batch loss ss: 0.0001820160250645131, batch loss polya: 0.0003466005437076092\n",
      "batch loss 0.004374471493065357, batch loss prom: 0.003863966092467308, batch loss ss: 0.00030882356804795563, batch loss polya: 0.00020168177434243262\n",
      "batch loss 0.0018950788071379066, batch loss prom: 0.0012662734370678663, batch loss ss: 0.0005240259342826903, batch loss polya: 0.00010477947944309562\n",
      "batch loss 0.0038327646907418966, batch loss prom: 0.00035398892941884696, batch loss ss: 0.0033764992840588093, batch loss polya: 0.00010227633902104571\n",
      "batch loss 0.0013225000584498048, batch loss prom: 0.0007049936102703214, batch loss ss: 0.00016199229867197573, batch loss polya: 0.0004555141495075077\n",
      "batch loss 0.00444698566570878, batch loss prom: 0.0018067717319354415, batch loss ss: 0.0018822111887857318, batch loss polya: 0.0007580029196105897\n",
      "batch loss 0.010766622610390186, batch loss prom: 0.007380008231848478, batch loss ss: 0.003071355167776346, batch loss polya: 0.0003152588615193963\n",
      "batch loss 0.0015336117940023541, batch loss prom: 0.0005322470096871257, batch loss ss: 0.0009688212885521352, batch loss polya: 3.2543604902457446e-05\n",
      "batch loss 0.0031690222676843405, batch loss prom: 0.0012647256953641772, batch loss ss: 0.0018648391123861074, batch loss polya: 3.9457496313843876e-05\n",
      "batch loss 0.24104982614517212, batch loss prom: 0.2397996038198471, batch loss ss: 0.0012274596374481916, batch loss polya: 2.276871418871451e-05\n",
      "batch loss 0.005590336862951517, batch loss prom: 0.0022730010095983744, batch loss ss: 0.00316547485999763, batch loss polya: 0.00015186110977083445\n",
      "batch loss 0.03481951355934143, batch loss prom: 0.009173743426799774, batch loss ss: 0.025633608922362328, batch loss polya: 1.2159273865108844e-05\n",
      "batch loss 0.010329226963222027, batch loss prom: 0.006861458066850901, batch loss ss: 0.003459066851064563, batch loss polya: 8.702239938429557e-06\n",
      "batch loss 0.0008807015838101506, batch loss prom: 0.0003685271949507296, batch loss ss: 0.0002076410164590925, batch loss polya: 0.0003045333724003285\n",
      "batch loss 0.008858033455908298, batch loss prom: 0.003426872193813324, batch loss ss: 0.005134135484695435, batch loss polya: 0.00029702542815357447\n",
      "batch loss 0.0020871893502771854, batch loss prom: 0.0009679876384325325, batch loss ss: 0.0008735416340641677, batch loss polya: 0.0002456601650919765\n",
      "batch loss 0.0017666235798969865, batch loss prom: 0.0009539344464428723, batch loss ss: 0.0007974305190145969, batch loss polya: 1.5258672647178173e-05\n",
      "batch loss 0.0008355282479897141, batch loss prom: 0.0004027270770166069, batch loss ss: 0.00018630675913300365, batch loss polya: 0.0002464944263920188\n",
      "batch loss 0.008266055025160313, batch loss prom: 0.0013598490040749311, batch loss ss: 0.006712151691317558, batch loss polya: 0.00019405389321036637\n",
      "batch loss 0.0021303982939571142, batch loss prom: 0.0011126763420179486, batch loss ss: 0.0009396428358741105, batch loss polya: 7.807903602952138e-05\n",
      "batch loss 0.06837642192840576, batch loss prom: 0.06268277764320374, batch loss ss: 0.00526636466383934, batch loss polya: 0.000427274004323408\n",
      "batch loss 0.008186385966837406, batch loss prom: 0.004290067590773106, batch loss ss: 0.003545785555616021, batch loss polya: 0.0003505330823827535\n",
      "batch loss 0.017649909481406212, batch loss prom: 0.008272903971374035, batch loss ss: 0.009326343424618244, batch loss polya: 5.066266385256313e-05\n",
      "batch loss 0.012748247012495995, batch loss prom: 0.0009927588980644941, batch loss ss: 0.011724375188350677, batch loss polya: 3.111314072157256e-05\n",
      "batch loss 0.21724802255630493, batch loss prom: 0.2127310037612915, batch loss ss: 0.004512959159910679, batch loss polya: 4.0531076592742465e-06\n",
      "batch loss 0.1242525577545166, batch loss prom: 0.12041974812746048, batch loss ss: 0.003782500745728612, batch loss polya: 5.030505417380482e-05\n",
      "batch loss 0.0008305336814373732, batch loss prom: 0.0003184764937032014, batch loss ss: 0.0002374367177253589, batch loss polya: 0.0002746204845607281\n",
      "batch loss 0.013941037468612194, batch loss prom: 0.013230509124696255, batch loss ss: 0.0006225554971024394, batch loss polya: 8.797258487902582e-05\n",
      "batch loss 0.004626539535820484, batch loss prom: 0.001925639808177948, batch loss ss: 0.002682660473510623, batch loss polya: 1.823885577323381e-05\n",
      "batch loss 0.011052793823182583, batch loss prom: 0.0012055517872795463, batch loss ss: 0.009691686369478703, batch loss polya: 0.00015555603022221476\n",
      "batch loss 0.010540725663304329, batch loss prom: 0.008659313432872295, batch loss ss: 0.0018631733255460858, batch loss polya: 1.823885577323381e-05\n",
      "batch loss 0.3698204755783081, batch loss prom: 0.3686632513999939, batch loss ss: 0.0011375630274415016, batch loss polya: 1.966933996300213e-05\n",
      "batch loss 0.03374135121703148, batch loss prom: 0.012943773530423641, batch loss ss: 0.020794358104467392, batch loss polya: 3.2186455882765586e-06\n",
      "batch loss 0.0009094172855839133, batch loss prom: 0.0004001055203843862, batch loss ss: 0.00018630675913300365, batch loss polya: 0.00032300499151460826\n",
      "batch loss 0.01042114943265915, batch loss prom: 0.009660282172262669, batch loss ss: 0.000753357307985425, batch loss polya: 7.510157047363464e-06\n",
      "batch loss 0.09152895212173462, batch loss prom: 0.08677228540182114, batch loss ss: 0.004603739827871323, batch loss polya: 0.00015293381875380874\n",
      "batch loss 0.002766228513792157, batch loss prom: 0.001887565478682518, batch loss ss: 0.0007114263135008514, batch loss polya: 0.00016723664884921163\n",
      "batch loss 0.004685687832534313, batch loss prom: 0.002923145890235901, batch loss ss: 0.0017414417816326022, batch loss polya: 2.109982233378105e-05\n",
      "batch loss 0.0017885497072711587, batch loss prom: 0.0009401192655786872, batch loss ss: 0.0008237544680014253, batch loss polya: 2.4676019165781327e-05\n",
      "batch loss 0.005294308997690678, batch loss prom: 0.0010122895473614335, batch loss ss: 0.004040650092065334, batch loss polya: 0.00024136967840604484\n",
      "batch loss 0.001146406983025372, batch loss prom: 0.000601349223870784, batch loss ss: 0.00016258825780823827, batch loss polya: 0.00038246947224251926\n",
      "batch loss 0.0016306211473420262, batch loss prom: 0.0007702721050009131, batch loss ss: 0.0006243425305001438, batch loss polya: 0.00023600654094479978\n",
      "batch loss 0.001101350993849337, batch loss prom: 0.0005540504935197532, batch loss ss: 0.0004570631426759064, batch loss polya: 9.023735765367746e-05\n",
      "batch loss 0.14806756377220154, batch loss prom: 0.14593899250030518, batch loss ss: 0.0020874394103884697, batch loss polya: 4.1126360883936286e-05\n",
      "batch loss 0.01737736538052559, batch loss prom: 0.005954977124929428, batch loss ss: 0.011293650604784489, batch loss polya: 0.0001287377526750788\n",
      "batch loss 0.010016222484409809, batch loss prom: 0.0031499075703322887, batch loss ss: 0.006831030361354351, batch loss polya: 3.528532761265524e-05\n",
      "batch loss 0.4457254707813263, batch loss prom: 0.42983368039131165, batch loss ss: 0.0158846452832222, batch loss polya: 7.152531907195225e-06\n",
      "batch loss 0.008498791605234146, batch loss prom: 0.007712941151112318, batch loss ss: 0.0006411403883248568, batch loss polya: 0.000144709600135684\n",
      "batch loss 0.0007888171239756048, batch loss prom: 0.00035386974923312664, batch loss ss: 0.00021681819634977728, batch loss polya: 0.0002181292074965313\n",
      "batch loss 0.004961226601153612, batch loss prom: 0.004278672393411398, batch loss ss: 0.0005445189890451729, batch loss polya: 0.0001380348257953301\n",
      "batch loss 0.008346091024577618, batch loss prom: 0.00248659192584455, batch loss ss: 0.005749237257987261, batch loss polya: 0.0001102625101339072\n",
      "batch loss 0.010635719634592533, batch loss prom: 0.0027484046295285225, batch loss ss: 0.007823420688509941, batch loss polya: 6.389413465512916e-05\n",
      "batch loss 0.0081139225512743, batch loss prom: 0.005409247241914272, batch loss ss: 0.0026972838677465916, batch loss polya: 7.390948667307384e-06\n",
      "batch loss 0.0023335926234722137, batch loss prom: 0.0015673269517719746, batch loss ss: 0.0007046362152323127, batch loss polya: 6.16293036728166e-05\n",
      "batch loss 0.002352275187149644, batch loss prom: 0.0006970121758058667, batch loss ss: 0.001591488253325224, batch loss polya: 6.3774932641536e-05\n",
      "batch loss 0.087743379175663, batch loss prom: 0.07636850327253342, batch loss ss: 0.011321350000798702, batch loss polya: 5.352353764465079e-05\n",
      "batch loss 0.06741681694984436, batch loss prom: 0.06473815441131592, batch loss ss: 0.0025692330673336983, batch loss polya: 0.00010942813969450071\n",
      "batch loss 0.0023989954497665167, batch loss prom: 0.0012722263345494866, batch loss ss: 0.0010883843060582876, batch loss polya: 3.838465272565372e-05\n",
      "batch loss 0.0019202670082449913, batch loss prom: 0.0009252319578081369, batch loss ss: 0.0009813260985538363, batch loss polya: 1.3708974620385561e-05\n",
      "batch loss 0.003487692214548588, batch loss prom: 0.0029356263112276793, batch loss ss: 0.0004637358069885522, batch loss polya: 8.83301836438477e-05\n",
      "batch loss 0.009728294797241688, batch loss prom: 0.0026177444960922003, batch loss ss: 0.007090761326253414, batch loss polya: 1.9788545614574105e-05\n",
      "batch loss 0.08564779162406921, batch loss prom: 0.08396729081869125, batch loss ss: 0.0015310243470594287, batch loss polya: 0.0001494772732257843\n",
      "batch loss 0.0008193315006792545, batch loss prom: 0.00030870441696606576, batch loss ss: 0.0002379134384682402, batch loss polya: 0.0002727136597968638\n",
      "batch loss 0.008913871832191944, batch loss prom: 0.002531302161514759, batch loss ss: 0.006247395649552345, batch loss polya: 0.00013517419574782252\n",
      "batch loss 0.00610819086432457, batch loss prom: 0.0024398579262197018, batch loss ss: 0.0032795476727187634, batch loss polya: 0.0003887851198669523\n",
      "batch loss 0.005358707159757614, batch loss prom: 0.001527334563434124, batch loss ss: 0.003718368476256728, batch loss polya: 0.00011300401820335537\n",
      "batch loss 0.0072674863040447235, batch loss prom: 0.001016457681544125, batch loss ss: 0.006199889350682497, batch loss polya: 5.113947918289341e-05\n",
      "batch loss 0.014529617503285408, batch loss prom: 0.013273682445287704, batch loss ss: 0.0012404375011101365, batch loss polya: 1.549708758830093e-05\n",
      "batch loss 2.3547821044921875, batch loss prom: 2.35245418548584, batch loss ss: 0.002267529722303152, batch loss polya: 6.031808152329177e-05\n",
      "batch loss 0.0023362035863101482, batch loss prom: 0.0018703126115724444, batch loss ss: 0.00044264530879445374, batch loss polya: 2.3245540432981215e-05\n",
      "batch loss 0.017476234585046768, batch loss prom: 0.002881781430914998, batch loss ss: 0.014571087434887886, batch loss polya: 2.3364747903542593e-05\n",
      "batch loss 0.001393867307342589, batch loss prom: 0.0005553610390052199, batch loss ss: 0.0001463782973587513, batch loss polya: 0.0006921279709786177\n",
      "batch loss 0.0008314852020703256, batch loss prom: 0.00031835734262131155, batch loss ss: 0.00020895205670967698, batch loss polya: 0.00030417583184316754\n",
      "batch loss 0.0008525820448994637, batch loss prom: 0.0003163314249832183, batch loss ss: 0.00027295202016830444, batch loss polya: 0.0002632986579556018\n",
      "batch loss 0.11142050474882126, batch loss prom: 0.10944601148366928, batch loss ss: 0.0018725732807070017, batch loss polya: 0.00010191874753218144\n",
      "batch loss 0.013688451610505581, batch loss prom: 0.0008772339206188917, batch loss ss: 0.012759004719555378, batch loss polya: 5.221230458118953e-05\n",
      "batch loss 0.001307572820223868, batch loss prom: 0.0006332775810733438, batch loss ss: 0.0006151691195555031, batch loss polya: 5.9126061387360096e-05\n",
      "batch loss 0.006441151257604361, batch loss prom: 0.0018352109473198652, batch loss ss: 0.004512484651058912, batch loss polya: 9.345571743324399e-05\n",
      "batch loss 0.003705702256411314, batch loss prom: 0.002428084844723344, batch loss ss: 0.0011442311806604266, batch loss polya: 0.0001333863037871197\n",
      "batch loss 0.0008103940635919571, batch loss prom: 0.000291662581730634, batch loss ss: 0.0002525725867599249, batch loss polya: 0.0002661589242052287\n",
      "batch loss 0.22058308124542236, batch loss prom: 0.2184380292892456, batch loss ss: 0.0021265766117721796, batch loss polya: 1.847726889536716e-05\n",
      "batch loss 0.0009207360562868416, batch loss prom: 0.00044264530879445374, batch loss ss: 0.0002153879904653877, batch loss polya: 0.0002627027570270002\n",
      "batch loss 0.0017519663088023663, batch loss prom: 0.0007757514831610024, batch loss ss: 0.0009660820942372084, batch loss polya: 1.0132738680113107e-05\n",
      "batch loss 0.0008524570148438215, batch loss prom: 0.0003492222458589822, batch loss ss: 0.00019202772818971425, batch loss polya: 0.00031120702624320984\n",
      "batch loss 0.0008654419798403978, batch loss prom: 0.00038747431244701147, batch loss ss: 0.00017236177518498152, batch loss polya: 0.00030560590676032007\n",
      "batch loss 0.000806340598501265, batch loss prom: 0.0003093002596870065, batch loss ss: 0.0002747396647464484, batch loss polya: 0.00022230061586014926\n",
      "batch loss 0.0007595047354698181, batch loss prom: 0.0002687808300834149, batch loss ss: 0.0002686616498976946, batch loss polya: 0.00022206225548870862\n",
      "batch loss 0.006842858623713255, batch loss prom: 0.005954147316515446, batch loss ss: 0.0008368566050194204, batch loss polya: 5.185469490243122e-05\n",
      "batch loss 0.0028991717845201492, batch loss prom: 0.0017147850012406707, batch loss ss: 0.0011595914838835597, batch loss polya: 2.47952248173533e-05\n",
      "batch loss 0.0008114607771858573, batch loss prom: 0.00034731553751043975, batch loss ss: 0.00018904806347563863, batch loss polya: 0.00027509720530360937\n",
      "batch loss 0.3600141406059265, batch loss prom: 0.353482723236084, batch loss ss: 0.006478616502135992, batch loss polya: 5.280832192511298e-05\n",
      "batch loss 0.004953659139573574, batch loss prom: 0.0014063954586163163, batch loss ss: 0.0035323624033480883, batch loss polya: 1.490105023549404e-05\n",
      "batch loss 0.08683119714260101, batch loss prom: 0.06681596487760544, batch loss ss: 0.019303208217024803, batch loss polya: 0.0007120219524949789\n",
      "batch loss 0.002422915305942297, batch loss prom: 0.001479246304370463, batch loss ss: 0.0005589353386312723, batch loss polya: 0.0003847335756290704\n",
      "batch loss 0.001058107358403504, batch loss prom: 0.0005743046058341861, batch loss ss: 0.0001461399078834802, batch loss polya: 0.00033766290289349854\n",
      "batch loss 0.19993844628334045, batch loss prom: 0.1874314397573471, batch loss ss: 0.012466481886804104, batch loss polya: 4.053033626405522e-05\n",
      "batch loss 0.002837145235389471, batch loss prom: 0.0019248068565502763, batch loss ss: 0.00048387263086624444, batch loss polya: 0.00042846560245379806\n",
      "batch loss 0.06941433995962143, batch loss prom: 0.058946091681718826, batch loss ss: 0.010197797790169716, batch loss polya: 0.00027044929447583854\n",
      "batch loss 0.004798386245965958, batch loss prom: 0.004040412604808807, batch loss ss: 0.0006108802044764161, batch loss polya: 0.00014709345123264939\n",
      "batch loss 0.002988356864079833, batch loss prom: 0.002541052643209696, batch loss ss: 0.0004191712068859488, batch loss polya: 2.8132995794294402e-05\n",
      "batch loss 0.0007708255434408784, batch loss prom: 0.0002967870968859643, batch loss ss: 0.00021062063751742244, batch loss polya: 0.00026341783814132214\n",
      "batch loss 0.0036079043056815863, batch loss prom: 0.000608854868914932, batch loss ss: 0.00270845927298069, batch loss polya: 0.00029059001826681197\n",
      "batch loss 0.0025342863518744707, batch loss prom: 0.0009510761592537165, batch loss ss: 0.00011777184408856556, batch loss polya: 0.001465438399463892\n",
      "batch loss 0.0069095971994102, batch loss prom: 0.0018889933126047254, batch loss ss: 0.004978047218173742, batch loss polya: 4.255681051290594e-05\n",
      "batch loss 0.6576880216598511, batch loss prom: 0.0004717191040981561, batch loss ss: 0.6571954488754272, batch loss polya: 2.0861407392658293e-05\n",
      "batch loss 0.019739048555493355, batch loss prom: 0.016944166272878647, batch loss ss: 0.0022021110635250807, batch loss polya: 0.0005927712772972882\n",
      "batch loss 0.0008572190999984741, batch loss prom: 0.00037722624256275594, batch loss ss: 0.0001668790791882202, batch loss polya: 0.0003131137927994132\n",
      "batch loss 0.0008026444120332599, batch loss prom: 0.00031716562807559967, batch loss ss: 0.00020096666412428021, batch loss polya: 0.00028451209072954953\n",
      "batch loss 0.00561275240033865, batch loss prom: 0.003882728284224868, batch loss ss: 0.0016540905926376581, batch loss polya: 7.593343616463244e-05\n",
      "batch loss 0.0157349593937397, batch loss prom: 0.001029557315632701, batch loss ss: 0.01469467394053936, batch loss polya: 1.07287787614041e-05\n",
      "batch loss 0.004699145909398794, batch loss prom: 0.0012537722941488028, batch loss ss: 0.0033111530356109142, batch loss polya: 0.00013422065239865333\n",
      "batch loss 0.08157243579626083, batch loss prom: 0.07365119457244873, batch loss ss: 0.0071576363407075405, batch loss polya: 0.0007636015070602298\n",
      "batch loss 0.007922838442027569, batch loss prom: 0.0029286136850714684, batch loss ss: 0.00498504564166069, batch loss polya: 9.179073458653875e-06\n",
      "batch loss 0.0022779020946472883, batch loss prom: 0.0018974411068484187, batch loss ss: 0.0003277718205936253, batch loss polya: 5.2689116273541003e-05\n",
      "batch loss 0.008055925369262695, batch loss prom: 0.0014996008248999715, batch loss ss: 0.006499224808067083, batch loss polya: 5.709961988031864e-05\n",
      "batch loss 0.0007860767072997987, batch loss prom: 0.00033861625706776977, batch loss ss: 0.0001896439935080707, batch loss polya: 0.00025781645672395825\n",
      "batch loss 0.046323470771312714, batch loss prom: 0.0006814065272919834, batch loss ss: 0.04560272395610809, batch loss polya: 3.93382906622719e-05\n",
      "batch loss 0.02139405906200409, batch loss prom: 0.003082882845774293, batch loss ss: 0.01830950751900673, batch loss polya: 1.6689286894688848e-06\n",
      "batch loss 0.0016265561571344733, batch loss prom: 0.0006677066558040679, batch loss ss: 0.0007595514762215316, batch loss polya: 0.00019929806876461953\n",
      "batch loss 0.006475996226072311, batch loss prom: 0.004457537550479174, batch loss ss: 0.002009160118177533, batch loss polya: 9.298280929215252e-06\n",
      "batch loss 0.0045579783618450165, batch loss prom: 0.002408819505944848, batch loss ss: 0.0019095772877335548, batch loss polya: 0.00023958197562023997\n",
      "batch loss 0.016693148761987686, batch loss prom: 0.0013404440833255649, batch loss ss: 0.015325525775551796, batch loss polya: 2.7179348762729205e-05\n",
      "batch loss 0.0009369310573674738, batch loss prom: 0.000481132126878947, batch loss ss: 0.0001541257370263338, batch loss polya: 0.000301673193462193\n",
      "batch loss 0.0036457173991948366, batch loss prom: 0.0021802245173603296, batch loss ss: 0.0008095800876617432, batch loss polya: 0.0006559127941727638\n",
      "batch loss 0.1319904327392578, batch loss prom: 0.1304389387369156, batch loss ss: 0.0014698426239192486, batch loss polya: 8.165503095369786e-05\n",
      "batch loss 0.08631668239831924, batch loss prom: 0.0836930125951767, batch loss ss: 0.002488137688487768, batch loss polya: 0.00013553177996072918\n",
      "batch loss 0.07488790899515152, batch loss prom: 0.00042274597217328846, batch loss ss: 0.07442057877779007, batch loss polya: 4.458328112377785e-05\n",
      "batch loss 0.0009112093830481172, batch loss prom: 0.00035279724397696555, batch loss ss: 0.00020549570035655051, batch loss polya: 0.00035291642416268587\n",
      "batch loss 0.007759526837617159, batch loss prom: 0.0015367376618087292, batch loss ss: 0.006217186339199543, batch loss polya: 5.602820692729438e-06\n",
      "batch loss 0.001685709459707141, batch loss prom: 0.0008660380262881517, batch loss ss: 0.00012337400403339416, batch loss polya: 0.0006962973857298493\n",
      "batch loss 0.0007353093824349344, batch loss prom: 0.000302030734019354, batch loss ss: 0.0002026352594839409, batch loss polya: 0.00023064337437972426\n",
      "batch loss 0.1631269007921219, batch loss prom: 0.16232916712760925, batch loss ss: 0.0007164295529946685, batch loss polya: 8.129743218887597e-05\n",
      "batch loss 0.003844322869554162, batch loss prom: 0.0028049908578395844, batch loss ss: 0.0008952185744419694, batch loss polya: 0.00014411364099942148\n",
      "batch loss 0.012056263163685799, batch loss prom: 0.001077428925782442, batch loss ss: 0.010951178148388863, batch loss polya: 2.7656173188006505e-05\n",
      "batch loss 0.007752611301839352, batch loss prom: 0.00541149964556098, batch loss ss: 0.002004044596105814, batch loss polya: 0.00033706706017255783\n",
      "batch loss 0.000790960097219795, batch loss prom: 0.0003669780562631786, batch loss ss: 0.0001902399235405028, batch loss polya: 0.0002337421028641984\n",
      "batch loss 0.005691115278750658, batch loss prom: 0.0011235122801735997, batch loss ss: 0.004215759225189686, batch loss polya: 0.0003518439189065248\n",
      "batch loss 0.003819817677140236, batch loss prom: 0.003037246409803629, batch loss ss: 0.0007419217727147043, batch loss polya: 4.0649541915627196e-05\n",
      "batch loss 0.07841535657644272, batch loss prom: 0.07619376480579376, batch loss ss: 0.002121818484738469, batch loss polya: 9.97731985989958e-05\n",
      "batch loss 0.003983119502663612, batch loss prom: 0.0019462230848148465, batch loss ss: 0.0003665013937279582, batch loss polya: 0.0016703951405361295\n",
      "batch loss 0.0007665343582630157, batch loss prom: 0.0003143055073451251, batch loss ss: 0.00021741411183029413, batch loss polya: 0.0002348147245356813\n",
      "batch loss 0.009996513836085796, batch loss prom: 0.009086566045880318, batch loss ss: 0.0003682888636831194, batch loss polya: 0.0005416594794951379\n",
      "batch loss 0.010495449416339397, batch loss prom: 0.0019883401691913605, batch loss ss: 0.008462049067020416, batch loss polya: 4.5060096454108134e-05\n",
      "batch loss 0.09124824404716492, batch loss prom: 0.08180918544530869, batch loss ss: 0.009344294667243958, batch loss polya: 9.476689592702314e-05\n",
      "batch loss 0.00808987021446228, batch loss prom: 0.0031600084621459246, batch loss ss: 0.0048117320984601974, batch loss polya: 0.00011812942830147222\n",
      "batch loss 0.0020254268310964108, batch loss prom: 0.0010084786918014288, batch loss ss: 0.0010028815595433116, batch loss polya: 1.4066597032069694e-05\n",
      "batch loss 0.0008097983663901687, batch loss prom: 0.00028606137493625283, batch loss ss: 0.0002554328821133822, batch loss polya: 0.0002683041093405336\n",
      "batch loss 0.006946903187781572, batch loss prom: 0.004363895393908024, batch loss ss: 0.0024949158541858196, batch loss polya: 8.809178689261898e-05\n",
      "batch loss 0.07583103328943253, batch loss prom: 0.06660252809524536, batch loss ss: 0.008191442117094994, batch loss polya: 0.0010370597010478377\n",
      "batch loss 0.0007971611339598894, batch loss prom: 0.0003367095487192273, batch loss ss: 0.00020013237372040749, batch loss polya: 0.0002603192115202546\n",
      "batch loss 0.014422662556171417, batch loss prom: 0.005502080079168081, batch loss ss: 0.008920224383473396, batch loss polya: 3.576278118089249e-07\n",
      "batch loss 0.0032663517631590366, batch loss prom: 0.0011593532981351018, batch loss ss: 0.0019602624233812094, batch loss polya: 0.00014673586701974273\n",
      "batch loss 0.0007825057837180793, batch loss prom: 0.00029976642690598965, batch loss ss: 0.00024029705673456192, batch loss polya: 0.00024244230007752776\n",
      "batch loss 0.000982815632596612, batch loss prom: 0.0004076126788277179, batch loss ss: 0.00015233787416946143, batch loss polya: 0.0004228651523590088\n",
      "batch loss 0.0018091012025251985, batch loss prom: 0.0006165986997075379, batch loss ss: 0.0011508992174640298, batch loss polya: 4.160317621426657e-05\n",
      "batch loss 0.007187971379607916, batch loss prom: 0.006450782995671034, batch loss ss: 0.000691770575940609, batch loss polya: 4.541770613286644e-05\n",
      "batch loss 0.0087636923417449, batch loss prom: 0.0012022180017083883, batch loss ss: 0.006895673461258411, batch loss polya: 0.0006658005877397954\n",
      "batch loss 0.0064577339217066765, batch loss prom: 0.004467150662094355, batch loss ss: 0.0012306743301451206, batch loss polya: 0.0007599088130518794\n",
      "batch loss 0.02838740311563015, batch loss prom: 0.0020895807538181543, batch loss ss: 0.026296034455299377, batch loss polya: 1.7881377516459906e-06\n",
      "batch loss 0.009659112431108952, batch loss prom: 0.0018055817345157266, batch loss ss: 0.007658761460334063, batch loss polya: 0.00019476900342851877\n",
      "batch loss 0.005584044847637415, batch loss prom: 0.0014992436626926064, batch loss ss: 0.004029370378702879, batch loss polya: 5.543078441405669e-05\n",
      "batch loss 0.001605600817129016, batch loss prom: 0.0009627474937587976, batch loss ss: 0.0005625095800496638, batch loss polya: 8.034383063204587e-05\n",
      "batch loss 0.0008057464146986604, batch loss prom: 0.0002834395272657275, batch loss ss: 0.0002544794406276196, batch loss polya: 0.00026782741770148277\n",
      "batch loss 0.005613420624285936, batch loss prom: 0.001468295231461525, batch loss ss: 0.0039651356637477875, batch loss polya: 0.00017998983094003052\n",
      "batch loss 0.0007964461110532284, batch loss prom: 0.0003082277253270149, batch loss ss: 0.00018702188390307128, batch loss polya: 0.00030119650182314217\n",
      "batch loss 0.000777255860157311, batch loss prom: 0.00034731553751043975, batch loss ss: 0.00017772526189219207, batch loss polya: 0.0002522150462027639\n",
      "batch loss 0.000742337666451931, batch loss prom: 0.0003358753747306764, batch loss ss: 0.0001941730733960867, batch loss polya: 0.00021228920377325267\n",
      "batch loss 0.08843406289815903, batch loss prom: 0.08499280363321304, batch loss ss: 0.0033308761194348335, batch loss polya: 0.00011038171214750037\n",
      "batch loss 0.006177895702421665, batch loss prom: 0.0056321267038583755, batch loss ss: 0.0003978414461016655, batch loss polya: 0.0001479277852922678\n",
      "batch loss 0.0008572193328291178, batch loss prom: 0.0003457663697190583, batch loss ss: 0.00016223068814724684, batch loss polya: 0.0003492222458589822\n",
      "batch loss 0.00836939737200737, batch loss prom: 0.001488054753281176, batch loss ss: 0.00679480005055666, batch loss polya: 8.654219709569588e-05\n",
      "batch loss 0.0013792035169899464, batch loss prom: 0.0005272428970783949, batch loss ss: 0.00013422065239865333, batch loss polya: 0.0007177399238571525\n",
      "batch loss 0.012349747121334076, batch loss prom: 0.0004338276921771467, batch loss ss: 0.0005955114611424506, batch loss polya: 0.011320407502353191\n",
      "batch loss 0.19845892488956451, batch loss prom: 0.192471444606781, batch loss ss: 0.005669228732585907, batch loss polya: 0.0003182381624355912\n",
      "batch loss 0.15983770787715912, batch loss prom: 0.15812955796718597, batch loss ss: 0.0016872945707291365, batch loss polya: 2.0861407392658293e-05\n",
      "batch loss 0.0007193414494395256, batch loss prom: 0.00025996167096309364, batch loss ss: 0.0002383901592111215, batch loss polya: 0.00022098960471339524\n",
      "batch loss 0.011047140695154667, batch loss prom: 0.0009924016194418073, batch loss ss: 0.009754019789397717, batch loss polya: 0.00030071981018409133\n",
      "batch loss 0.034264206886291504, batch loss prom: 0.0007768235518597066, batch loss ss: 0.033240530639886856, batch loss polya: 0.00024685196694917977\n",
      "batch loss 0.010257354937493801, batch loss prom: 0.0017669078661128879, batch loss ss: 0.008458857424557209, batch loss polya: 3.158996332786046e-05\n",
      "batch loss 0.0013200188986957073, batch loss prom: 0.00047708096099086106, batch loss ss: 0.0001941730733960867, batch loss polya: 0.00064876489341259\n",
      "batch loss 0.010843497700989246, batch loss prom: 0.0029221950098872185, batch loss ss: 0.007867183536291122, batch loss polya: 5.411955135059543e-05\n",
      "batch loss 0.0007728494238108397, batch loss prom: 0.00029404606902971864, batch loss ss: 0.0001842805795604363, batch loss polya: 0.00029452278977259994\n",
      "batch loss 0.05636834725737572, batch loss prom: 0.04816685616970062, batch loss ss: 0.006576442625373602, batch loss polya: 0.0016250512562692165\n",
      "batch loss 0.06808825582265854, batch loss prom: 0.0638963133096695, batch loss ss: 0.00394043792039156, batch loss polya: 0.00025149996508844197\n",
      "batch loss 0.0028361366130411625, batch loss prom: 0.0013469918631017208, batch loss ss: 0.0014765085652470589, batch loss polya: 1.2636104656849056e-05\n",
      "batch loss 0.009849725291132927, batch loss prom: 0.0011332763824611902, batch loss ss: 0.008585565723478794, batch loss polya: 0.0001308832288486883\n",
      "batch loss 0.0009229928255081177, batch loss prom: 0.0004368066438473761, batch loss ss: 0.0001461399078834802, batch loss polya: 0.0003400462737772614\n",
      "batch loss 0.0031942883506417274, batch loss prom: 0.0026496085338294506, batch loss ss: 0.0004528927383944392, batch loss polya: 9.178694017464295e-05\n",
      "batch loss 0.0015449665952473879, batch loss prom: 0.0006504327175207436, batch loss ss: 0.0006729483720846474, batch loss polya: 0.0002215855201939121\n",
      "batch loss 0.0015330702299252152, batch loss prom: 0.00108624086715281, batch loss ss: 0.0004140473320148885, batch loss polya: 3.2782016205601394e-05\n",
      "batch loss 0.058141469955444336, batch loss prom: 0.05282531678676605, batch loss ss: 0.005228417459875345, batch loss polya: 8.77341881277971e-05\n",
      "batch loss 0.060871485620737076, batch loss prom: 0.05729525163769722, batch loss ss: 0.0034255655482411385, batch loss polya: 0.00015066919149830937\n",
      "batch loss 0.007213295437395573, batch loss prom: 0.004635422024875879, batch loss ss: 0.002395619172602892, batch loss polya: 0.00018225439998786896\n",
      "batch loss 0.0008180146105587482, batch loss prom: 0.00031931069679558277, batch loss ss: 0.00017474555352237076, batch loss polya: 0.00032395837479270995\n",
      "batch loss 0.0065025389194488525, batch loss prom: 0.001622075797058642, batch loss ss: 0.004847085103392601, batch loss polya: 3.3378044463461265e-05\n",
      "batch loss 0.09880011528730392, batch loss prom: 0.09314073622226715, batch loss ss: 0.005618850234895945, batch loss polya: 4.053033626405522e-05\n",
      "batch loss 0.0018685836112126708, batch loss prom: 0.0010963627137243748, batch loss ss: 0.00071190285962075, batch loss polya: 6.031808152329177e-05\n",
      "batch loss 0.0008750910055823624, batch loss prom: 0.00037651124875992537, batch loss ss: 0.00014649749209638685, batch loss polya: 0.00035208225017413497\n",
      "batch loss 0.00595262972638011, batch loss prom: 0.002284181071445346, batch loss ss: 0.003578807692974806, batch loss polya: 8.964136941358447e-05\n",
      "batch loss 0.0008469690219499171, batch loss prom: 0.000364713923772797, batch loss ss: 0.0001541257370263338, batch loss polya: 0.0003281293320469558\n",
      "batch loss 0.011383886449038982, batch loss prom: 0.0026002663653343916, batch loss ss: 0.008703275583684444, batch loss polya: 8.034383063204587e-05\n",
      "batch loss 0.1406477987766266, batch loss prom: 0.10810787230730057, batch loss ss: 0.030846908688545227, batch loss polya: 0.0016930069541558623\n",
      "batch loss 0.04689979553222656, batch loss prom: 0.005171612370759249, batch loss ss: 0.04172448813915253, batch loss polya: 3.6954811548639555e-06\n",
      "batch loss 0.0008165844483301044, batch loss prom: 0.00031883400515653193, batch loss ss: 0.00017438798386137933, batch loss polya: 0.0003233625029679388\n",
      "batch loss 0.06391486525535583, batch loss prom: 0.05921589583158493, batch loss ss: 0.004444008227437735, batch loss polya: 0.0002549561613705009\n",
      "batch loss 0.0057450225576758385, batch loss prom: 0.002850875724107027, batch loss ss: 0.0027174947317689657, batch loss polya: 0.000176652567461133\n",
      "batch loss 0.003104990581050515, batch loss prom: 0.0019909576512873173, batch loss ss: 0.0010702840518206358, batch loss polya: 4.3748852476710454e-05\n",
      "batch loss 0.0013281159335747361, batch loss prom: 0.000659248442389071, batch loss ss: 0.0001820160250645131, batch loss polya: 0.00048685140791349113\n",
      "batch loss 0.0007807184010744095, batch loss prom: 0.0002795067266561091, batch loss ss: 0.00022706791060045362, batch loss polya: 0.00027414379292167723\n",
      "batch loss 0.003183018881827593, batch loss prom: 0.0003326578007545322, batch loss ss: 0.0028219898231327534, batch loss polya: 2.8371408916427754e-05\n",
      "batch loss 0.0023688513319939375, batch loss prom: 0.0008797351038083434, batch loss ss: 0.0011991222854703665, batch loss polya: 0.0002899941464420408\n",
      "batch loss 0.0020552482455968857, batch loss prom: 0.0005311747081577778, batch loss ss: 0.0005820487276650965, batch loss polya: 0.0009420248097740114\n",
      "batch loss 0.0050377924926579, batch loss prom: 0.003316143061965704, batch loss ss: 0.0014107999159023166, batch loss polya: 0.0003108495147898793\n",
      "batch loss 0.09767094999551773, batch loss prom: 0.09604751318693161, batch loss ss: 0.0015070997178554535, batch loss polya: 0.00011634149996098131\n",
      "batch loss 0.0038435058668255806, batch loss prom: 0.0011451836908236146, batch loss ss: 0.0026656591799110174, batch loss polya: 3.266281055402942e-05\n",
      "batch loss 0.06398846954107285, batch loss prom: 0.06091113016009331, batch loss ss: 0.002483856864273548, batch loss polya: 0.0005934861255809665\n",
      "batch loss 0.01786666549742222, batch loss prom: 0.001212695729918778, batch loss ss: 0.016629651188850403, batch loss polya: 2.4318398573086597e-05\n",
      "batch loss 0.004310084041208029, batch loss prom: 0.0037896260619163513, batch loss ss: 0.0005079409456811845, batch loss polya: 1.2516897186287679e-05\n",
      "batch loss 0.0009083313052542508, batch loss prom: 0.0004817279113922268, batch loss ss: 0.00017963226127903908, batch loss polya: 0.0002469711471349001\n",
      "batch loss 0.0019303937442600727, batch loss prom: 0.0005704921204596758, batch loss ss: 0.0001408954558428377, batch loss polya: 0.0012190061388537288\n",
      "batch loss 0.00809007603675127, batch loss prom: 0.0051674614660441875, batch loss ss: 0.002900918712839484, batch loss polya: 2.169585604860913e-05\n",
      "batch loss 0.0033580611925572157, batch loss prom: 0.002717970171943307, batch loss ss: 0.000602421467192471, batch loss polya: 3.766942609217949e-05\n",
      "batch loss 0.0007776134880259633, batch loss prom: 0.00035232058144174516, batch loss ss: 0.00018737945356406271, batch loss polya: 0.0002379134384682402\n",
      "batch loss 0.0077118463814258575, batch loss prom: 0.0010904086520895362, batch loss ss: 0.006586390547454357, batch loss polya: 3.504691630951129e-05\n",
      "batch loss 0.0008704490028321743, batch loss prom: 0.0003203832311555743, batch loss ss: 0.00017796363681554794, batch loss polya: 0.0003721021639648825\n",
      "batch loss 0.0007715399260632694, batch loss prom: 0.0003002431185450405, batch loss ss: 0.0002015625941567123, batch loss polya: 0.00026973424246534705\n",
      "batch loss 0.008686498738825321, batch loss prom: 0.001465676468797028, batch loss ss: 0.007206517271697521, batch loss polya: 1.4305012882687151e-05\n",
      "batch loss 0.00201520137488842, batch loss prom: 0.000393432448618114, batch loss ss: 0.0015095992712303996, batch loss polya: 0.00011216964776394889\n",
      "batch loss 0.03783542662858963, batch loss prom: 0.010669803246855736, batch loss ss: 0.02716025710105896, batch loss polya: 5.364403477869928e-06\n",
      "batch loss 0.05036061257123947, batch loss prom: 0.049123167991638184, batch loss ss: 0.0011476842919364572, batch loss polya: 8.976056415122002e-05\n",
      "batch loss 0.009241432882845402, batch loss prom: 0.0017232344252988696, batch loss ss: 0.007472303695976734, batch loss polya: 4.589452510117553e-05\n",
      "batch loss 0.0021575915161520243, batch loss prom: 0.0005204515182413161, batch loss ss: 0.0015943447360768914, batch loss polya: 4.279521817807108e-05\n",
      "batch loss 0.005443115718662739, batch loss prom: 0.0007967158453539014, batch loss ss: 0.004269888624548912, batch loss polya: 0.00037651124875992537\n",
      "batch loss 0.0009373015491291881, batch loss prom: 0.00039867559098638594, batch loss ss: 0.0001784403866622597, batch loss polya: 0.0003601856005843729\n",
      "batch loss 0.003232695162296295, batch loss prom: 0.0015530440723523498, batch loss ss: 0.001542688929475844, batch loss polya: 0.00013696208770852536\n",
      "batch loss 0.0007797629805281758, batch loss prom: 0.00031835734262131155, batch loss ss: 0.00021431533969007432, batch loss polya: 0.0002470903273206204\n",
      "batch loss 0.007713236380368471, batch loss prom: 0.0015814905054867268, batch loss ss: 0.006115533411502838, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.002229968784376979, batch loss prom: 0.0016733704833313823, batch loss ss: 0.000456109904916957, batch loss polya: 0.00010048838157672435\n",
      "batch loss 0.00118930172175169, batch loss prom: 0.0005952732171863317, batch loss ss: 0.00014745102089364082, batch loss polya: 0.0004465774691198021\n",
      "batch loss 0.002902494976297021, batch loss prom: 0.0007678897818550467, batch loss ss: 0.000570253818295896, batch loss polya: 0.0015643513761460781\n",
      "batch loss 0.0071343244053423405, batch loss prom: 0.0025481870397925377, batch loss ss: 0.00448910566046834, batch loss polya: 9.703165414975956e-05\n",
      "batch loss 0.0013084685197100043, batch loss prom: 0.0008451942121610045, batch loss ss: 0.0004278697888366878, batch loss polya: 3.540453326422721e-05\n",
      "batch loss 0.0018827958265319467, batch loss prom: 0.0012124576605856419, batch loss ss: 0.0006541258189827204, batch loss polya: 1.6212332411669195e-05\n",
      "batch loss 0.012772425077855587, batch loss prom: 0.0007963585085235536, batch loss ss: 0.011951152235269547, batch loss polya: 2.4914430468925275e-05\n",
      "batch loss 0.006217867136001587, batch loss prom: 0.001127441762946546, batch loss ss: 0.0050324914045631886, batch loss polya: 5.793403761344962e-05\n",
      "batch loss 0.0017163001466542482, batch loss prom: 0.0002786724944598973, batch loss ss: 0.0013136576162651181, batch loss polya: 0.00012396997772157192\n",
      "batch loss 0.0027753114700317383, batch loss prom: 0.0018820922123268247, batch loss ss: 0.0008636558777652681, batch loss polya: 2.95634672511369e-05\n",
      "batch loss 0.0007796463323757052, batch loss prom: 0.0002786724944598973, batch loss ss: 0.0002450642641633749, batch loss polya: 0.0002559096028562635\n",
      "batch loss 0.06740107387304306, batch loss prom: 0.06329213082790375, batch loss ss: 0.003920133225619793, batch loss polya: 0.00018880968855228275\n",
      "batch loss 0.022067179903388023, batch loss prom: 0.020603211596608162, batch loss ss: 0.001409014337696135, batch loss polya: 5.495397272170521e-05\n",
      "batch loss 0.007455642335116863, batch loss prom: 0.0013092526933178306, batch loss ss: 0.006099064368754625, batch loss polya: 4.732496745418757e-05\n",
      "batch loss 0.01057675015181303, batch loss prom: 0.0005694198189303279, batch loss ss: 0.009751658886671066, batch loss polya: 0.00025567124248482287\n",
      "batch loss 0.0023990620393306017, batch loss prom: 0.0014743659412488341, batch loss ss: 0.0002752163854893297, batch loss polya: 0.0006494796834886074\n",
      "batch loss 0.0015870470087975264, batch loss prom: 0.0010836211731657386, batch loss ss: 0.0004772001120727509, batch loss polya: 2.6225699912174605e-05\n",
      "batch loss 0.0042519946582615376, batch loss prom: 0.003028926905244589, batch loss ss: 0.0005560758872888982, batch loss polya: 0.0006669919239357114\n",
      "batch loss 0.18792463839054108, batch loss prom: 0.18402959406375885, batch loss ss: 0.0036423548590391874, batch loss polya: 0.0002526917669456452\n",
      "batch loss 0.018364399671554565, batch loss prom: 0.0021435872185975313, batch loss ss: 0.01619446650147438, batch loss polya: 2.634490556374658e-05\n",
      "batch loss 0.023110583424568176, batch loss prom: 0.00344279152341187, batch loss ss: 0.01957421563565731, batch loss polya: 9.357491217087954e-05\n",
      "batch loss 0.07446467876434326, batch loss prom: 0.0730317160487175, batch loss ss: 0.0013233008794486523, batch loss polya: 0.00010966652916977182\n",
      "batch loss 0.0009307475993409753, batch loss prom: 0.000392598332837224, batch loss ss: 0.00017832119192462415, batch loss polya: 0.00035982808913104236\n",
      "batch loss 0.049019526690244675, batch loss prom: 0.000920706195756793, batch loss ss: 0.048096079379320145, batch loss polya: 2.7418097943154862e-06\n",
      "batch loss 0.008775261230766773, batch loss prom: 0.0034736788365989923, batch loss ss: 0.005115752574056387, batch loss polya: 0.0001858300092862919\n",
      "batch loss 0.003918803762644529, batch loss prom: 0.0009145130170509219, batch loss ss: 0.0006399490521289408, batch loss polya: 0.0023643416352570057\n",
      "batch loss 0.004814933519810438, batch loss prom: 0.0012442474253475666, batch loss ss: 0.003515613032504916, batch loss polya: 5.507317473529838e-05\n",
      "batch loss 0.003029815386980772, batch loss prom: 0.001637666835449636, batch loss ss: 0.001364015624858439, batch loss polya: 2.8132995794294402e-05\n",
      "batch loss 0.0021792110055685043, batch loss prom: 0.0016799159348011017, batch loss ss: 0.0003510097449179739, batch loss polya: 0.00014828535495325923\n",
      "batch loss 0.0013941822107881308, batch loss prom: 0.00040558696491643786, batch loss ss: 0.00014697425649501383, batch loss polya: 0.0008416209602728486\n",
      "batch loss 0.07922539114952087, batch loss prom: 0.07593115419149399, batch loss ss: 0.003235940122976899, batch loss polya: 5.829164365422912e-05\n",
      "batch loss 0.012060102075338364, batch loss prom: 0.0020831567235291004, batch loss ss: 0.009970031678676605, batch loss polya: 6.9141146923357155e-06\n",
      "batch loss 0.06821854412555695, batch loss prom: 0.05757393687963486, batch loss ss: 0.010353545658290386, batch loss polya: 0.0002910667099058628\n",
      "batch loss 0.07147517800331116, batch loss prom: 0.06200952082872391, batch loss ss: 0.008981069549918175, batch loss polya: 0.00048458753735758364\n",
      "batch loss 0.0743064284324646, batch loss prom: 0.07283755391836166, batch loss ss: 0.0011748324614018202, batch loss polya: 0.00029404606902971864\n",
      "batch loss 0.0007535424083471298, batch loss prom: 0.00031192204914987087, batch loss ss: 0.00018439977429807186, batch loss polya: 0.00025722055579535663\n",
      "batch loss 0.0013757831184193492, batch loss prom: 0.0007101159426383674, batch loss ss: 0.00040999590419232845, batch loss polya: 0.00025567124248482287\n",
      "batch loss 0.001305788871832192, batch loss prom: 0.00048387263086624444, batch loss ss: 0.0007291757501661777, batch loss polya: 9.274052717955783e-05\n",
      "batch loss 0.001883466960862279, batch loss prom: 0.0007121411035768688, batch loss ss: 0.00038795097498223186, batch loss polya: 0.0007833749405108392\n",
      "batch loss 0.00732794962823391, batch loss prom: 0.0009617946925573051, batch loss ss: 0.0062612565234303474, batch loss polya: 0.00010489867418073118\n",
      "batch loss 0.0052711027674376965, batch loss prom: 0.002277163788676262, batch loss ss: 0.0027510200161486864, batch loss polya: 0.00024291902082040906\n",
      "batch loss 0.01169516146183014, batch loss prom: 0.003441247157752514, batch loss ss: 0.008234006352722645, batch loss polya: 1.9907753085135482e-05\n",
      "batch loss 0.0035493196919560432, batch loss prom: 0.000266278104390949, batch loss ss: 0.003073731902986765, batch loss polya: 0.00020930961181875318\n",
      "batch loss 0.0010314395185559988, batch loss prom: 0.00043501926120370626, batch loss ss: 0.00017975145601667464, batch loss polya: 0.0004166688595432788\n",
      "batch loss 0.002343034604564309, batch loss prom: 0.001101244823075831, batch loss ss: 0.001206504413858056, batch loss polya: 3.528532761265524e-05\n",
      "batch loss 0.010352378711104393, batch loss prom: 0.007817506790161133, batch loss ss: 0.0022103183437138796, batch loss polya: 0.00032455421751365066\n",
      "batch loss 0.06794068962335587, batch loss prom: 0.06240685284137726, batch loss ss: 0.005405334290117025, batch loss polya: 0.0001284993631998077\n",
      "batch loss 0.0007599812233820558, batch loss prom: 0.00028761065914295614, batch loss ss: 0.0002474478678777814, batch loss polya: 0.00022492263815365732\n",
      "batch loss 0.006485378835350275, batch loss prom: 0.001039322349242866, batch loss ss: 0.005413989536464214, batch loss polya: 3.2066785934148356e-05\n",
      "batch loss 0.006204313598573208, batch loss prom: 0.005239445716142654, batch loss ss: 0.0008522216230630875, batch loss polya: 0.00011264643399044871\n",
      "batch loss 0.015046462416648865, batch loss prom: 0.0030724245589226484, batch loss ss: 0.011951387859880924, batch loss polya: 2.2649508537142538e-05\n",
      "batch loss 0.008209668099880219, batch loss prom: 0.0009320206008851528, batch loss ss: 0.007244508247822523, batch loss polya: 3.313963316031732e-05\n",
      "batch loss 0.028259137645363808, batch loss prom: 0.0016562328673899174, batch loss ss: 0.026597540825605392, batch loss polya: 5.364403477869928e-06\n",
      "batch loss 0.01658795028924942, batch loss prom: 0.014903984032571316, batch loss ss: 0.0016817011637613177, batch loss polya: 2.264974000354414e-06\n",
      "batch loss 0.0014560618437826633, batch loss prom: 0.0008143446175381541, batch loss ss: 0.00037245964631438255, batch loss polya: 0.00026925752172246575\n",
      "batch loss 0.0008575745159760118, batch loss prom: 0.00038354191929101944, batch loss ss: 0.00015567521040793508, batch loss polya: 0.00031835734262131155\n",
      "batch loss 0.022093020379543304, batch loss prom: 0.004091820679605007, batch loss ss: 0.017992496490478516, batch loss polya: 8.702239938429557e-06\n",
      "batch loss 0.005444962996989489, batch loss prom: 0.00492158392444253, batch loss ss: 0.0002706876548472792, batch loss polya: 0.0002526917669456452\n",
      "batch loss 0.0007560453377664089, batch loss prom: 0.0002992897352669388, batch loss ss: 0.00018082413589581847, batch loss polya: 0.0002759314374998212\n",
      "batch loss 0.009409555234014988, batch loss prom: 0.0019729926716536283, batch loss ss: 0.007389356382191181, batch loss polya: 4.7205765440594405e-05\n",
      "batch loss 0.01089067105203867, batch loss prom: 0.00975059624761343, batch loss ss: 0.0011298231547698379, batch loss polya: 1.0251946150674485e-05\n",
      "batch loss 0.0008489972096867859, batch loss prom: 0.00033682872890494764, batch loss ss: 0.00016544880054425448, batch loss polya: 0.00034671969478949904\n",
      "batch loss 0.004299298860132694, batch loss prom: 0.0018397325184196234, batch loss ss: 0.002263010013848543, batch loss polya: 0.000196556793525815\n",
      "batch loss 0.02694769576191902, batch loss prom: 0.001069450518116355, batch loss ss: 0.02566416747868061, batch loss polya: 0.00021407696476671845\n",
      "batch loss 0.31984245777130127, batch loss prom: 0.31801676750183105, batch loss ss: 0.0017683359328657389, batch loss polya: 5.7338023907504976e-05\n",
      "batch loss 0.0007708269404247403, batch loss prom: 0.00028236693469807506, batch loss ss: 0.00024077377747744322, batch loss polya: 0.00024768622824922204\n",
      "batch loss 0.005065944045782089, batch loss prom: 0.004086596891283989, batch loss ss: 0.0009302341495640576, batch loss polya: 4.911301948595792e-05\n",
      "batch loss 0.04957681521773338, batch loss prom: 0.04487455636262894, batch loss ss: 0.004396416246891022, batch loss polya: 0.0003058442671317607\n",
      "batch loss 0.0010515745962038636, batch loss prom: 0.00045789722935296595, batch loss ss: 0.00017033556650858372, batch loss polya: 0.0004233417857903987\n",
      "batch loss 0.0022822616156190634, batch loss prom: 0.0003083468764089048, batch loss ss: 0.001927543431520462, batch loss polya: 4.637133679352701e-05\n",
      "batch loss 0.004605498164892197, batch loss prom: 0.0016336203552782536, batch loss ss: 0.0028020190075039864, batch loss polya: 0.00016985881666187197\n",
      "batch loss 0.0037657206412404776, batch loss prom: 0.003124239156022668, batch loss ss: 0.0003122795606032014, batch loss polya: 0.0003292018664069474\n",
      "batch loss 0.007284850813448429, batch loss prom: 0.000982278841547668, batch loss ss: 0.005926298908889294, batch loss polya: 0.0003762729174923152\n",
      "batch loss 0.02513202279806137, batch loss prom: 0.01861296407878399, batch loss ss: 0.006510476116091013, batch loss polya: 8.583032467868179e-06\n",
      "batch loss 0.007020866964012384, batch loss prom: 0.002836730098351836, batch loss ss: 0.0038899718783795834, batch loss polya: 0.00029416524921543896\n",
      "batch loss 0.0007248240290209651, batch loss prom: 0.00024959311122074723, batch loss ss: 0.00023147765023168176, batch loss polya: 0.00024375328212045133\n",
      "batch loss 0.0008345787064172328, batch loss prom: 0.00034517052699811757, batch loss ss: 0.00017188502533826977, batch loss polya: 0.0003175231395289302\n",
      "batch loss 0.005154752172529697, batch loss prom: 0.001312109874561429, batch loss ss: 0.003733214223757386, batch loss polya: 0.00010942813969450071\n",
      "batch loss 0.003857651259750128, batch loss prom: 0.0030573313124477863, batch loss ss: 0.0007599088130518794, batch loss polya: 4.0411134250462055e-05\n",
      "batch loss 0.2814180850982666, batch loss prom: 0.28033265471458435, batch loss ss: 0.0009439303539693356, batch loss polya: 0.00014149141497910023\n",
      "batch loss 0.0008787792758084834, batch loss prom: 0.00046135272714309394, batch loss ss: 0.00018034738604910672, batch loss polya: 0.00023707917716819793\n",
      "batch loss 0.03275778517127037, batch loss prom: 0.0010031197452917695, batch loss ss: 0.03175120800733566, batch loss polya: 3.4570634852570947e-06\n",
      "batch loss 0.0010504914680495858, batch loss prom: 0.00038223114097490907, batch loss ss: 0.00014840454969089478, batch loss polya: 0.0005198557628318667\n",
      "batch loss 0.0023314517457038164, batch loss prom: 0.0010387268848717213, batch loss ss: 0.0012762743281200528, batch loss polya: 1.645074735279195e-05\n",
      "batch loss 0.0007851268164813519, batch loss prom: 0.00029738296871073544, batch loss ss: 0.0002113357331836596, batch loss polya: 0.00027640812913887203\n",
      "batch loss 0.09105212986469269, batch loss prom: 0.08889615535736084, batch loss ss: 0.002093387534841895, batch loss polya: 6.258291978156194e-05\n",
      "batch loss 0.046827126294374466, batch loss prom: 0.04188809171319008, batch loss ss: 0.004627827554941177, batch loss polya: 0.00031120702624320984\n",
      "batch loss 0.0018471338553354144, batch loss prom: 0.0007059465860947967, batch loss ss: 0.0003829461056739092, batch loss polya: 0.0007582411635667086\n",
      "batch loss 0.0700637474656105, batch loss prom: 0.06648027896881104, batch loss ss: 0.003472728654742241, batch loss polya: 0.00011073929636040702\n",
      "batch loss 0.006124340929090977, batch loss prom: 0.0016421893378719687, batch loss ss: 0.004060358740389347, batch loss polya: 0.0004217927053105086\n",
      "batch loss 0.001570713589899242, batch loss prom: 0.0009298768127337098, batch loss ss: 0.0005413020844571292, batch loss polya: 9.953480184776708e-05\n",
      "batch loss 0.0032860152423381805, batch loss prom: 0.0007614573696628213, batch loss ss: 0.0025113255251199007, batch loss polya: 1.3232143828645349e-05\n",
      "batch loss 0.09139090776443481, batch loss prom: 0.07313011586666107, batch loss ss: 0.015686923637986183, batch loss polya: 0.0025738703552633524\n",
      "batch loss 0.0010015277657657862, batch loss prom: 0.0004638549580704421, batch loss ss: 0.000179036331246607, batch loss polya: 0.0003586364327929914\n",
      "batch loss 0.042750533670186996, batch loss prom: 0.0378158874809742, batch loss ss: 0.004194985143840313, batch loss polya: 0.000739658426027745\n",
      "batch loss 0.0024123406037688255, batch loss prom: 0.000639710808172822, batch loss ss: 0.0017669078661128879, batch loss polya: 5.722029527532868e-06\n",
      "batch loss 0.0015960129676386714, batch loss prom: 0.0007985025877133012, batch loss ss: 0.0001174142598756589, batch loss polya: 0.0006800960982218385\n",
      "batch loss 0.003348984755575657, batch loss prom: 0.002552348654717207, batch loss ss: 0.00039664984797127545, batch loss polya: 0.0003999863693024963\n",
      "batch loss 0.015222356654703617, batch loss prom: 0.0014791273279115558, batch loss ss: 0.01373106986284256, batch loss polya: 1.2159273865108844e-05\n",
      "batch loss 0.009879295714199543, batch loss prom: 0.0016171961324289441, batch loss ss: 0.008180564269423485, batch loss polya: 8.153582894010469e-05\n",
      "batch loss 0.0013788521755486727, batch loss prom: 0.0007768235518597066, batch loss ss: 0.0003840185818262398, batch loss polya: 0.00021801002731081098\n",
      "batch loss 0.0763322114944458, batch loss prom: 0.0735972598195076, batch loss ss: 0.002654007636010647, batch loss polya: 8.093983342405409e-05\n",
      "batch loss 0.0008450678433291614, batch loss prom: 0.00033945043105632067, batch loss ss: 0.00018571082910057157, batch loss polya: 0.00031990656862035394\n",
      "batch loss 0.01053591724485159, batch loss prom: 0.0012235306203365326, batch loss ss: 0.009301896207034588, batch loss polya: 1.0490362910786644e-05\n",
      "batch loss 0.0029731893446296453, batch loss prom: 0.002312725642696023, batch loss ss: 0.000621959799900651, batch loss polya: 3.85038583772257e-05\n",
      "batch loss 0.005005734972655773, batch loss prom: 0.0017444168915972114, batch loss ss: 0.0031642864923924208, batch loss polya: 9.703165414975956e-05\n",
      "batch loss 0.004658573307096958, batch loss prom: 0.0009925207123160362, batch loss ss: 0.0036491251084953547, batch loss polya: 1.6927575416048057e-05\n",
      "batch loss 0.0075133563950657845, batch loss prom: 0.006170982029289007, batch loss ss: 0.0013230626937001944, batch loss polya: 1.9311717551317997e-05\n",
      "batch loss 0.003624206641688943, batch loss prom: 0.0024852838832885027, batch loss ss: 0.00037949037505313754, batch loss polya: 0.0007594323833473027\n",
      "batch loss 0.015599679201841354, batch loss prom: 0.0026385514065623283, batch loss ss: 0.012956717051565647, batch loss polya: 4.410734163684538e-06\n",
      "batch loss 0.10961602628231049, batch loss prom: 0.10613906383514404, batch loss ss: 0.003419863060116768, batch loss polya: 5.709961988031864e-05\n",
      "batch loss 0.0007548558060079813, batch loss prom: 0.00029559535323642194, batch loss ss: 0.00024327656137757003, batch loss polya: 0.00021598390594590455\n",
      "batch loss 0.005840239115059376, batch loss prom: 0.001999285537749529, batch loss ss: 0.0037057793233543634, batch loss polya: 0.00013517419574782252\n",
      "batch loss 0.001259723911061883, batch loss prom: 0.0006384003208950162, batch loss ss: 0.000176652567461133, batch loss polya: 0.00044467096449807286\n",
      "batch loss 0.0018519118893891573, batch loss prom: 0.0011082704877480865, batch loss ss: 0.0006654431927017868, batch loss polya: 7.819823804311454e-05\n",
      "batch loss 0.004670808557420969, batch loss prom: 0.0007662221323698759, batch loss ss: 0.0037098173052072525, batch loss polya: 0.00019476900342851877\n",
      "batch loss 0.010009434074163437, batch loss prom: 0.0014915067004039884, batch loss ss: 0.008507675491273403, batch loss polya: 1.0251946150674485e-05\n",
      "batch loss 0.010191245004534721, batch loss prom: 0.00267350603826344, batch loss ss: 0.00750176515430212, batch loss polya: 1.597391747054644e-05\n",
      "batch loss 0.008667890913784504, batch loss prom: 0.003859572345390916, batch loss ss: 0.004752530250698328, batch loss polya: 5.578839045483619e-05\n",
      "batch loss 0.08481393754482269, batch loss prom: 0.08200326561927795, batch loss ss: 0.0024285605177283287, batch loss polya: 0.00038211196078918874\n",
      "batch loss 0.007264563348144293, batch loss prom: 0.006189108360558748, batch loss ss: 0.0005127069307491183, batch loss polya: 0.0005627478822134435\n",
      "batch loss 0.004987566266208887, batch loss prom: 0.0009634620510041714, batch loss ss: 0.003944356460124254, batch loss polya: 7.974783511599526e-05\n",
      "batch loss 0.009417323395609856, batch loss prom: 0.00764515670016408, batch loss ss: 0.0017592919757589698, batch loss polya: 1.2874520507466514e-05\n",
      "batch loss 0.0010221208212897182, batch loss prom: 0.0005471401382237673, batch loss ss: 0.00012838016846217215, batch loss polya: 0.0003466005437076092\n",
      "batch loss 0.006230068393051624, batch loss prom: 0.0010033579310402274, batch loss ss: 0.0050959461368620396, batch loss polya: 0.00013076403411105275\n",
      "batch loss 0.014890849590301514, batch loss prom: 0.0022690759506076574, batch loss ss: 0.012601865455508232, batch loss polya: 1.9907753085135482e-05\n",
      "batch loss 0.0007431746344082057, batch loss prom: 0.00028010259848088026, batch loss ss: 0.0001821352052502334, batch loss polya: 0.0002809368306770921\n",
      "batch loss 0.2633736729621887, batch loss prom: 0.25848662853240967, batch loss ss: 0.004740784410387278, batch loss polya: 0.00014625910262111574\n",
      "batch loss 0.013994591310620308, batch loss prom: 0.002645566128194332, batch loss ss: 0.011224458925426006, batch loss polya: 0.0001245659514097497\n",
      "batch loss 0.0007984699914231896, batch loss prom: 0.0003195490571670234, batch loss ss: 0.00017128908075392246, batch loss polya: 0.00030763185350224376\n",
      "batch loss 0.0007833394920453429, batch loss prom: 0.00025388356880284846, batch loss ss: 0.00022432672267314047, batch loss polya: 0.0003051292151212692\n",
      "batch loss 0.0008836679626256227, batch loss prom: 0.00042024365393444896, batch loss ss: 0.00014399446081370115, batch loss polya: 0.0003194298769813031\n",
      "batch loss 0.00115923210978508, batch loss prom: 0.00043049128726124763, batch loss ss: 0.000666277133859694, batch loss polya: 6.246371776796877e-05\n",
      "batch loss 0.0008306445088237524, batch loss prom: 0.0003579214389901608, batch loss ss: 0.0001646144810365513, batch loss polya: 0.0003081085451412946\n",
      "batch loss 0.11845356971025467, batch loss prom: 0.11731382459402084, batch loss ss: 0.0007919512572698295, batch loss polya: 0.0003477922291494906\n",
      "batch loss 0.007031814195215702, batch loss prom: 0.0010630200849846005, batch loss ss: 0.0059367273934185505, batch loss polya: 3.2066785934148356e-05\n",
      "batch loss 0.05120749771595001, batch loss prom: 0.042333152145147324, batch loss ss: 0.008756335824728012, batch loss polya: 0.00011801023356383666\n",
      "batch loss 0.00885029323399067, batch loss prom: 0.0016499252524226904, batch loss ss: 0.007065074983984232, batch loss polya: 0.00013529339048545808\n",
      "batch loss 0.0007814326672814786, batch loss prom: 0.00025281094713136554, batch loss ss: 0.0002244459028588608, batch loss polya: 0.00030417583184316754\n",
      "batch loss 0.006229187827557325, batch loss prom: 0.0007390628452412784, batch loss ss: 0.004762140568345785, batch loss polya: 0.0007279845303855836\n",
      "batch loss 0.005371876060962677, batch loss prom: 0.001039203256368637, batch loss ss: 0.004250302445143461, batch loss polya: 8.237022848334163e-05\n",
      "batch loss 0.0058306120336055756, batch loss prom: 0.0012032896047458053, batch loss ss: 0.004529098514467478, batch loss polya: 9.822363062994555e-05\n",
      "batch loss 0.004344038665294647, batch loss prom: 0.0032742007169872522, batch loss ss: 0.0010407513473182917, batch loss polya: 2.90866428258596e-05\n",
      "batch loss 0.0017517430242151022, batch loss prom: 0.0006619884516112506, batch loss ss: 0.0008874768391251564, batch loss polya: 0.0002022777043748647\n",
      "batch loss 0.0008527780883014202, batch loss prom: 0.0004655231023207307, batch loss ss: 0.0003295593778602779, batch loss polya: 5.769562994828448e-05\n",
      "batch loss 0.05099955573678017, batch loss prom: 0.043371424078941345, batch loss ss: 0.007054185029119253, batch loss polya: 0.0005739472107961774\n",
      "batch loss 0.04533926770091057, batch loss prom: 0.038732029497623444, batch loss ss: 0.0060784476809203625, batch loss polya: 0.0005287918029353023\n",
      "batch loss 0.0010996910277754068, batch loss prom: 0.00043358939001336694, batch loss ss: 0.0005523824947886169, batch loss polya: 0.0001137191939051263\n",
      "batch loss 0.0007742817979305983, batch loss prom: 0.00029297350556589663, batch loss ss: 0.0002109781780745834, batch loss polya: 0.0002703301142901182\n",
      "batch loss 0.0012791429180651903, batch loss prom: 0.0005516675882972777, batch loss ss: 0.00014983485743869096, batch loss polya: 0.0005776405450887978\n",
      "batch loss 0.0008033629273995757, batch loss prom: 0.00027533553657121956, batch loss ss: 0.0002585315378382802, batch loss polya: 0.0002694958820939064\n",
      "batch loss 0.002001032931730151, batch loss prom: 0.0013404440833255649, batch loss ss: 0.0006115949945524335, batch loss polya: 4.8993817472364753e-05\n",
      "batch loss 0.008577568456530571, batch loss prom: 0.0010302717564627528, batch loss ss: 0.0074865021742880344, batch loss polya: 6.0794889577664435e-05\n",
      "batch loss 0.0007512798183597624, batch loss prom: 0.00030417583184316754, batch loss ss: 0.00021336186910048127, batch loss polya: 0.0002337421028641984\n",
      "batch loss 0.0009393206564709544, batch loss prom: 0.00037746457383036613, batch loss ss: 0.00014828535495325923, batch loss polya: 0.0004135706985834986\n",
      "batch loss 0.0024444875307381153, batch loss prom: 0.0014804366510361433, batch loss ss: 0.000508417550008744, batch loss polya: 0.00045563330058939755\n",
      "batch loss 0.0013789408840239048, batch loss prom: 0.0011339908232912421, batch loss ss: 0.00022265815641731024, batch loss polya: 2.2291887944447808e-05\n",
      "batch loss 0.009524553082883358, batch loss prom: 0.00183723377995193, batch loss ss: 0.007571215741336346, batch loss polya: 0.0001161031104857102\n",
      "batch loss 0.010867876932024956, batch loss prom: 0.004351077135652304, batch loss ss: 0.006454335991293192, batch loss polya: 6.246371776796877e-05\n",
      "batch loss 0.0008672313997521996, batch loss prom: 0.00033563701435923576, batch loss ss: 0.00017450717859901488, batch loss polya: 0.0003570872650016099\n",
      "batch loss 0.0033376303035765886, batch loss prom: 0.0008430502493865788, batch loss ss: 0.0024861162528395653, batch loss polya: 8.4638240878121e-06\n",
      "batch loss 0.006397185381501913, batch loss prom: 0.002263485686853528, batch loss ss: 0.004082441329956055, batch loss polya: 5.125868119648658e-05\n",
      "batch loss 0.0035010231658816338, batch loss prom: 0.0028729853220283985, batch loss ss: 0.0006245807744562626, batch loss polya: 3.4570634852570947e-06\n",
      "batch loss 0.0007395944558084011, batch loss prom: 0.00034350217902101576, batch loss ss: 0.00016640232934150845, batch loss polya: 0.00022968991834204644\n",
      "batch loss 0.0008006219286471605, batch loss prom: 0.00027426297310739756, batch loss ss: 0.0002585315378382802, batch loss polya: 0.00026782741770148277\n",
      "batch loss 0.002682736609131098, batch loss prom: 0.002229587407782674, batch loss ss: 0.0004085659747943282, batch loss polya: 4.458328112377785e-05\n",
      "batch loss 0.00673192273825407, batch loss prom: 0.0021721357479691505, batch loss ss: 0.0040076426230371, batch loss polya: 0.0005521441926248372\n",
      "batch loss 0.0012475944822654128, batch loss prom: 0.0005992047372274101, batch loss ss: 0.0003844952443614602, batch loss polya: 0.000263894529780373\n",
      "batch loss 0.0022892518900334835, batch loss prom: 0.0011923355050384998, batch loss ss: 0.0010209829779341817, batch loss polya: 7.593343616463244e-05\n",
      "batch loss 0.0007179075619205832, batch loss prom: 0.00030250742565840483, batch loss ss: 0.00017426878912374377, batch loss polya: 0.0002411313180346042\n",
      "batch loss 0.0010182010009884834, batch loss prom: 0.0003738896339200437, batch loss ss: 0.00014840454969089478, batch loss polya: 0.0004959068610332906\n",
      "batch loss 0.0045447624288499355, batch loss prom: 0.0003313469351269305, batch loss ss: 0.004206143785268068, batch loss polya: 7.271740287251305e-06\n",
      "batch loss 0.1701241433620453, batch loss prom: 0.14796553552150726, batch loss ss: 0.022054413333535194, batch loss polya: 0.00010418349120300263\n",
      "batch loss 0.003130381228402257, batch loss prom: 0.0022131730802357197, batch loss ss: 0.0008263748604804277, batch loss polya: 9.083335316972807e-05\n",
      "batch loss 0.0019741179421544075, batch loss prom: 0.000942977552767843, batch loss ss: 0.000995974289253354, batch loss polya: 3.516612196108326e-05\n",
      "batch loss 0.027306625619530678, batch loss prom: 0.009261267259716988, batch loss ss: 0.01804202049970627, batch loss polya: 3.3378546504536644e-06\n",
      "batch loss 0.002341152634471655, batch loss prom: 0.0016437364974990487, batch loss ss: 0.0006224363460205495, batch loss polya: 7.497983460780233e-05\n",
      "batch loss 0.004989071283489466, batch loss prom: 0.001419966109097004, batch loss ss: 0.003418912645429373, batch loss polya: 0.0001501924270996824\n",
      "batch loss 0.009884432889521122, batch loss prom: 0.0008233971311710775, batch loss ss: 0.00902312807738781, batch loss polya: 3.790783375734463e-05\n",
      "batch loss 0.002470174804329872, batch loss prom: 0.0008578196284361184, batch loss ss: 0.00010466027742950246, batch loss polya: 0.0015076948329806328\n",
      "batch loss 0.07843413203954697, batch loss prom: 0.07454495131969452, batch loss ss: 0.0036839256063103676, batch loss polya: 0.00020525732543319464\n",
      "batch loss 0.001009630155749619, batch loss prom: 0.00044800734031014144, batch loss ss: 0.00016902448260225356, batch loss polya: 0.000392598332837224\n",
      "batch loss 0.05993306636810303, batch loss prom: 0.05659199506044388, batch loss ss: 0.003199222730472684, batch loss polya: 0.00014184899919200689\n",
      "batch loss 0.0020607805345207453, batch loss prom: 0.0008784249657765031, batch loss ss: 0.0011635207338258624, batch loss polya: 1.883488948806189e-05\n",
      "batch loss 0.0007407924858853221, batch loss prom: 0.00028618055512197316, batch loss ss: 0.00020168177434243262, batch loss polya: 0.00025293012731708586\n",
      "batch loss 0.0024740167427808046, batch loss prom: 0.001303895260207355, batch loss ss: 0.0011237503495067358, batch loss polya: 4.637133679352701e-05\n",
      "batch loss 0.0010599968954920769, batch loss prom: 0.0006287504802457988, batch loss ss: 0.0001357701694360003, batch loss polya: 0.0002954761730507016\n",
      "batch loss 0.007670530583709478, batch loss prom: 0.001141730579547584, batch loss ss: 0.006497448310256004, batch loss polya: 3.135155202471651e-05\n",
      "batch loss 0.0008582938462495804, batch loss prom: 0.00033444532891735435, batch loss ss: 0.00017414960893802345, batch loss polya: 0.0003496989083942026\n",
      "batch loss 0.0008594893151894212, batch loss prom: 0.0003194298769813031, batch loss ss: 0.00020001317898277193, batch loss polya: 0.0003400462737772614\n",
      "batch loss 0.011280849575996399, batch loss prom: 0.0002097863471135497, batch loss ss: 0.010921228677034378, batch loss polya: 0.00014983485743869096\n",
      "batch loss 0.008753001689910889, batch loss prom: 0.0008735416340641677, batch loss ss: 0.007585294544696808, batch loss polya: 0.00029416524921543896\n",
      "batch loss 0.0014340614434331656, batch loss prom: 0.0007990981102921069, batch loss ss: 0.0006053998949937522, batch loss polya: 2.95634672511369e-05\n",
      "batch loss 0.002781399991363287, batch loss prom: 0.0003083468764089048, batch loss ss: 0.0024165494833141565, batch loss polya: 5.6503606174374e-05\n",
      "batch loss 0.004842041525989771, batch loss prom: 0.0010973153403028846, batch loss ss: 0.003580827033147216, batch loss polya: 0.00016389934171456844\n",
      "batch loss 0.005465229973196983, batch loss prom: 0.004881251137703657, batch loss ss: 0.0005395148764364421, batch loss polya: 4.446407547220588e-05\n",
      "batch loss 0.05957057699561119, batch loss prom: 0.054776228964328766, batch loss ss: 0.004404012113809586, batch loss polya: 0.00039033422945067286\n",
      "batch loss 0.007659708149731159, batch loss prom: 0.006770764011889696, batch loss ss: 0.0008440031087957323, batch loss polya: 4.494089080253616e-05\n",
      "batch loss 0.005634799133986235, batch loss prom: 0.0013010379625484347, batch loss ss: 0.0042466227896511555, batch loss polya: 8.713819261174649e-05\n",
      "batch loss 0.04518044739961624, batch loss prom: 0.008363342843949795, batch loss ss: 0.03681698441505432, batch loss polya: 1.1920928244535389e-07\n",
      "batch loss 0.000749370432458818, batch loss prom: 0.0003064401389565319, batch loss ss: 0.00017307691450696439, batch loss polya: 0.0002698534226510674\n",
      "batch loss 0.0008070498006418347, batch loss prom: 0.000339569611242041, batch loss ss: 0.00017033556650858372, batch loss polya: 0.0002971446083392948\n",
      "batch loss 0.0007541345548816025, batch loss prom: 0.00034683887497521937, batch loss ss: 0.00017271934484597296, batch loss polya: 0.00023457636416424066\n",
      "batch loss 0.007415373809635639, batch loss prom: 0.0008831891464069486, batch loss ss: 0.006453033071011305, batch loss polya: 7.915183232398704e-05\n",
      "batch loss 0.6101373434066772, batch loss prom: 0.0025134659372270107, batch loss ss: 0.6075709462165833, batch loss polya: 5.2927523938706145e-05\n",
      "batch loss 0.0018250290304422379, batch loss prom: 0.0012061471352353692, batch loss ss: 0.0005853846669197083, batch loss polya: 3.349725011503324e-05\n",
      "batch loss 0.0018394009675830603, batch loss prom: 0.0005936052766628563, batch loss ss: 0.0007967158453539014, batch loss polya: 0.00044907975825481117\n",
      "batch loss 0.053537748754024506, batch loss prom: 0.05102727189660072, batch loss ss: 0.002193308901041746, batch loss polya: 0.00031716562807559967\n",
      "batch loss 0.017257023602724075, batch loss prom: 0.01623176597058773, batch loss ss: 0.0007047553663142025, batch loss polya: 0.00032050241134129465\n",
      "batch loss 0.004565555136650801, batch loss prom: 0.00419581588357687, batch loss ss: 0.00030214988510124385, batch loss polya: 6.758938252460212e-05\n",
      "batch loss 0.0023777771275490522, batch loss prom: 0.0008394769974984229, batch loss ss: 0.0015284058172255754, batch loss polya: 9.894321920000948e-06\n",
      "batch loss 0.011314811185002327, batch loss prom: 0.0005004345439374447, batch loss ss: 0.010749648325145245, batch loss polya: 6.472854875028133e-05\n",
      "batch loss 0.0015780387911945581, batch loss prom: 0.0011788808042183518, batch loss ss: 0.00038413776201196015, batch loss polya: 1.5020257706055418e-05\n",
      "batch loss 0.008244060911238194, batch loss prom: 0.007008255925029516, batch loss ss: 0.0012269833823665977, batch loss polya: 8.821448318485636e-06\n",
      "batch loss 0.009685280732810497, batch loss prom: 0.002195450011640787, batch loss ss: 0.0073585896752774715, batch loss polya: 0.00013124081306159496\n",
      "batch loss 0.034672390669584274, batch loss prom: 0.0020918408408761024, batch loss ss: 0.03253572806715965, batch loss polya: 4.482168878894299e-05\n",
      "batch loss 0.0007667753379791975, batch loss prom: 0.0002640137099660933, batch loss ss: 0.00024923557066358626, batch loss polya: 0.0002535260282456875\n",
      "batch loss 0.0008087115129455924, batch loss prom: 0.0003992714046034962, batch loss ss: 0.00016151554882526398, batch loss polya: 0.0002479245886206627\n",
      "batch loss 0.0014350184937939048, batch loss prom: 0.0006555553991347551, batch loss ss: 0.0007543102256022394, batch loss polya: 2.5152843591058627e-05\n",
      "batch loss 0.005859341938048601, batch loss prom: 0.001117201172746718, batch loss ss: 0.004628302529454231, batch loss polya: 0.00011383838864276186\n",
      "batch loss 0.0007452024146914482, batch loss prom: 0.000286657246761024, batch loss ss: 0.0002499506517779082, batch loss polya: 0.00020859450160060078\n",
      "batch loss 0.0008118159021250904, batch loss prom: 0.00031871485407464206, batch loss ss: 0.00016282663273159415, batch loss polya: 0.0003302744007669389\n",
      "batch loss 0.014161347411572933, batch loss prom: 0.0019180249655619264, batch loss ss: 0.012236288748681545, batch loss polya: 7.033323527139146e-06\n",
      "batch loss 0.0010927445255219936, batch loss prom: 0.0006883158930577338, batch loss ss: 0.0002898749662563205, batch loss polya: 0.00011455356434453279\n",
      "batch loss 0.0009733695769682527, batch loss prom: 0.0004782725009135902, batch loss ss: 0.00043990471749566495, batch loss polya: 5.519237674889155e-05\n",
      "batch loss 0.2232975959777832, batch loss prom: 0.20733115077018738, batch loss ss: 0.01584557257592678, batch loss polya: 0.00012087091454304755\n",
      "batch loss 0.002312872326001525, batch loss prom: 0.001660517300479114, batch loss ss: 0.0006267252028919756, batch loss polya: 2.5629668016335927e-05\n",
      "batch loss 0.005440551787614822, batch loss prom: 0.0016884845681488514, batch loss ss: 0.0036960402503609657, batch loss polya: 5.602679812000133e-05\n",
      "batch loss 0.0007278023404069245, batch loss prom: 0.00028391621890477836, batch loss ss: 0.00021920185827184469, batch loss polya: 0.00022468426323030144\n",
      "batch loss 0.5510870218276978, batch loss prom: 0.4760408401489258, batch loss ss: 0.07504593580961227, batch loss polya: 2.3841855067985307e-07\n",
      "batch loss 0.000709211453795433, batch loss prom: 0.00024172721896320581, batch loss ss: 0.0002369599969824776, batch loss polya: 0.00023052419419400394\n",
      "batch loss 0.006126450840383768, batch loss prom: 0.0011211306555196643, batch loss ss: 0.004959187004715204, batch loss polya: 4.6132929128361866e-05\n",
      "batch loss 0.010773740708827972, batch loss prom: 0.00970372837036848, batch loss ss: 0.0008199428557418287, batch loss polya: 0.00025006983196362853\n",
      "batch loss 0.0859101414680481, batch loss prom: 0.07796447724103928, batch loss ss: 0.007877237163484097, batch loss polya: 6.842378934379667e-05\n",
      "batch loss 0.0019150819862261415, batch loss prom: 0.0012288884026929736, batch loss ss: 0.0006524579366669059, batch loss polya: 3.373566141817719e-05\n",
      "batch loss 0.0016221884870901704, batch loss prom: 0.000771939754486084, batch loss ss: 0.0007838514284230769, batch loss polya: 6.639736966462806e-05\n",
      "batch loss 0.0007298268610611558, batch loss prom: 0.000288087350782007, batch loss ss: 0.00018475732940714806, batch loss polya: 0.000256982195423916\n",
      "batch loss 0.005003683734685183, batch loss prom: 0.001434369827620685, batch loss ss: 0.0034988634288311005, batch loss polya: 7.045020902296528e-05\n",
      "batch loss 0.060499366372823715, batch loss prom: 0.054522495716810226, batch loss ss: 0.005666976794600487, batch loss polya: 0.00030989613151177764\n",
      "batch loss 0.007907402701675892, batch loss prom: 0.0004027270770166069, batch loss ss: 0.007495139259845018, batch loss polya: 9.536697689327411e-06\n",
      "batch loss 0.0035574124194681644, batch loss prom: 0.000520570669323206, batch loss ss: 0.0030133577529340982, batch loss polya: 2.3483953555114567e-05\n",
      "batch loss 0.0007156444480642676, batch loss prom: 0.0002798642381094396, batch loss ss: 0.0001793938863556832, batch loss polya: 0.0002563863235991448\n",
      "batch loss 0.0057090409100055695, batch loss prom: 0.001583870965987444, batch loss ss: 0.00409882515668869, batch loss polya: 2.634490556374658e-05\n",
      "batch loss 0.0006964580388739705, batch loss prom: 0.00026770823751576245, batch loss ss: 0.00020823694649152458, batch loss polya: 0.0002205128694185987\n",
      "batch loss 0.0007297098636627197, batch loss prom: 0.0002723561483435333, batch loss ss: 0.0002356490003876388, batch loss polya: 0.0002217047003796324\n",
      "batch loss 0.0007575984345749021, batch loss prom: 0.0002656822034623474, batch loss ss: 0.00025197668583132327, batch loss polya: 0.00023993951617740095\n",
      "batch loss 0.06310908496379852, batch loss prom: 0.06124162673950195, batch loss ss: 0.0018016549292951822, batch loss polya: 6.580135959666222e-05\n",
      "batch loss 0.0007662986172363162, batch loss prom: 0.000259365770034492, batch loss ss: 0.0002548369811847806, batch loss polya: 0.0002520958660170436\n",
      "batch loss 0.00158766470849514, batch loss prom: 0.0012175773736089468, batch loss ss: 0.00033742457162588835, batch loss polya: 3.266281055402942e-05\n",
      "batch loss 0.0028499222826212645, batch loss prom: 0.002193665597587824, batch loss ss: 0.0003718638326972723, batch loss polya: 0.0002843929105438292\n",
      "batch loss 0.008456479758024216, batch loss prom: 0.0011269653914496303, batch loss ss: 0.0072919647209346294, batch loss polya: 3.755022044060752e-05\n",
      "batch loss 0.7575383186340332, batch loss prom: 0.7560263276100159, batch loss ss: 0.0008779485360719264, batch loss polya: 0.000633992429357022\n",
      "batch loss 0.017369307577610016, batch loss prom: 0.0017577449325472116, batch loss ss: 0.015597495250403881, batch loss polya: 1.4066597032069694e-05\n",
      "batch loss 0.0007902434444986284, batch loss prom: 0.0003399271226953715, batch loss ss: 0.00014995403762441128, batch loss polya: 0.0003003622987307608\n",
      "batch loss 0.0015517210122197866, batch loss prom: 0.0008542464347556233, batch loss ss: 0.0004773192631546408, batch loss polya: 0.00022015532886143774\n",
      "batch loss 0.001365593750961125, batch loss prom: 0.0005623904871754348, batch loss ss: 0.0007271506474353373, batch loss polya: 7.60526381782256e-05\n",
      "batch loss 0.015034390613436699, batch loss prom: 0.0014766276581212878, batch loss ss: 0.01350316684693098, batch loss polya: 5.4596363042946905e-05\n",
      "batch loss 0.0007752338424324989, batch loss prom: 0.00031120702624320984, batch loss ss: 0.000198821333469823, batch loss polya: 0.00026520551182329655\n",
      "batch loss 0.005220569670200348, batch loss prom: 0.002165950369089842, batch loss ss: 0.003007890423759818, batch loss polya: 4.672895011026412e-05\n",
      "batch loss 0.052693042904138565, batch loss prom: 0.04948696494102478, batch loss ss: 0.0028901018667966127, batch loss polya: 0.0003159739135298878\n",
      "batch loss 0.0055615720339119434, batch loss prom: 0.0014869834994897246, batch loss ss: 0.0040494357235729694, batch loss polya: 2.5152843591058627e-05\n",
      "batch loss 0.004781681578606367, batch loss prom: 0.0008740180637687445, batch loss ss: 0.003814446274191141, batch loss polya: 9.321732068201527e-05\n",
      "batch loss 0.003038649447262287, batch loss prom: 0.0015829188050702214, batch loss ss: 0.0007148809381760657, batch loss polya: 0.0007408496458083391\n",
      "batch loss 0.008981204591691494, batch loss prom: 0.002598720835521817, batch loss ss: 0.0062028514221310616, batch loss polya: 0.00017963226127903908\n",
      "batch loss 0.0010195894865319133, batch loss prom: 0.0004377598816063255, batch loss ss: 0.0005469018360599875, batch loss polya: 3.4927710657939315e-05\n",
      "batch loss 0.0007737986161373556, batch loss prom: 0.0003352795320097357, batch loss ss: 0.00015758226800244302, batch loss polya: 0.0002809368306770921\n",
      "batch loss 0.36352771520614624, batch loss prom: 0.35802870988845825, batch loss ss: 0.00549662671983242, batch loss polya: 2.3841830625315197e-06\n",
      "batch loss 0.0007119500078260899, batch loss prom: 0.00027616979787126184, batch loss ss: 0.00017927470616996288, batch loss polya: 0.00025650550378486514\n",
      "batch loss 0.052840471267700195, batch loss prom: 0.04041457921266556, batch loss ss: 0.01218035165220499, batch loss polya: 0.0002455409849062562\n",
      "batch loss 0.5923126935958862, batch loss prom: 0.5917325615882874, batch loss ss: 0.0003781795676331967, batch loss polya: 0.0002019201492657885\n",
      "batch loss 0.0009629224659875035, batch loss prom: 0.00040713604539632797, batch loss ss: 0.00018153927521780133, batch loss polya: 0.00037424711626954377\n",
      "batch loss 0.013086563907563686, batch loss prom: 0.001838185708038509, batch loss ss: 0.011153611354529858, batch loss polya: 9.476689592702314e-05\n",
      "batch loss 0.06079905480146408, batch loss prom: 0.05864676460623741, batch loss ss: 0.002024507150053978, batch loss polya: 0.00012778419477399439\n",
      "batch loss 0.07772596925497055, batch loss prom: 0.06295481324195862, batch loss ss: 0.014533961191773415, batch loss polya: 0.00023719835735391825\n",
      "batch loss 0.00282171368598938, batch loss prom: 0.0013188959565013647, batch loss ss: 0.001416513929143548, batch loss polya: 8.630380034446716e-05\n",
      "batch loss 0.04460207745432854, batch loss prom: 0.0011544713051989675, batch loss ss: 0.043443791568279266, batch loss polya: 3.814689989667386e-06\n",
      "batch loss 0.0019197327783331275, batch loss prom: 0.0010081215295940638, batch loss ss: 0.0008191090892069042, batch loss polya: 9.250213042832911e-05\n",
      "batch loss 0.01185903511941433, batch loss prom: 0.010611655190587044, batch loss ss: 0.0012173393042758107, batch loss polya: 3.0040289857424796e-05\n",
      "batch loss 0.007202818989753723, batch loss prom: 0.003596031339839101, batch loss ss: 0.003554694587364793, batch loss polya: 5.209310256759636e-05\n",
      "batch loss 0.011881759390234947, batch loss prom: 0.010074716061353683, batch loss ss: 0.0011632826644927263, batch loss polya: 0.0006437613046728075\n",
      "batch loss 0.0008139647543430328, batch loss prom: 0.00031990656862035394, batch loss ss: 0.00018940561858471483, batch loss polya: 0.0003046525234822184\n",
      "batch loss 0.0007224362925626338, batch loss prom: 0.0003091811086051166, batch loss ss: 0.00017987063620239496, batch loss polya: 0.00023338454775512218\n",
      "batch loss 0.0008114607771858573, batch loss prom: 0.00029213930247351527, batch loss ss: 0.00018225439998786896, batch loss polya: 0.00033706706017255783\n",
      "batch loss 0.05064887925982475, batch loss prom: 0.04847387969493866, batch loss ss: 0.0019920284394174814, batch loss polya: 0.0001829695247579366\n",
      "batch loss 0.06456013768911362, batch loss prom: 0.06248155236244202, batch loss ss: 0.001916835200972855, batch loss polya: 0.00016175392374861985\n",
      "batch loss 0.007684790063649416, batch loss prom: 0.0014197280397638679, batch loss ss: 0.006205220706760883, batch loss polya: 5.98412734689191e-05\n",
      "batch loss 0.003205738728865981, batch loss prom: 0.0019417019793763757, batch loss ss: 0.0011368485866114497, batch loss polya: 0.00012718822108581662\n",
      "batch loss 0.0007300638826563954, batch loss prom: 0.00029952809563837945, batch loss ss: 0.0001726001501083374, batch loss polya: 0.0002579356369096786\n",
      "batch loss 0.0008194427937269211, batch loss prom: 0.0003797286772169173, batch loss ss: 0.00019464982324279845, batch loss polya: 0.0002450642641633749\n",
      "batch loss 0.009230869822204113, batch loss prom: 0.001039322349242866, batch loss ss: 0.00817855354398489, batch loss polya: 1.2993727978027891e-05\n",
      "batch loss 0.001741331536322832, batch loss prom: 0.0009171332349069417, batch loss ss: 0.0007007050444371998, batch loss polya: 0.0001234931987710297\n",
      "batch loss 0.0007923943921923637, batch loss prom: 0.00029023250681348145, batch loss ss: 0.00018976318824570626, batch loss polya: 0.0003123987407889217\n",
      "batch loss 0.002577394712716341, batch loss prom: 0.0020412816666066647, batch loss ss: 0.0004040378553327173, batch loss polya: 0.00013207517622504383\n",
      "batch loss 0.0007024168153293431, batch loss prom: 0.00026008085114881396, batch loss ss: 0.0001928620331455022, batch loss polya: 0.0002494739310350269\n",
      "batch loss 0.0007698711124248803, batch loss prom: 0.0003044141922146082, batch loss ss: 0.00019858295854646713, batch loss polya: 0.0002668739762157202\n",
      "batch loss 0.001213144976645708, batch loss prom: 0.0004226268210913986, batch loss ss: 0.0001932195882545784, batch loss polya: 0.0005972985527478158\n",
      "batch loss 0.05041714012622833, batch loss prom: 0.04715140908956528, batch loss ss: 0.0029094768688082695, batch loss polya: 0.000356253091013059\n",
      "batch loss 0.0180915966629982, batch loss prom: 0.0061263153329491615, batch loss ss: 0.011945969425141811, batch loss polya: 1.9311717551317997e-05\n",
      "batch loss 0.011864074505865574, batch loss prom: 0.011280803009867668, batch loss ss: 0.0005230727256275713, batch loss polya: 6.01988795096986e-05\n",
      "batch loss 0.005155334249138832, batch loss prom: 0.004092295654118061, batch loss ss: 0.0009120118920691311, batch loss polya: 0.0001510267611593008\n",
      "batch loss 0.005446059163659811, batch loss prom: 0.0024365282151848078, batch loss ss: 0.00285075674764812, batch loss polya: 0.00015877417172305286\n",
      "batch loss 0.006935446988791227, batch loss prom: 0.0022190012969076633, batch loss ss: 0.004643134772777557, batch loss polya: 7.331102824537084e-05\n",
      "batch loss 3.1333324909210205, batch loss prom: 0.013257801532745361, batch loss ss: 3.119666814804077, batch loss polya: 0.0004078510100953281\n",
      "batch loss 0.002296755090355873, batch loss prom: 0.0010550415609031916, batch loss ss: 0.0011685217032209039, batch loss polya: 7.319182623177767e-05\n",
      "batch loss 0.0021448128391057253, batch loss prom: 0.0016509962733834982, batch loss ss: 0.0003270567976869643, batch loss polya: 0.00016675988445058465\n",
      "batch loss 0.0019592782482504845, batch loss prom: 0.0014505588915199041, batch loss ss: 0.00029047083808109164, batch loss polya: 0.00021824838768225163\n",
      "batch loss 0.005374266300350428, batch loss prom: 0.0015281677478924394, batch loss ss: 0.0038294093683362007, batch loss polya: 1.6689160474925302e-05\n",
      "batch loss 0.0007914409507066011, batch loss prom: 0.0002898749662563205, batch loss ss: 0.00018916724366135895, batch loss polya: 0.0003123987407889217\n",
      "batch loss 0.05458369478583336, batch loss prom: 0.0416024811565876, batch loss ss: 0.012651893310248852, batch loss polya: 0.0003293210465926677\n",
      "batch loss 0.003721094923093915, batch loss prom: 0.00300586991943419, batch loss ss: 0.0005067494930699468, batch loss polya: 0.00020847532141488045\n",
      "batch loss 0.007310403510928154, batch loss prom: 0.002591111231595278, batch loss ss: 0.004369355272501707, batch loss polya: 0.0003499372396618128\n",
      "batch loss 0.0007257737452164292, batch loss prom: 0.00028546550311148167, batch loss ss: 0.0001711698860162869, batch loss polya: 0.00026913834153674543\n",
      "batch loss 0.052592817693948746, batch loss prom: 0.048867203295230865, batch loss ss: 0.003371984465047717, batch loss polya: 0.00035363141796551645\n",
      "batch loss 0.005694166757166386, batch loss prom: 0.0007491880678571761, batch loss ss: 0.0048412722535431385, batch loss polya: 0.0001037067049765028\n",
      "batch loss 0.001669762423262, batch loss prom: 0.0009781105909496546, batch loss ss: 0.0003352795320097357, batch loss polya: 0.00035637227119877934\n",
      "batch loss 0.0028833546675741673, batch loss prom: 0.002094101160764694, batch loss ss: 0.0007320346776396036, batch loss polya: 5.721882189391181e-05\n",
      "batch loss 0.05228375270962715, batch loss prom: 0.047584809362888336, batch loss ss: 0.00444911140948534, batch loss polya: 0.0002498314715921879\n",
      "batch loss 0.0007710655918344855, batch loss prom: 0.00027414379292167723, batch loss ss: 0.0002517383254598826, batch loss polya: 0.0002451834443490952\n",
      "batch loss 0.010747136548161507, batch loss prom: 0.006685864180326462, batch loss ss: 0.004040768835693598, batch loss polya: 2.0503786799963564e-05\n",
      "batch loss 0.02715020626783371, batch loss prom: 0.006701258011162281, batch loss ss: 0.0204483512789011, batch loss polya: 5.960462772236497e-07\n",
      "batch loss 0.002183927921578288, batch loss prom: 0.0005305789527483284, batch loss ss: 0.0014212755486369133, batch loss polya: 0.0002320735511602834\n",
      "batch loss 0.0007403124473057687, batch loss prom: 0.0003238391946069896, batch loss ss: 0.0001833270798670128, batch loss polya: 0.00023314618738368154\n",
      "batch loss 0.0023322824854403734, batch loss prom: 0.0017333496361970901, batch loss ss: 0.00023457636416424066, batch loss polya: 0.00036435641231946647\n",
      "batch loss 0.0058515239506959915, batch loss prom: 0.000717144284863025, batch loss ss: 0.005086339078843594, batch loss polya: 4.8040190449682996e-05\n",
      "batch loss 0.0007206522859632969, batch loss prom: 0.00026544384309090674, batch loss ss: 0.00023266946664080024, batch loss polya: 0.0002225389762315899\n",
      "batch loss 0.0035199217963963747, batch loss prom: 0.0018434212543070316, batch loss ss: 0.001578157884068787, batch loss polya: 9.83428253675811e-05\n",
      "batch loss 0.000943973776884377, batch loss prom: 0.0004232226056046784, batch loss ss: 0.00018070495571009815, batch loss polya: 0.0003400462737772614\n",
      "batch loss 0.0007317342096939683, batch loss prom: 0.0002755738969426602, batch loss ss: 0.00018749863374978304, batch loss polya: 0.0002686616498976946\n",
      "batch loss 0.05226042494177818, batch loss prom: 0.04991958290338516, batch loss ss: 0.0016720612766221166, batch loss polya: 0.0006687788409180939\n",
      "batch loss 0.00666316132992506, batch loss prom: 0.002242433140054345, batch loss ss: 0.004342887084931135, batch loss polya: 7.784063927829266e-05\n",
      "batch loss 0.0029183542355895042, batch loss prom: 0.0021949741058051586, batch loss ss: 0.000660439720377326, batch loss polya: 6.294052582234144e-05\n",
      "batch loss 0.06748531758785248, batch loss prom: 0.06544318795204163, batch loss ss: 0.0019767999183386564, batch loss polya: 6.532455881824717e-05\n",
      "batch loss 0.056538645178079605, batch loss prom: 0.053914546966552734, batch loss ss: 0.0024567442014813423, batch loss polya: 0.00016735584358684719\n",
      "batch loss 0.0006975288270041347, batch loss prom: 0.0002719986077863723, batch loss ss: 0.0001716466504149139, batch loss polya: 0.00025388356880284846\n",
      "batch loss 0.000736857415176928, batch loss prom: 0.0002932118659373373, batch loss ss: 0.00017498392844572663, batch loss polya: 0.0002686616498976946\n",
      "batch loss 0.0012685043038800359, batch loss prom: 0.00037472377880476415, batch loss ss: 0.0001479277852922678, batch loss polya: 0.0007458527106791735\n",
      "batch loss 0.0007948930142447352, batch loss prom: 0.0003383779258001596, batch loss ss: 0.00016199229867197573, batch loss polya: 0.00029452278977259994\n",
      "batch loss 0.005650235339999199, batch loss prom: 0.0015867274487391114, batch loss ss: 0.003988170530647039, batch loss polya: 7.533743337262422e-05\n",
      "batch loss 0.032688967883586884, batch loss prom: 0.001293656532652676, batch loss ss: 0.031392451375722885, batch loss polya: 2.861018856492592e-06\n",
      "batch loss 0.00476347841322422, batch loss prom: 0.0012688927818089724, batch loss ss: 0.003277052426710725, batch loss polya: 0.00021753329201601446\n",
      "batch loss 0.004135938826948404, batch loss prom: 0.0009248746791854501, batch loss ss: 0.0028966395184397697, batch loss polya: 0.00031442465842701495\n",
      "batch loss 0.0009812605567276478, batch loss prom: 0.0004843492351938039, batch loss ss: 0.00014578233822248876, batch loss polya: 0.0003511289251036942\n",
      "batch loss 0.01997304894030094, batch loss prom: 0.00076908094342798, batch loss ss: 0.019189544022083282, batch loss polya: 1.4424220353248529e-05\n",
      "batch loss 0.273500919342041, batch loss prom: 0.2601967751979828, batch loss ss: 0.013269447721540928, batch loss polya: 3.4689302992774174e-05\n",
      "batch loss 0.003379588946700096, batch loss prom: 0.001069450518116355, batch loss ss: 0.0022973830346018076, batch loss polya: 1.2755313036905136e-05\n",
      "batch loss 0.7267706990242004, batch loss prom: 0.01807468570768833, batch loss ss: 0.708694577217102, batch loss polya: 1.4305104514278355e-06\n",
      "batch loss 0.005807832349091768, batch loss prom: 0.0008663953049108386, batch loss ss: 0.004783258773386478, batch loss polya: 0.00015817821258679032\n",
      "batch loss 0.0007375702261924744, batch loss prom: 0.0003302744007669389, batch loss ss: 0.0001754606782924384, batch loss polya: 0.00023183519078884274\n",
      "batch loss 0.0007399548776447773, batch loss prom: 0.0003240775258745998, batch loss ss: 0.00018273114983458072, batch loss polya: 0.00023314618738368154\n",
      "batch loss 0.005152651574462652, batch loss prom: 0.0023071356117725372, batch loss ss: 0.0028067738749086857, batch loss polya: 3.8742269680369645e-05\n",
      "batch loss 0.0057225655764341354, batch loss prom: 0.0015376898227259517, batch loss ss: 0.004102624487131834, batch loss polya: 8.225102646974847e-05\n",
      "batch loss 0.003542984602972865, batch loss prom: 0.0028586022090166807, batch loss ss: 0.0003305127320345491, batch loss polya: 0.00035386974923312664\n",
      "batch loss 0.006722741760313511, batch loss prom: 0.0005317704635672271, batch loss ss: 0.006118614226579666, batch loss polya: 7.235741941258311e-05\n",
      "batch loss 0.0040352074429392815, batch loss prom: 0.0010152667528018355, batch loss ss: 0.0027898934204131365, batch loss polya: 0.0002300474588992074\n",
      "batch loss 0.007456005085259676, batch loss prom: 0.0026519864331930876, batch loss ss: 0.004677307326346636, batch loss polya: 0.0001267114421352744\n",
      "batch loss 0.003940158523619175, batch loss prom: 0.0019996424671262503, batch loss ss: 0.001731921685859561, batch loss polya: 0.00020859450160060078\n",
      "batch loss 0.006317280698567629, batch loss prom: 0.0015582811320200562, batch loss ss: 0.004720496013760567, batch loss polya: 3.85038583772257e-05\n",
      "batch loss 0.001725906040519476, batch loss prom: 0.0005034133209846914, batch loss ss: 0.00014137222024146467, batch loss polya: 0.0010811204556375742\n",
      "batch loss 0.006421531084924936, batch loss prom: 0.0010664734290912747, batch loss ss: 0.005288183689117432, batch loss polya: 6.687417771900073e-05\n",
      "batch loss 0.0007251776987686753, batch loss prom: 0.0002857038634829223, batch loss ss: 0.00016985881666187197, batch loss polya: 0.0002696150622796267\n",
      "batch loss 0.002686216961592436, batch loss prom: 0.0019487215904518962, batch loss ss: 0.0005576247931458056, batch loss polya: 0.00017987063620239496\n",
      "batch loss 0.020712871104478836, batch loss prom: 0.0018161722691729665, batch loss ss: 0.018686912953853607, batch loss polya: 0.0002097863471135497\n",
      "batch loss 0.0007384084747172892, batch loss prom: 0.0002933310461230576, batch loss ss: 0.0001995364436879754, batch loss polya: 0.0002455409849062562\n",
      "batch loss 0.0018990525277331471, batch loss prom: 0.0008418591460213065, batch loss ss: 0.0010492063593119383, batch loss polya: 7.986990567587782e-06\n",
      "batch loss 0.002494414569810033, batch loss prom: 0.0017755947774276137, batch loss ss: 0.00040737437666393816, batch loss polya: 0.00031144535751082003\n",
      "batch loss 0.05783448368310928, batch loss prom: 0.05517283454537392, batch loss ss: 0.0025064502842724323, batch loss polya: 0.0001551984460093081\n",
      "batch loss 0.0031701417174190283, batch loss prom: 0.00267576496116817, batch loss ss: 0.00045265440712682903, batch loss polya: 4.172238186583854e-05\n",
      "batch loss 0.0607960969209671, batch loss prom: 0.058666665107011795, batch loss ss: 0.0017101438716053963, batch loss polya: 0.00041929035796783864\n",
      "batch loss 0.00365345343016088, batch loss prom: 0.0023017835337668657, batch loss ss: 0.0004223884898237884, batch loss polya: 0.000929281348362565\n",
      "batch loss 0.04777494817972183, batch loss prom: 0.04467370733618736, batch loss ss: 0.0026805205270648003, batch loss polya: 0.0004207202873658389\n",
      "batch loss 0.005694455932825804, batch loss prom: 0.0010845737997442484, batch loss ss: 0.004428223706781864, batch loss polya: 0.00018165845540352166\n",
      "batch loss 0.006853152997791767, batch loss prom: 0.0021459662821143866, batch loss ss: 0.004527912009507418, batch loss polya: 0.00017927470616996288\n",
      "batch loss 0.0010503331432119012, batch loss prom: 0.0004120216181036085, batch loss ss: 0.0005864569102413952, batch loss polya: 5.185469490243122e-05\n",
      "batch loss 0.09405346214771271, batch loss prom: 0.09337149560451508, batch loss ss: 0.0005189026123844087, batch loss polya: 0.00016306500765495002\n",
      "batch loss 0.0008332604775205255, batch loss prom: 0.00040451448876410723, batch loss ss: 0.00015209948469419032, batch loss polya: 0.0002766464895103127\n",
      "batch loss 0.0007914330344647169, batch loss prom: 0.0003816353273577988, batch loss ss: 0.00016127715934999287, batch loss polya: 0.0002485204895492643\n",
      "-----\n",
      "prom acc: 90.0, prom loss: 0.21893683075904846\n",
      "ss acc: 80.0, ss loss: 0.7420704960823059\n",
      "polya acc: 100.0, polya loss: 0.00014145360910333693\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model, loss_fn, optimizer, scheduler, BATCH_SIZE, EPOCH_SIZE, 'cpu', eval=True, val_dataloader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, './result/24012022.pth')\n",
    "model.shared_layer.save_pretrained('./result/24012022/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prom': tensor([[ 1.6117, -2.9922]], grad_fn=<AddmmBackward0>), 'ss': tensor([[ 2.3533, -1.9821]], grad_fn=<AddmmBackward0>), 'polya': tensor([[-0.2783,  1.3930]], grad_fn=<AddmmBackward0>)}\n",
      "prom pred tensor([[ 1.6117, -2.9922]], grad_fn=<AddmmBackward0>); label tensor([0])\n",
      "ss pred tensor([[ 2.3533, -1.9821]], grad_fn=<AddmmBackward0>); label tensor([1])\n",
      "polya pred tensor([[-0.2783,  1.3930]], grad_fn=<AddmmBackward0>); label tensor([0])\n",
      "loss prom 0.009962832555174828, ss 4.348450660705566, polya 1.8435773849487305\n"
     ]
    }
   ],
   "source": [
    "s = \"GTACGATCGACTAGACACTATATATA\"\n",
    "prom = 0\n",
    "ss = 0\n",
    "polya = 0\n",
    "\n",
    "kmer = create_kmer(s, 3)\n",
    "tokenizer = BertTokenizer.from_pretrained('./pretrained/3-new-12w-0')\n",
    "output = tokenizer.encode_plus(text=kmer, padding='max_length', return_attention_mask=True)\n",
    "ids = []\n",
    "attns = []\n",
    "prom_labels = []\n",
    "ss_labels = []\n",
    "polya_labels = []\n",
    "ids.append(output['input_ids'])\n",
    "attns.append(output['attention_mask'])\n",
    "prom_labels.append(0)\n",
    "ss_labels.append(1)\n",
    "polya_labels.append(0)\n",
    "\n",
    "input_ids = torch.tensor(ids)\n",
    "attention_masks = torch.tensor(ids)\n",
    "prom_labels = torch.tensor(prom_labels)\n",
    "ss_labels = torch.tensor(ss_labels)\n",
    "polya_labels = torch.tensor(polya_labels)\n",
    "\n",
    "\n",
    "outputs = model(input_ids, attention_masks)\n",
    "prom = outputs['prom']\n",
    "ss = outputs['ss']\n",
    "polya = outputs['polya']\n",
    "print(outputs)\n",
    "print('prom pred {}; label {}'.format(prom, prom_labels))\n",
    "print('ss pred {}; label {}'.format(ss, ss_labels))\n",
    "print('polya pred {}; label {}'.format(polya, polya_labels))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_prom = loss_fn(prom, prom_labels)\n",
    "loss_ss = loss_fn(ss, ss_labels)\n",
    "loss_polya = loss_fn(polya, polya_labels)\n",
    "print('loss prom {}, ss {}, polya {}'.format(loss_prom, loss_ss, loss_polya))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2962,  0.0700,  0.0424,  ...,  0.3942,  0.8422,  0.2371],\n",
       "         [-0.2962,  0.0700,  0.0423,  ...,  0.3942,  0.8423,  0.2370],\n",
       "         [-0.2963,  0.0697,  0.0428,  ...,  0.3942,  0.8423,  0.2371],\n",
       "         ...,\n",
       "         [-0.2962,  0.0700,  0.0428,  ...,  0.3942,  0.8423,  0.2371],\n",
       "         [-0.2962,  0.0700,  0.0424,  ...,  0.3943,  0.8423,  0.2370],\n",
       "         [-0.2962,  0.0700,  0.0424,  ...,  0.3942,  0.8422,  0.2371]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = model.shared_layer\n",
    "Y = bert(input_ids=input_ids, attention_mask=attention_masks)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(Y[0][0]))\n",
    "print(len(Y[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained/3-new-12w-0 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "from dnabert import initialize_training_model, initialize_sequence_labelling_model\n",
    "\n",
    "pretrained_path = './pretrained/3-new-12w-0'\n",
    "mtl_model = initialize_training_model(pretrained_path)\n",
    "dnaseq_model = initialize_sequence_labelling_model(pretrained_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNASeqLabelling(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (stack): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnaseq_model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7170ee380771f2003055f3cee3e2e4dd0d81d1dac73a8c82197236b1572f37c2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('sequence-processing': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
