{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Data test: 100%|██████████| 6961/6961 [00:55<00:00, 125.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import os\n",
    "from utils.seqlab import preprocessing_kmer\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:0\"\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "test_file = os.path.join(\"workspace\", \"seqlab-latest\", \"test.csv\")\n",
    "batch_size = 8\n",
    "test_dataloader = preprocessing_kmer(test_file, tokenizer, batch_size)\n",
    "test_size = len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pretrained\\3-new-12w-0 were not used when initializing DNABERT_SL: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DNABERT_SL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DNABERT_SL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DNABERT_SL were not initialized from the model checkpoint at pretrained\\3-new-12w-0 and are newly initialized: ['head.classifier.bias', 'head.linear.hidden-block-0.linear.weight', 'head.linear.hidden-block-0.linear.bias', 'head.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# somehow I do PCA analysis.\n",
    "from models import seqlab, pretrained\n",
    "from transformers import BertForMaskedLM\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "m = seqlab.DNABERT_SL(\n",
    "    BertForMaskedLM.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\")).bert,\n",
    "    json.load(open(os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"), \"r\"))\n",
    ")\n",
    "n = pretrained.DNABERT_SL.from_pretrained(\n",
    "    os.path.join(\"pretrained\", \"3-new-12w-0\"),\n",
    "    json.load(open(os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"), \"r\"))\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    os.path.join(\"run\", \"sso01-adamw-lr5e-5-base.lin1-2w1boplw\", \"latest\", \"checkpoint.pth\"), \n",
    "    map_location=\"cuda:0\") # force to cuda:0 device\n",
    "m.load_state_dict(checkpoint.get(\"model\"))\n",
    "n.load_state_dict(checkpoint.get(\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.save_pretrained(os.path.join(\"pretrained\", \"dnabert-sl-lin1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train()\n",
    "n.train()\n",
    "str(m.state_dict()) == str(n.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 871/871 [1:28:01<00:00,  6.06s/it]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>bert_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>1.148287057876587 1.622141718864441 -1.0630100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2518802285194397 1.3096948862075806 0.932622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2287495732307434 1.3885688781738281 0.312197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.41064363718032837 1.1078848838806152 0.12063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8710600137710571 1.133277416229248 0.5390868...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id  target_id                                         bert_value\n",
       "0         2       -100  1.148287057876587 1.622141718864441 -1.0630100...\n",
       "1        29          7  0.2518802285194397 1.3096948862075806 0.932622...\n",
       "2        38          7  0.2287495732307434 1.3885688781738281 0.312197...\n",
       "3        10          7  0.41064363718032837 1.1078848838806152 0.12063...\n",
       "4        28          7  0.8710600137710571 1.133277416229248 0.5390868..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils.seqlab import id2label\n",
    "import pandas as pd\n",
    "\n",
    "m.eval()\n",
    "# n.eval()\n",
    "m.to(device)\n",
    "# n.to(device)\n",
    "token_ids, target_ids, bert_outputs = [], [], []\n",
    "for step, batch in tqdm(enumerate(test_dataloader), total=test_size, desc=\"Testing\"):\n",
    "    input_ids, attn_mask, token_type_ids, target_labels = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        out, out_bert, out_head = m(input_ids, attn_mask)\n",
    "        for b_input_ids, b_target, b_bert in zip(input_ids, target_labels, out_bert):\n",
    "            for i, j, k in zip(b_input_ids, b_target, b_bert):\n",
    "                token_ids.append(i.item())\n",
    "                target_ids.append(j.item())\n",
    "                bert_outputs.append(\" \".join([str(a) for a in k.tolist()]))\n",
    "\n",
    "df = pd.DataFrame(data={\n",
    "    \"token_id\": token_ids,\n",
    "    \"target_id\": target_ids,\n",
    "    \"bert_value\": bert_outputs\n",
    "})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"motif_analysis\", \"token_analysis\", \"token_bert_value.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_sequence_id                                       input_tokens  \\\n",
      "0                916  ACT CTT TTT TTT TTC TCC CCC CCT CTT TTT TTT TT...   \n",
      "1               1108  TGT GTT TTA TAG AGA GAA AAT ATT TTC TCA CAG AG...   \n",
      "2               1117  GTG TGT GTT TTA TAG AGA GAA AAT ATT TTC TCA CA...   \n",
      "3               1135  TGG GGT GTG TGT GTT TTA TAG AGA GAA AAT ATT TT...   \n",
      "4               1144  CTG TGG GGT GTG TGT GTT TTA TAG AGA GAA AAT AT...   \n",
      "\n",
      "                                      prediction_ids  \\\n",
      "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 7 ...   \n",
      "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
      "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
      "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
      "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
      "\n",
      "                                          target_ids  step  f1_score-iii  \\\n",
      "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 7 ...  2051             1   \n",
      "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  2286             1   \n",
      "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  2297             1   \n",
      "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  2319             1   \n",
      "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  2330             1   \n",
      "\n",
      "   precision-iii  recall-iii  f1_score-iiE  precision-iiE  ...  \\\n",
      "0              1           1             1              1  ...   \n",
      "1              1           1             1              1  ...   \n",
      "2              1           1             1              1  ...   \n",
      "3              1           1             1              1  ...   \n",
      "4              1           1             1              1  ...   \n",
      "\n",
      "                                   prediction_tokens  \\\n",
      "0  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "1  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "2  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "3  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "4  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "\n",
      "                                       target_tokens  \\\n",
      "0  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "1  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "2  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "3  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "4  iii iii iii iii iii iii iii iii iii iii iii ii...   \n",
      "\n",
      "                                          prediction  \\\n",
      "0  iiiiiiiiiiiiiiiiiiiiiiEEEEEEEEEEEEEEEEEEEEEEEE...   \n",
      "1  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiEEE...   \n",
      "2  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiEE...   \n",
      "3  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...   \n",
      "4  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...   \n",
      "\n",
      "                                              target  nucl_precision_intron  \\\n",
      "0  iiiiiiiiiiiiiiiiiiiiiiEEEEEEEEEEEEEEEEEEEEEEEE...                      1   \n",
      "1  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiEEE...                      1   \n",
      "2  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiEE...                      1   \n",
      "3  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...                      1   \n",
      "4  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...                      1   \n",
      "\n",
      "   nucl_precision_exon  nucl_recall_intron  nucl_recall_exon  nucl_f1_intron  \\\n",
      "0                    1                   1                 1               1   \n",
      "1                    1                   1                 1               1   \n",
      "2                    1                   1                 1               1   \n",
      "3                    1                   1                 1               1   \n",
      "4                    1                   1                 1               1   \n",
      "\n",
      "   nucl_f1_exon  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 45/45 [00:15<00:00,  2.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>bert_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGA</td>\n",
       "      <td>iiE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>0.08756396174430847 0.035568974912166595 0.370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAA</td>\n",
       "      <td>iEE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>0.3126485049724579 -1.088175892829895 -0.56700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGG</td>\n",
       "      <td>EEi</td>\n",
       "      <td>Eii</td>\n",
       "      <td>-0.1707116961479187 0.4697659909725189 1.07950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGT</td>\n",
       "      <td>Eii</td>\n",
       "      <td>iiE</td>\n",
       "      <td>-0.8013615608215332 0.10018081218004227 1.5437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGG</td>\n",
       "      <td>iiE</td>\n",
       "      <td>Eii</td>\n",
       "      <td>-0.11103878915309906 -0.24303054809570312 1.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token target prediction                                         bert_value\n",
       "0   AGA    iiE        iiE  0.08756396174430847 0.035568974912166595 0.370...\n",
       "1   GAA    iEE        iiE  0.3126485049724579 -1.088175892829895 -0.56700...\n",
       "2   AGG    EEi        Eii  -0.1707116961479187 0.4697659909725189 1.07950...\n",
       "3   GGT    Eii        iiE  -0.8013615608215332 0.10018081218004227 1.5437...\n",
       "4   AGG    iiE        Eii  -0.11103878915309906 -0.24303054809570312 1.02..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from utils.seqlab import _process_sequence_and_label, id2label, label2id\n",
    "from models import seqlab\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch import tensor, no_grad, argmax\n",
    "\n",
    "# get token prediction from categorized dataframes.\n",
    "import os\n",
    "import pandas as pd\n",
    "path = os.path.join(\"prediction\", \"dataframe-F1 Score=1.csv\")\n",
    "df = pd.read_csv(path)\n",
    "print(df.head(5))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "model = seqlab.DNABERT_SL(\n",
    "    BertForMaskedLM.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\")).bert,\n",
    "    json.load(open(os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"), \"r\"))\n",
    ")\n",
    "model.eval()\n",
    "device = \"cuda:0\"\n",
    "model.to(device)\n",
    "ss_labels = [\n",
    "    \"iiE\",\n",
    "    \"iEE\", \n",
    "    \"EEi\", \n",
    "    \"Eii\"\n",
    "]\n",
    "ss_label_ids = [label2id[a] for a in ss_labels]\n",
    "arr_tokens, arr_labels, arr_bert_values, arr_pred_tokens = [], [], [], []\n",
    "for i, r in tqdm(df.iterrows(), total=df.shape[0], desc=\"Testing\"):\n",
    "    with no_grad():\n",
    "        b_input_ids, b_attention_mask, b_token_type_ids, b_label_ids = _process_sequence_and_label(\n",
    "            r[\"input_tokens\"],\n",
    "            r[\"target_tokens\"],\n",
    "            tokenizer\n",
    "        )\n",
    "        b_input_ids = tensor([b_input_ids]).to(device)\n",
    "        b_attention_mask = tensor([b_attention_mask]).to(device)\n",
    "        b_label_ids = tensor([b_label_ids]).to(device)\n",
    "    b_out, b_out_bert, b_out_head = model(\n",
    "        b_input_ids, \n",
    "        b_attention_mask\n",
    "    )\n",
    "    b_pred_ids = argmax(b_out, 2)\n",
    "    # print(b_input_ids.shape, b_label_ids.shape, b_out_bert.shape)\n",
    "    for input_ids, label_ids, out_bert, pred_ids in zip(b_input_ids, b_label_ids, b_out_bert, b_pred_ids):\n",
    "        for i, j, k, p in zip(input_ids, label_ids, out_bert, pred_ids):\n",
    "            label_id = j.item()\n",
    "            pred_id = p.item()\n",
    "            if label_id >= 0:\n",
    "                if label_id in ss_label_ids:\n",
    "                    token_label = id2label[label_id]\n",
    "                    token = tokenizer.ids_to_tokens[i.item()]\n",
    "                    pred_token= id2label[p.item()]\n",
    "                    bert_values_str = [str(a) for a in k.tolist()]\n",
    "                    arr_tokens.append(token)\n",
    "                    arr_pred_tokens.append(pred_token)\n",
    "                    arr_labels.append(token_label)\n",
    "                    arr_bert_values.append(\" \".join(bert_values_str))\n",
    "\n",
    "ndf = pd.DataFrame(data={\n",
    "    \"token\": arr_tokens,\n",
    "    \"target\": arr_labels,\n",
    "    \"prediction\": arr_pred_tokens,\n",
    "    \"bert_value\": arr_bert_values\n",
    "})\n",
    "ndf.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>bert_value</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGA</td>\n",
       "      <td>iiE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>0.08756396174430847 0.035568974912166595 0.370...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AGA</td>\n",
       "      <td>iiE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>0.7666749358177185 -0.15378955006599426 1.4997...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>GAA</td>\n",
       "      <td>iEE</td>\n",
       "      <td>iEE</td>\n",
       "      <td>0.26655879616737366 -1.0910930633544922 -0.665...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token target prediction                                         bert_value  \\\n",
       "0    AGA    iiE        iiE  0.08756396174430847 0.035568974912166595 0.370...   \n",
       "80   AGA    iiE        iiE  0.7666749358177185 -0.15378955006599426 1.4997...   \n",
       "81   GAA    iEE        iEE  0.26655879616737366 -1.0910930633544922 -0.665...   \n",
       "\n",
       "    comparison  \n",
       "0            1  \n",
       "80           1  \n",
       "81           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compare_(row):\n",
    "    target = row[\"target\"]\n",
    "    prediction = row[\"prediction\"]\n",
    "    if target == prediction:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# true_pred_df = ndf[ndf[\"target\"] == ndf[\"prediction\"]]\n",
    "# print(true_pred_df.shape) 2, 4\n",
    "\n",
    "ndf[\"comparison\"] = ndf.apply(lambda x: _compare_(x), axis=1)\n",
    "ndf[ndf[\"comparison\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>bert_value</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAA</td>\n",
       "      <td>iEE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>0.3126485049724579 -1.088175892829895 -0.56700...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGG</td>\n",
       "      <td>EEi</td>\n",
       "      <td>Eii</td>\n",
       "      <td>-0.1707116961479187 0.4697659909725189 1.07950...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGT</td>\n",
       "      <td>Eii</td>\n",
       "      <td>iiE</td>\n",
       "      <td>-0.8013615608215332 0.10018081218004227 1.5437...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGG</td>\n",
       "      <td>iiE</td>\n",
       "      <td>Eii</td>\n",
       "      <td>-0.11103878915309906 -0.24303054809570312 1.02...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GGA</td>\n",
       "      <td>iEE</td>\n",
       "      <td>iiE</td>\n",
       "      <td>-0.06882086396217346 0.0999293401837349 1.1488...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>GGT</td>\n",
       "      <td>Eii</td>\n",
       "      <td>iiE</td>\n",
       "      <td>-0.12136223912239075 0.24540439248085022 1.074...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>AGG</td>\n",
       "      <td>iiE</td>\n",
       "      <td>Eii</td>\n",
       "      <td>0.19183388352394104 -0.3378389775753021 0.5174...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>GGA</td>\n",
       "      <td>iEE</td>\n",
       "      <td>EEE</td>\n",
       "      <td>0.17814867198467255 -0.09485137462615967 1.077...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>AGG</td>\n",
       "      <td>EEi</td>\n",
       "      <td>EEE</td>\n",
       "      <td>0.021793914958834648 0.720974862575531 0.61671...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GGT</td>\n",
       "      <td>Eii</td>\n",
       "      <td>iiE</td>\n",
       "      <td>-0.09474881738424301 0.2509042024612427 1.0941...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token target prediction  \\\n",
       "1     GAA    iEE        iiE   \n",
       "2     AGG    EEi        Eii   \n",
       "3     GGT    Eii        iiE   \n",
       "4     AGG    iiE        Eii   \n",
       "5     GGA    iEE        iiE   \n",
       "..    ...    ...        ...   \n",
       "175   GGT    Eii        iiE   \n",
       "176   AGG    iiE        Eii   \n",
       "177   GGA    iEE        EEE   \n",
       "178   AGG    EEi        EEE   \n",
       "179   GGT    Eii        iiE   \n",
       "\n",
       "                                            bert_value  comparison  \n",
       "1    0.3126485049724579 -1.088175892829895 -0.56700...           0  \n",
       "2    -0.1707116961479187 0.4697659909725189 1.07950...           0  \n",
       "3    -0.8013615608215332 0.10018081218004227 1.5437...           0  \n",
       "4    -0.11103878915309906 -0.24303054809570312 1.02...           0  \n",
       "5    -0.06882086396217346 0.0999293401837349 1.1488...           0  \n",
       "..                                                 ...         ...  \n",
       "175  -0.12136223912239075 0.24540439248085022 1.074...           0  \n",
       "176  0.19183388352394104 -0.3378389775753021 0.5174...           0  \n",
       "177  0.17814867198467255 -0.09485137462615967 1.077...           0  \n",
       "178  0.021793914958834648 0.720974862575531 0.61671...           0  \n",
       "179  -0.09474881738424301 0.2509042024612427 1.0941...           0  \n",
       "\n",
       "[177 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf[ndf[\"comparison\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.to_csv(\n",
    "    os.path.join(\"motif_analysis\", \"token_analysis\", \"df-F1=1.csv\"), \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>prediction</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACT</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTT</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTT</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTT</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTC</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token prediction target\n",
       "0   ACT        iii    iii\n",
       "1   CTT        iii    iii\n",
       "2   TTT        iii    iii\n",
       "3   TTT        iii    iii\n",
       "4   TTC        iii    iii"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# something weird.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.path.join(\"prediction\", \"dataframe-F1 Score=1.csv\")\n",
    "tokens, predictions, targets = [], [], []\n",
    "df = pd.read_csv(path)\n",
    "for step, r in df.iterrows():\n",
    "    input_tokens = r[\"input_tokens\"].split(\" \")\n",
    "    prediction_tokens = r[\"prediction_tokens\"].split(\" \")\n",
    "    target_tokens = r[\"target_tokens\"].split(\" \")\n",
    "\n",
    "    for i, j, k in zip(input_tokens, prediction_tokens, target_tokens):\n",
    "        tokens.append(i)\n",
    "        predictions.append(j)\n",
    "        targets.append(k)\n",
    "\n",
    "df = pd.DataFrame(data={\n",
    "    \"token\": tokens,\n",
    "    \"prediction\": predictions,\n",
    "    \"target\": targets\n",
    "})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 3)\n",
      "(22950, 3)\n",
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[df[\"prediction\"] == df[\"target\"]].shape)\n",
    "print(df[df[\"prediction\"] != df[\"target\"]].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequence-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14ae8cb2141f3f34f4e0523006ff2d6cb0f7956c0f094e5497e312072e4d0d3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
