{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenv\\deep-learning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# generate token for every ids.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from utils.seqlab import Index_Dictionary\n",
    "from utils.utils import merge_kmer\n",
    "\n",
    "path = os.path.join(\"prediction\", \"log\", \"prediction_log.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "df[\"input_tokens\"] = df.apply(lambda x: \" \".join(tokenizer.convert_ids_to_tokens([int(a) for a in x[\"input_ids\"].split(\" \")])), axis=1)\n",
    "df[\"prediction_tokens\"] = df.apply(lambda x: \" \".join([Index_Dictionary[a] for a in [int(b) for b in x[\"prediction_ids\"].split(\" \")]]), axis=1)\n",
    "df[\"target_tokens\"] = df.apply(lambda x: \" \".join([Index_Dictionary[a] for a in [int(b) for b in x[\"target_ids\"].split(\" \")]]), axis=1)\n",
    "df[\"sequence\"] = df.apply(lambda x: merge_kmer(x[\"input_tokens\"].split(\" \")), axis=1)\n",
    "df[\"prediction\"] = df.apply(lambda x: merge_kmer(x[\"prediction_tokens\"].split(\" \")), axis=1)\n",
    "df[\"target\"] = df.apply(lambda x: merge_kmer(x[\"target_tokens\"].split(\" \")), axis=1)\n",
    "df[\"avg_f1_score\"] = df.apply(lambda x: (x[\"f1_score-EEE\"] + x[\"f1_score-EEi\"] + x[\"f1_score-Eii\"] + x[\"f1_score-iEE\"] + x[\"f1_score-iiE\"] + x[\"f1_score-iii\"])/6, axis=1)\n",
    "df.to_csv(os.path.join(\"prediction\", \"log\", \"prediction_log_complete.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted = df.sort_values(by=[\"avg_f1_score\"], ascending=False)\n",
    "sorted[sorted[\"avg_f1_score\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 34)\n",
      "(320, 3)\n",
      "(320, 3)\n",
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"prediction\", \"log\", \"prediction_log_complete.csv\"))\n",
    "ss_labels = [\"iiE\", \"iEE\", \"EEi\", \"Eii\"]\n",
    "\n",
    "all_correct_df = df[df[\"avg_f1_score\"] == 1]\n",
    "print(all_correct_df.shape)\n",
    "tokens, predictions, targets = [], [], []\n",
    "for i, r in all_correct_df.iterrows():\n",
    "    arr_tokens = r[\"input_tokens\"].split(\" \")\n",
    "    arr_predictions = r[\"prediction_tokens\"].split(\" \")\n",
    "    arr_targets = r[\"target_tokens\"].split(\" \")\n",
    "\n",
    "    all_clear = all([a == b for a, b in zip(arr_predictions, arr_targets)])\n",
    "    if not all_clear:\n",
    "        raise ValueError(f\"{arr_predictions}\\n{arr_targets}\")\n",
    "\n",
    "    for i, j, k in zip(arr_tokens, arr_predictions, arr_targets):\n",
    "        if k in ss_labels:\n",
    "            tokens.append(i)\n",
    "            predictions.append(j)\n",
    "            targets.append(k)\n",
    "\n",
    "ndf = pd.DataFrame(data={\n",
    "    \"token\": tokens,\n",
    "    \"prediction\": predictions,\n",
    "    \"target\": targets\n",
    "})\n",
    "print(ndf.shape)\n",
    "correct_df = ndf[ndf[\"prediction\"] == ndf[\"target\"]]\n",
    "print(correct_df.shape)\n",
    "false_df = ndf[ndf[\"prediction\"] != ndf[\"target\"]]\n",
    "print(false_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb381ed8bacaf36aa3bfaca5a0502d4671ddf79cb6e63c342c2d7fda9a71fcc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
