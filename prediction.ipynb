{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import sys\n",
    "import os\n",
    "from getopt import getopt\n",
    "from models.seqlab import DNABERT_SL\n",
    "from utils.seqlab import NUM_LABELS, Index_Dictionary, preprocessing_kmer\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.metrics import Metrics\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model config at models\\config\\seqlab\\base.lin1.json\n",
      "found model checkpoint at run\\sso01-adamw-lr5e-5-base.lin1-2w1boplw\\latest\\checkpoint.pth\n",
      "found test data at workspace\\seqlab-latest\\gene_index.01_test_ss_all_pos.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Data gene_index 01_test_ss_all_pos: 100%|██████████| 6961/6961 [01:48<00:00, 63.88it/s]\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manwari32\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "c:\\.virtualenv\\sequence-processing\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>z:\\Workspace\\research\\sequence-processing\\wandb\\run-20221028_142710-2k4sio8u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anwari32/prediction/runs/2k4sio8u\" target=\"_blank\">playful-voice-3</a></strong> to <a href=\"https://wandb.ai/anwari32/prediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_metric.Metric at 0x1f3fc7ac108>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args = parse_args(sys.argv[1:])\n",
    "# for key in args.keys():\n",
    "#     print(f\"# {key} - {args[key]}\")\n",
    "\n",
    "# use static input first.\n",
    "args = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"model-config\": os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"),\n",
    "    \"model-checkpoint\": os.path.join(\"run\", \"sso01-adamw-lr5e-5-base.lin1-2w1boplw\", \"latest\", \"checkpoint.pth\"),\n",
    "    \"test-config\": os.path.join(\"training\", \"config\", \"seqlab\", \"ss-only.01.lr5e-5.json\"),\n",
    "    \"log\": os.path.join(\"prediction\", \"sso01-adamw-lr5e-5-base.lin1-2w1boplw\")\n",
    "}\n",
    "\n",
    "device = args.get(\"device\", \"cpu\") # specify device or use cpu otherwise.\n",
    "\n",
    "model_config_path = args.get(\"model-config\", False)\n",
    "model_checkpoint = args.get(\"model-checkpoint\", False)\n",
    "test_config_path = args.get(\"test-config\")\n",
    "test_config = json.load(open(test_config_path, \"r\"))\n",
    "test_file = test_config.get(\"test_data\", False)\n",
    "\n",
    "if not model_config_path:\n",
    "    raise ValueError(\"model config not specified.\")\n",
    "if not os.path.exists(model_config_path):\n",
    "    raise ValueError(f\"model config not exists at {model_config_path}\")\n",
    "print(f\"using model config at {model_config_path}\")\n",
    "    \n",
    "if not model_checkpoint:\n",
    "    raise ValueError(\"model checkpoint not specified.\")\n",
    "if not os.path.exists(model_checkpoint):\n",
    "    raise ValueError(f\"model checkpoint not exists at {model_checkpoint}\")\n",
    "print(f\"found model checkpoint at {model_checkpoint}\")\n",
    "\n",
    "if not test_file:\n",
    "    raise ValueError(\"test not specified.\")\n",
    "if not os.path.exists(test_file):\n",
    "    raise ValueError(f\"test file not exists at {test_file}\")\n",
    "print(f\"found test data at {test_file}\")\n",
    "\n",
    "bert_for_masked_lm = BertForMaskedLM.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "model = DNABERT_SL(\n",
    "    bert_for_masked_lm.bert, # bert, \n",
    "    json.load(open(model_config_path, \"r\")) # config\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "model.load_state_dict(checkpoint.get(\"model\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "batch_size = 1\n",
    "test_dataloader = preprocessing_kmer(test_file, tokenizer, batch_size)\n",
    "test_size = len(test_dataloader)\n",
    "\n",
    "logpath = args.get(\"log\", \"prediction\")\n",
    "if os.path.exists(logpath):\n",
    "    os.remove(logpath)\n",
    "os.makedirs(os.path.dirname(logpath), exist_ok=True)\n",
    "logfile = open(logpath, \"x\")\n",
    "logfile.write(\"step,input_ids,prediction,target\\n\")\n",
    "\n",
    "# initialize wandb.\n",
    "run = wandb.init(\n",
    "    project=\"prediction\",\n",
    "    entity=\"anwari32\"\n",
    ")\n",
    "wandb.define_metric(\"prediction_step\")\n",
    "wandb.define_metric(\"prediction/*\", step_metric=\"prediction_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 544/6961 [07:48<1:32:05,  1.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/2507420436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mpred_ids_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtarget_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prediction_step = 0\n",
    "device = \"cuda:0\"\n",
    "model.to(device)\n",
    "for step, batch in tqdm(enumerate(test_dataloader), total=test_size, desc=\"Testing\"):\n",
    "    input_ids, attn_mask, token_type_ids, target_labels = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        predictions, bert_output = model(input_ids, attn_mask)\n",
    "        for inputs, pred, target_label in zip(input_ids, predictions, target_labels):\n",
    "            vals, pred_ids = torch.max(pred, 1)\n",
    "            input_ids_list = inputs.tolist()\n",
    "            pred_ids_list = pred_ids.tolist()\n",
    "            target_list = target_label.tolist()\n",
    "            \n",
    "            # log to local first.\n",
    "            input_ids_str = [str(a) for a in input_ids_list]\n",
    "            input_ids_str = \" \".join(input_ids_str)\n",
    "            pred_ids_str = [str(a) for a in pred_ids_list]\n",
    "            pred_ids_str = \" \".join(pred_ids_str)\n",
    "            target_ids_str = [str(a) for a in target_list]\n",
    "            target_ids_str = \" \".join(target_ids_str)\n",
    "\n",
    "            logfile.write(f\"{prediction_step},{input_ids_str},{pred_ids_str},{target_ids_str}\\n\")\n",
    "\n",
    "            actual_input_ids = input_ids_list[1:] # remove CLS token\n",
    "            actual_input_ids = [t for t in actual_input_ids if t > 0]\n",
    "            actual_target_ids = target_list[1:] # remove CLS token\n",
    "            actual_target_ids = [a for a in actual_target_ids if a >= 0]\n",
    "            actual_pred_ids = pred_ids_list[1:] # remove CLS prediction\n",
    "            actual_pred_ids = actual_pred_ids[0:len(actual_target_ids)]\n",
    "\n",
    "            metrics = Metrics(actual_pred_ids, actual_target_ids)\n",
    "            for label_idx in range(NUM_LABELS):\n",
    "                wandb.log({\n",
    "                    f\"prediction/precision-{Index_Dictionary[label_idx]}\": metrics.precision(label_idx),\n",
    "                    f\"prediction/recall-{Index_Dictionary[label_idx]}\": metrics.recall(label_idx),\n",
    "                    f\"prediction/f1_score-{Index_Dictionary[label_idx]}\": metrics.f1_score(label_idx),\n",
    "                    \"prediction_step\": prediction_step\n",
    "                })\n",
    "\n",
    "            prediction_step += 1\n",
    "            \n",
    "logfile.close()\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('sequence-processing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14ae8cb2141f3f34f4e0523006ff2d6cb0f7956c0f094e5497e312072e4d0d3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
