{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import sys\n",
    "import os\n",
    "from getopt import getopt\n",
    "from models.seqlab import DNABERT_SL\n",
    "from utils.seqlab import NUM_LABELS, Index_Dictionary, preprocessing_kmer\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.metrics import Metrics\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model config at models\\config\\seqlab\\base.lin1.json\n",
      "found model checkpoint at run\\sso01-adamw-lr5e-5-base.lin1-2w1boplw\\latest\\checkpoint.pth\n",
      "found test data at workspace\\seqlab-latest\\gene_index.01_test_ss_all_pos.csv\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 45\u001b[0m\n\u001b[0;32m     39\u001b[0m bert_for_masked_lm \u001b[38;5;241m=\u001b[39m BertForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-new-12w-0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m DNABERT_SL(\n\u001b[0;32m     41\u001b[0m     bert_for_masked_lm\u001b[38;5;241m.\u001b[39mbert, \u001b[38;5;66;03m# bert, \u001b[39;00m\n\u001b[0;32m     42\u001b[0m     json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(model_config_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m# config\u001b[39;00m\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\torch\\serialization.py:705\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    706\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[0;32m    707\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\torch\\serialization.py:242\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "# args = parse_args(sys.argv[1:])\n",
    "# for key in args.keys():\n",
    "#     print(f\"# {key} - {args[key]}\")\n",
    "\n",
    "# use static input first.\n",
    "args = {\n",
    "    \"device\": \"gpu:0\",\n",
    "    \"model-config\": os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"),\n",
    "    \"model-checkpoint\": os.path.join(\"run\", \"sso01-adamw-lr5e-5-base.lin1-2w1boplw\", \"latest\", \"checkpoint.pth\"),\n",
    "    \"test-config\": os.path.join(\"training\", \"config\", \"seqlab\", \"ss-only.01.lr5e-5.json\")\n",
    "}\n",
    "\n",
    "device = args.get(\"device\", \"cpu\") # specify device or use cpu otherwise.\n",
    "\n",
    "model_config_path = args.get(\"model-config\", False)\n",
    "model_checkpoint = args.get(\"model-checkpoint\", False)\n",
    "test_config_path = args.get(\"test-config\")\n",
    "test_config = json.load(open(test_config_path, \"r\"))\n",
    "test_file = test_config.get(\"test_data\", False)\n",
    "\n",
    "if not model_config_path:\n",
    "    raise ValueError(\"model config not specified.\")\n",
    "if not os.path.exists(model_config_path):\n",
    "    raise ValueError(f\"model config not exists at {model_config_path}\")\n",
    "print(f\"using model config at {model_config_path}\")\n",
    "    \n",
    "if not model_checkpoint:\n",
    "    raise ValueError(\"model checkpoint not specified.\")\n",
    "if not os.path.exists(model_checkpoint):\n",
    "    raise ValueError(f\"model checkpoint not exists at {model_checkpoint}\")\n",
    "print(f\"found model checkpoint at {model_checkpoint}\")\n",
    "\n",
    "if not test_file:\n",
    "    raise ValueError(\"test not specified.\")\n",
    "if not os.path.exists(test_file):\n",
    "    raise ValueError(f\"test file not exists at {test_file}\")\n",
    "print(f\"found test data at {test_file}\")\n",
    "\n",
    "bert_for_masked_lm = BertForMaskedLM.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "model = DNABERT_SL(\n",
    "    bert_for_masked_lm.bert, # bert, \n",
    "    json.load(open(model_config_path, \"r\")) # config\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "model.load_state_dict(checkpoint.get(\"model\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "batch_size = 1\n",
    "test_dataloader = preprocessing_kmer(test_file, tokenizer, batch_size)\n",
    "test_size = len(test_dataloader)\n",
    "\n",
    "logpath = args[\"log\"]\n",
    "if os.path.exists(logpath):\n",
    "    os.remove(logpath)\n",
    "os.makedirs(os.path.dirname(logpath), exist_ok=True)\n",
    "logfile = open(logpath, \"x\")\n",
    "logfile.write(\"step,input_ids,prediction,target\\n\")\n",
    "\n",
    "# initialize wandb.\n",
    "wandb.init(\n",
    "    project=\"prediction\",\n",
    "    entity=\"anwari32\"\n",
    ")\n",
    "wandb.define_metric(\"prediction_step\")\n",
    "wandb.define_metric(\"prediction/*\", step_metric=\"prediction_step\")\n",
    "\n",
    "result = []\n",
    "prediction_step = 0\n",
    "for step, batch in tqdm(enumerate(test_dataloader), total=test_size, desc=\"Testing\"):\n",
    "    input_ids, attn_mask, token_type_ids, target_labels = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        predictions, bert_output = model(input_ids, attn_mask)\n",
    "        for inputs, pred, target_label in zip(input_ids, predictions, target_labels):\n",
    "            vals, pred_ids = torch.max(pred, 1)\n",
    "            \n",
    "            # log to local first.\n",
    "            input_ids_str = [str(a) for a in inputs]\n",
    "            input_ids_str = \" \".join(input_ids_str)\n",
    "            pred_ids_str = [str(a) for a in pred_ids]\n",
    "            pred_ids_str = \" \".join(pred_ids_str)\n",
    "            target_ids_str = [str(a) for a in target_label]\n",
    "            target_ids_str = \" \".join(target_ids_str)\n",
    "\n",
    "            logfile.write(f\"{prediction_step},{input_ids_str},{pred_ids_str},{target_ids_str}\\n\")\n",
    "\n",
    "            actual_input_ids = input_ids[1:] # remove CLS token\n",
    "            actual_input_ids = [t for t in actual_input_ids if t > 0]\n",
    "            actual_pred_ids = pred_ids[1:] # remove CLS prediction\n",
    "            actual_pred_ids = actual_pred_ids[0:len(actual_input_ids)]\n",
    "            target_ids = target_label[1:] # remove CLS token\n",
    "            target_ids = target_label[0:len(actual_input_ids)]\n",
    "\n",
    "            metrics = Metrics(actual_pred_ids, target_ids)\n",
    "            for label_idx in range(NUM_LABELS):\n",
    "                wandb.log({\n",
    "                    f\"prediction/precision-{Index_Dictionary[label_idx]}\": metrics.precision(label_idx),\n",
    "                    f\"prediction/recall-{Index_Dictionary[label_idx]}\": metrics.recall(label_idx),\n",
    "                    \"prediction_step\": prediction_step\n",
    "                })\n",
    "\n",
    "            prediction_step += 1\n",
    "            \n",
    "\n",
    "\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\\sso01-adamw-lr5e-5-base.lin1-2w1boplw\\latest\\checkpoint.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_checkpoint)\n\u001b[1;32m----> 3\u001b[0m saved_models \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\torch\\serialization.py:705\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    706\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[0;32m    707\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-310\\lib\\site-packages\\torch\\serialization.py:242\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(model_checkpoint)\n",
    "saved_models = torch.load(model_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sequence-processing-310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95adb5e5f98c5e0ba07577f17d74d9d3cc9cb557759904522f47cd47fc4449cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
