{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using models\\config\\seqlab\\base.lin1.json as location of model-config\n",
      "using run\\sso01-adamw-lr5e-5-base.lin1-2w1boplw\\latest\\checkpoint.pth as location of model-checkpoint\n",
      "using index\\gene_index.01_test.csv as location of test-data\n",
      "using data\\gene_dir as location of gene-dir\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from models.seqlab import DNABERT_SL\n",
    "import torch\n",
    "\n",
    "# use static input first.\n",
    "args = {\n",
    "    \"model-config\": os.path.join(\"models\", \"config\", \"seqlab\", \"base.lin1.json\"),\n",
    "    \"model-checkpoint\": os.path.join(\"run\", \"sso01-adamw-lr5e-5-base.lin1-2w1boplw\", \"latest\", \"checkpoint.pth\"),\n",
    "    \"test-data\": os.path.join(\"index\", \"gene_index.01_test.csv\"),\n",
    "    \"gene-dir\": os.path.join(\"data\", \"gene_dir\")\n",
    "}\n",
    "\n",
    "device = \"cuda:0\" # specify device or use cpu otherwise.\n",
    "\n",
    "model_config_path = args.get(\"model-config\", False)\n",
    "model_checkpoint = args.get(\"model-checkpoint\", False)\n",
    "test_file = args.get(\"test-data\", False)\n",
    "gene_dir = args.get(\"gene-dir\", False)\n",
    "\n",
    "for k in args.keys():\n",
    "    p = args.get(k, False)\n",
    "    if not p:\n",
    "        raise ValueError(f\"location of {k} not specified.\")    \n",
    "    elif not os.path.exists(p):\n",
    "        raise ValueError(f\"location of {k} not exists at {p}\")\n",
    "    else:\n",
    "        print(f\"using {p} as location of {k}\")\n",
    "\n",
    "bert_for_masked_lm = BertForMaskedLM.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))\n",
    "model = DNABERT_SL(\n",
    "    bert_for_masked_lm.bert, # bert, \n",
    "    json.load(open(model_config_path, \"r\")) # config\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "model.load_state_dict(checkpoint.get(\"model\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(\"pretrained\", \"3-new-12w-0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_gene_index = pd.read_csv(test_file)\n",
    "for i, r in test_gene_index.iterrows():\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deep-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb381ed8bacaf36aa3bfaca5a0502d4671ddf79cb6e63c342c2d7fda9a71fcc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
