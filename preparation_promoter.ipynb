{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate positive CSV from positive EPD fastas True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate negative csv from negative EPD fastas True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate negative csv from negative EPD Data True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate positive and negative dataset.\n",
    "Still not expanded.\n",
    "\"\"\"\n",
    "from utils.utils import generate_csvs_from_fastas\n",
    "from data_preparation import generate_negative_datasets\n",
    "from data_dir import epd_tata_fastas, epd_non_tata_fastas, epd_tata_csvs, epd_non_tata_csvs, epd_non_tata_generated_csvs\n",
    "\n",
    "print(\"Generate positive CSV from positive EPD fastas {}\".format(\n",
    "    generate_csvs_from_fastas(\n",
    "        epd_tata_fastas,\n",
    "        epd_tata_csvs,\n",
    "        [1 for f in epd_tata_fastas]\n",
    "    )))\n",
    "\n",
    "print(\"Generate negative csv from negative EPD fastas {}\".format(\n",
    "    generate_csvs_from_fastas(\n",
    "        epd_non_tata_fastas,\n",
    "        epd_non_tata_csvs,\n",
    "        [0 for f in epd_non_tata_fastas]\n",
    "    )))\n",
    "\n",
    "from data_preparation import generate_negative_datasets\n",
    "from data_dir import epd_tata_csvs, epd_non_tata_generated_csvs\n",
    "print(\"Generate negative csv from positive EPD Data {}\".format(\n",
    "    generate_negative_datasets(\n",
    "        epd_tata_csvs,\n",
    "        epd_non_tata_generated_csvs,\n",
    "        [0 for f in epd_tata_csvs]\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling workspace\\promoter\\human_tata_min120_plus383.csv\n",
      "Sampling workspace\\promoter\\human_tata_min256_plus255.csv\n",
      "Sampling workspace\\promoter\\human_tata_min384_plus127.csv\n",
      "Sampling workspace\\promoter\\human_tata_min499_plus100.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.83it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling workspace\\promoter\\human_non_tata_min120_plus383.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:01,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling workspace\\promoter\\human_non_tata_min256_plus255.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12824/3061985211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mn_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mz:\\Workspace\\research\\sequence-processing\\utils\\utils.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[1;34m(src_csvs, target_csvs, n_sample, seed, replace)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_src\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen_src\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_csvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_csvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\Workspace\\research\\sequence-processing\\utils\\utils.py\u001b[0m in \u001b[0;36mgenerate_sample\u001b[1;34m(src_csv, target_csv, n_sample, seed, replace)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m# fraction take over n_sample.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0msampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5363\u001b[0m             )\n\u001b[0;32m   5364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5365\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5366\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "from data_dir import epd_tata_csvs, epd_non_tata_csvs, epd_non_tata_generated_csvs\n",
    "from utils.utils import generate_samples\n",
    "import os\n",
    "\n",
    "srcs = [epd_tata_csvs, epd_non_tata_csvs, epd_non_tata_generated_csvs]\n",
    "for src in srcs:\n",
    "\n",
    "    samples = []\n",
    "    n_sample = 500\n",
    "    #for f in epd_tata_csvs:\n",
    "    for f in src:\n",
    "        fname = os.path.basename(f)\n",
    "        fname = fname.split('.')\n",
    "        fextension = fname[1]\n",
    "        fname = fname[0]\n",
    "        fname = \"{}.sample.{}.{}\".format(fname, n_sample, fextension)\n",
    "        dirname = os.path.dirname(f)\n",
    "        fname = os.path.join(dirname, fname)\n",
    "        samples.append(fname)\n",
    "\n",
    "    generate_samples(src, samples,  n_sample=n_sample, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of workspace\\promoter\\human_tata_min120_plus383.csv is 3065\n",
      "Size of workspace\\promoter\\human_tata_min256_plus255.csv is 813\n",
      "Size of workspace\\promoter\\human_tata_min384_plus127.csv is 3065\n",
      "Size of workspace\\promoter\\human_tata_min499_plus100.csv is 3065\n",
      "Size of workspace\\promoter\\human_non_tata_min120_plus383.csv is 26533\n",
      "Size of workspace\\promoter\\human_non_tata_min256_plus255.csv is 141\n",
      "Size of workspace\\promoter\\human_non_tata_min384_plus127.csv is 1065\n",
      "Size of workspace\\promoter\\human_non_tata_min499_plus100.csv is 1386\n",
      "Size of workspace\\promoter\\human_non_tata_generated_min120_plus383.csv is 3065\n",
      "Size of workspace\\promoter\\human_non_tata_generated_min256_plus255.csv is 813\n",
      "Size of workspace\\promoter\\human_non_tata_generated_min384_plus127.csv is 3065\n",
      "Size of workspace\\promoter\\human_non_tata_generated_min499_plus100.csv is 3065\n"
     ]
    }
   ],
   "source": [
    "from data_dir import epd_tata_csvs, epd_non_tata_csvs, epd_non_tata_generated_csvs\n",
    "from utils.utils import generate_samples\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "srcs = [epd_tata_csvs, epd_non_tata_csvs, epd_non_tata_generated_csvs]\n",
    "for src in srcs:\n",
    "    for s in src:\n",
    "        df = pd.read_csv(s)\n",
    "        print(f\"Size of {s} is {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate samples for negatives.\n",
    "\"\"\"\n",
    "from data_preparation import generate_sample\n",
    "from data_dir import epd_neg_tata_csv, epd_non_tata_csv, epd_pos_tata_csv, epd_pos_tata_csv\n",
    "import os\n",
    "\n",
    "negative_generated = os.path.join(\"data\", \"epd\", \"negative_tata_generated_sample.csv\")\n",
    "negative_epd = os.path.join(\"data\", \"epd\", \"negative_tata_epd_sample.csv\")\n",
    "positive_epd = os.path.join(\"data\", \"epd\", \"positive_tata_epd_sample.csv\")\n",
    "n_sample = 750\n",
    "\n",
    "\n",
    "print(f\"Generate {n_sample} sample of {epd_neg_tata_csv}: {generate_sample(epd_neg_tata_csv, negative_generated, n_sample=n_sample)}\")\n",
    "print(f\"Generate {n_sample} sample of {epd_non_tata_csv}: {generate_sample(epd_non_tata_csv, negative_epd, n_sample=n_sample)}\")\n",
    "\"\"\"\n",
    "Generate sample for positives.\n",
    "\"\"\"\n",
    "print(f\"Generate {n_sample * 2} sample of {epd_pos_tata_csv}: {generate_sample(epd_pos_tata_csv, positive)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate kmer version for both positive and negative promoter data.\n",
    "\"\"\"\n",
    "from data_preparation import generate_kmer_csv\n",
    "from data_dir import epd_pos_tata_csv, epd_neg_tata_csv, epd_pos_tata_kmer_csv, epd_neg_tata_kmer_csv\n",
    "\n",
    "print(\"Generate kmer csv from positive data {}\".format(generate_kmer_csv(epd_pos_tata_csv, epd_pos_tata_kmer_csv)))\n",
    "print(\"Generate kmer csv from negative data {}\".format(generate_kmer_csv(epd_neg_tata_csv, epd_neg_tata_kmer_csv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and storing split to ./data/epd/train.positive.csv\n",
      "Splitting and storing split to ./data/epd/validation.positive.csv\n",
      "Splitting and storing split to ./data/epd/train.negative.csv\n",
      "Splitting and storing split to ./data/epd/validation.negative.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate train and validation for positive and negative\n",
    "\"\"\"\n",
    "from data_preparation import split_and_store_csv\n",
    "from data_dir import epd_pos_tata_kmer_csv, epd_neg_tata_kmer_csv, epd_pos_tata_kmer_dir, epd_neg_tata_kmer_dir, data_epd_dir\n",
    "\n",
    "fractions = [0.9, 0.1]\n",
    "split_and_store_csv(epd_pos_tata_kmer_csv, fractions, ['{}/train.positive.csv'.format(data_epd_dir), '{}/validation.positive.csv'.format(data_epd_dir)])\n",
    "split_and_store_csv(epd_neg_tata_kmer_csv, fractions, ['{}/train.negative.csv'.format(data_epd_dir), '{}/validation.negative.csv'.format(data_epd_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merging positive and negative for each of its training and validation file.\n",
    "\"\"\"\n",
    "from data_dir import data_epd_dir\n",
    "from data_preparation import merge_csv\n",
    "for _type in ['train', 'validation']:\n",
    "    pos = '{}/{}.positive.csv'.format(data_epd_dir, _type)\n",
    "    neg = '{}/{}.negative.csv'.format(data_epd_dir, _type)\n",
    "    target = '{}/{}.csv'.format(data_epd_dir, _type)\n",
    "    merge_csv([pos, neg], target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7170ee380771f2003055f3cee3e2e4dd0d81d1dac73a8c82197236b1572f37c2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('sequence-processing': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
