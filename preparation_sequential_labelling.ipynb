{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating index: 100%|██████████| 24/24 [06:53<00:00, 17.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate gene index.\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_gene_index(gene_dir, index_dir):\n",
    "    chr_dirs = [f\"chr{i+1}\" for i in range(0, 24)]\n",
    "    chrs_path = [os.path.join(gene_dir, a) for a in chr_dirs]\n",
    "    \n",
    "    index_path = os.path.join(index_dir, \"gene_index.csv\")\n",
    "    os.makedirs(os.path.dirname(index_path), exist_ok=True)\n",
    "    if os.path.exists(index_path):\n",
    "        os.remove(index_path)\n",
    "    index = open(index_path, \"x\")\n",
    "    index.write(\"chr,gene,size\\n\")\n",
    "    for chr_dir in tqdm(chrs_path, total=len(chrs_path), desc=\"Creating index\"):\n",
    "        file_names = [a for a in os.listdir(chr_dir) if os.path.isfile(os.path.join(chr_dir, a))]\n",
    "        for fname in file_names:\n",
    "            # Count gene length.\n",
    "            fpath = os.path.join(chr_dir, fname)\n",
    "            df = pd.read_csv(fpath)\n",
    "            len_sequence = 0\n",
    "            for i, r in df.iterrows():                \n",
    "                len_sequence += len(r[\"sequence\"])\n",
    "\n",
    "            index.write(f\"{os.path.basename(chr_dir)},{fname},{len_sequence}\\n\")\n",
    "    index.close()\n",
    "\n",
    "gene_dir = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\")\n",
    "index_dir = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\")\n",
    "generate_gene_index(gene_dir, index_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge genes.\n",
    "\"\"\"\n",
    "import os\n",
    "from data_preparation import merge_csv\n",
    "for c in range(4, 24):\n",
    "    chr = f\"chr{c+1}\"\n",
    "    src_dir = os.path.join(\"workspace\", \"seq2seq-stride.384\", chr)\n",
    "    dest_file = os.path.join(\"workspace\", \"seq2seq-stride.384\", chr, \"bundle.csv\")\n",
    "    src_files = [os.path.join(src_dir, fname) for fname in os.listdir(src_dir)] \n",
    "    status = merge_csv(src_files, dest_file)\n",
    "    if not status:\n",
    "        print(f\"Something wrong with merging files in directory {src_dir}.\")\n",
    "        raise Exception(\"something wrong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make sample from bundle.csv.\n",
    "\"\"\"\n",
    "from utils.utils import create_n_sample\n",
    "import os\n",
    "\n",
    "n_sample = 100\n",
    "for c in range(24):\n",
    "    bundle_csv = os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.csv\")\n",
    "    bundle_sample_csv = os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.sample.csv\")\n",
    "    create_n_sample(bundle_csv, n_sample, bundle_sample_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make train, validation, and test bundle for each chr.\n",
    "\"\"\"\n",
    "from utils.utils import split_and_store_csv\n",
    "import os\n",
    "\n",
    "fractions = [0.7, 0.2, 0.1]\n",
    "file_types = [\"train\", \"validation\", \"test\"]\n",
    "dest_dir = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\") for c in range(24)]\n",
    "src_files = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.csv\") for c in range(24)]\n",
    "dest_train_files = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.train.csv\") for c in range(24)]\n",
    "dest_valid_files = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.validation.csv\") for c in range(24)]\n",
    "dest_test_files = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.test.csv\") for c in range(24)]\n",
    "\n",
    "for src, dest_train, dest_valid, dest_test in zip(src_files, dest_train_files, dest_valid_files, dest_test_files):\n",
    "    split_and_store_csv(src, fractions, [\n",
    "        dest_train, dest_valid, dest_test\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge bundle.sample.csv from every chr.\n",
    "\"\"\"\n",
    "from data_preparation import merge_csv\n",
    "import os\n",
    "chr_bundle_sample_csvs = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.sample.csv\") for c in range(24)]\n",
    "merged_bundle_sample = os.path.join(\"workspace\", \"seq2seq-stride.384\", \"bundle.sample.csv\")\n",
    "merge_csv(chr_bundle_sample_csvs, merged_bundle_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge bundle from every chr.\n",
    "\"\"\"\n",
    "from data_preparation import merge_csv\n",
    "import os\n",
    "chr_bundle_csvs = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", \"bundle.csv\") for c in range(24)]\n",
    "merged_bundle = os.path.join(\"workspace\", \"seq2seq-stride.384\", \"bundle.csv\")\n",
    "merge_csv(chr_bundle_csvs, merged_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge bundle train, validation, and test from every chr.\n",
    "\"\"\"\n",
    "from data_preparation import merge_csv\n",
    "import os\n",
    "\n",
    "for t in [\"train\", \"validation\", \"test\"]:\n",
    "    chr_bundle_csvs = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", f\"bundle.{t}.csv\") for c in range(24)]\n",
    "    merged_bundle = os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"bundle.{t}.csv\")\n",
    "    merge_csv(chr_bundle_csvs, merged_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge bundle training, validation, and test from every chr.\n",
    "\"\"\"\n",
    "from data_preparation import merge_csv\n",
    "import os\n",
    "for t in [\"train\", \"validation\", \"test\"]:\n",
    "    chr_bundle_csvs = [os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"chr{c+1}\", f\"bundle.{t}.csv\") for c in range(24)]\n",
    "    merged_bundle = os.path.join(\"workspace\", \"seq2seq-stride.384\", f\"bundle.{t}.csv\")\n",
    "    merge_csv(chr_bundle_csvs, merged_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import kmer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "_cols = ['sequence', 'label']\n",
    "_stride = 256\n",
    "_length = 512\n",
    "for c in ['chr{}'.format(i+1) for i in range(24)]:\n",
    "    genes_dir_by_chr = os.path.join('data', 'genome', 'sequential-labelling-positive-strand', c)\n",
    "    genes_expansion_dir_by_chr = os.path.join('workspace', f\"sequential-labelling-stride.{_stride}\", c)\n",
    "    if not os.path.exists(genes_expansion_dir_by_chr):\n",
    "        os.makedirs(genes_expansion_dir_by_chr, exist_ok=True)\n",
    "    for gene_file in os.listdir(genes_dir_by_chr):\n",
    "        gene_file_path = os.path.join(genes_dir_by_chr, gene_file)\n",
    "        gene_expansion_file_path = os.path.join(genes_expansion_dir_by_chr, f\"{gene_file.split('.')[0]}.expanded.csv\")\n",
    "        if os.path.exists(gene_expansion_file_path):\n",
    "            os.remove(gene_expansion_file_path)\n",
    "        target_file = open(gene_expansion_file_path, 'x')\n",
    "        target_file.write(f\"sequence,label\\n\")\n",
    "        df = pd.read_csv(gene_file_path)\n",
    "        print(f\"Working on {c} {gene_file_path}                                 \", end='\\r')\n",
    "        for _, row in df.iterrows():\n",
    "            seq_chunks = kmer(row['sequence'].strip(), _length, _stride)\n",
    "            label_chunks = kmer(row['label'].strip(), _length, _stride)\n",
    "            for seq, label in zip(seq_chunks, label_chunks):\n",
    "                target_file.write(f\"{seq},{label}\\n\")\n",
    "        target_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter index based on gene name.\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "_chr_indices = [\n",
    "    'NC_000001.11.csv',\n",
    "    'NC_000002.12.csv',\n",
    "    'NC_000003.12.csv',\n",
    "    'NC_000004.12.csv',\n",
    "    'NC_000005.10.csv',\n",
    "    'NC_000006.12.csv',\n",
    "    'NC_000007.14.csv',\n",
    "    'NC_000008.11.csv',\n",
    "    'NC_000009.12.csv',\n",
    "    'NC_000010.11.csv',\n",
    "    'NC_000011.10.csv',\n",
    "    'NC_000012.12.csv',\n",
    "    'NC_000013.11.csv',\n",
    "    'NC_000014.9.csv',\n",
    "    'NC_000015.10.csv',\n",
    "    'NC_000016.10.csv',\n",
    "    'NC_000017.11.csv',\n",
    "    'NC_000018.10.csv',\n",
    "    'NC_000019.10.csv',\n",
    "    'NC_000020.11.csv',\n",
    "    'NC_000021.9.csv',\n",
    "    'NC_000022.11.csv',\n",
    "    'NC_000023.11.csv',\n",
    "    'NC_000024.10.csv']\n",
    "_chr_dir = [\"chr{}\".format(i+1) for i in range(len(_chr_indices))]\n",
    "\n",
    "for chr, chr_number in zip(_chr_indices, _chr_dir):\n",
    "    path = os.path.join('data', 'genome', 'grch38', 'csvs_strand', chr)\n",
    "    df = pd.read_csv(path)\n",
    "    genes = list(df['gene'].unique())\n",
    "    genes = [a for a in genes if not pd.isnull(a)]\n",
    "    for g in genes:\n",
    "        ndf = df[df['gene'] == g]\n",
    "        path = os.path.join('data', 'genome', 'grch38', 'genes', chr_number,\"{}.csv\".format(g))\n",
    "        if not os.path.exists(os.path.dirname(path)):\n",
    "            os.mkdir(os.path.dirname(path))\n",
    "        ndf.to_csv(path, index=False)\n",
    "        print(\"Success: {}                                                      \".format(path), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on chr chr24 gene ZNF92P1Y.csv                                                     \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate sequence from fasta based on gene indices.\n",
    "\"\"\"\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from data_dir import chr_fasta_mapname\n",
    "\n",
    "strand = '+'\n",
    "chrs = ['chr{}'.format(i+1) for i in range(24)] # Folder name.\n",
    "# chrs = ['chr{}'.format(i+1) for i in range(2)] # Folder name.\n",
    "\n",
    "for c in chrs:\n",
    "    chr_genes_indices_dir = os.path.join(\"data\", \"genome\", \"grch38\", \"genes\", c)\n",
    "    chr_genes_sequence_csv_dir = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\",c)\n",
    "    chr_fasta = os.path.join(\"data\", \"chr\", chr_fasta_mapname[c])\n",
    "\n",
    "    if not os.path.exists(chr_fasta):\n",
    "        raise FileNotFoundError(\"Fasta {} not found.\".format(chr_fasta))\n",
    "\n",
    "    \"\"\"\n",
    "    Read whole chromosome here and return its complete sequence.\n",
    "    Yes, it's long.\n",
    "    \"\"\"\n",
    "    records = SeqIO.parse(chr_fasta, \"fasta\")\n",
    "    chr_records = next(records)\n",
    "    chr_sequence = str(chr_records.seq)\n",
    "    genome_sequence = chr_sequence # Use genome sequence reader here.\n",
    "\n",
    "    _columns = ['sequence', 'label']\n",
    "    for fname in os.listdir(chr_genes_indices_dir):\n",
    "        print(\"Working on chr {} gene {}                                    \".format(c, fname), end='\\r')\n",
    "        fpath = os.path.join(chr_genes_indices_dir, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            \"\"\"\n",
    "            Gene index found. Read the index and cross-reference with genome sequence.\n",
    "            \"\"\"\n",
    "            index_df = pd.read_csv(fpath)\n",
    "            gene_region = index_df[index_df['region'] == \"gene\"]\n",
    "            if strand != None:\n",
    "                gene_region = gene_region[gene_region['strand'] == strand]\n",
    "\n",
    "            if len(gene_region) > 0:\n",
    "                gene_df = pd.DataFrame(columns=_columns)\n",
    "                for i, g in gene_region.iterrows():\n",
    "                    gene_start_index = int(g['start_index'])\n",
    "                    gene_end_index = int(g['end_index'])\n",
    "                    gene_sequence = genome_sequence[gene_start_index:gene_end_index + 1]\n",
    "                    # print(\"Gene sequence: {}\".format(gene_sequence))\n",
    "                    # If gene sequence isn't None then this gene is available in chromosome sequence.\n",
    "                    if gene_sequence != None:\n",
    "                        gene_sequential_labelling = ['i' for a in gene_sequence]\n",
    "                        exons = index_df[index_df['region'] == \"exon\"]\n",
    "                        #if strand != None:\n",
    "                        #    exons = index_df[index_df['strand'] == strand]\n",
    "                        for j, r in exons.iterrows():\n",
    "                            start_index = int(r['start_index'])\n",
    "                            end_index = int(r['end_index'])\n",
    "                            if (start_index >= gene_start_index and end_index <= gene_end_index):\n",
    "                                start_index = int(r['start_index']) - gene_start_index\n",
    "                                end_index = int(r['end_index']) - gene_start_index\n",
    "                                for k in range(start_index, end_index + 1):\n",
    "                                    gene_sequential_labelling[k] = 'E'\n",
    "                        gene_sequential_labelling = ''.join(gene_sequential_labelling)\n",
    "                        #endfor\n",
    "                        gene_df = pd.concat([gene_df, pd.DataFrame([[gene_sequence, gene_sequential_labelling]], columns=_columns)])\n",
    "\n",
    "                target_path = os.path.join(chr_genes_sequence_csv_dir, fname)\n",
    "                # data\\genome\\sequential-labelling\\chr1\n",
    "                # Only write if dataframe is not empty.\n",
    "                if gene_df.shape[0] > 0:\n",
    "                    if not os.path.exists(chr_genes_sequence_csv_dir):\n",
    "                        os.makedirs(chr_genes_sequence_csv_dir, exist_ok=True)\n",
    "                    if gene_df.shape[0] > 0:    \n",
    "                        gene_df.to_csv(target_path, index=False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chr24 ZFY.csv                                       \r"
     ]
    }
   ],
   "source": [
    "\"\"\"Chunk each gene into 512 characters, for each chromosome.\"\"\"\n",
    "import pandas as pd\n",
    "from data_preparation import kmer\n",
    "import os\n",
    "\n",
    "chrs = [f\"chr{i + 1}\" for i in range(24)] # Test one chromosome.\n",
    "chr_paths = [os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"{chr}\") for chr in chrs]\n",
    "dest_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.stride-512\", f\"{chr}\") for chr in chrs]\n",
    "for cp, dp in zip(chr_paths, dest_paths):\n",
    "    genes = os.listdir(cp)\n",
    "    genes = [g for g in genes if \"expanded\" not in g.split('.')]\n",
    "    for gene in genes:\n",
    "        gene_path = os.path.join(cp, gene)\n",
    "        gene_df = pd.read_csv(gene_path)\n",
    "        print(f\"Processing {os.path.basename(cp)} {gene}                    \", end=\"\\r\")\n",
    "        for i, r in gene_df.iterrows():\n",
    "            sequence = r[\"sequence\"]\n",
    "            label = r[\"label\"]\n",
    "            seq_chunks = kmer(sequence, 512, 512)\n",
    "            label_chunks = kmer(label, 512, 512)\n",
    "            dest_path = os.path.join(dp, f\"{gene.split('.')[0]}.csv\")\n",
    "            if os.path.exists(dest_path):\n",
    "                os.remove(dest_path)\n",
    "            if not os.path.exists(os.path.dirname(dest_path)):\n",
    "                os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            dest = open(dest_path, \"x\")\n",
    "            dest.write(\"sequence,label\\n\")\n",
    "            for c, l in zip(seq_chunks, label_chunks):\n",
    "                dest.write(f\"{c},{l}\\n\")\n",
    "            dest.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Move file around\"\"\"\n",
    "\n",
    "import os\n",
    "for i in range(24):\n",
    "    k = i + 1\n",
    "    src_path = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"chr{k}\")\n",
    "    dest_path = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"chr{k}.expanded\")\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "    files = os.listdir(src_path)\n",
    "    files = [f for f in files if \"expanded\" in f.split('.')]\n",
    "    for f in files:\n",
    "        oldpath = os.path.join(src_path, f)\n",
    "        newpath = os.path.join(dest_path, f)\n",
    "        if not os.path.exists(newpath):\n",
    "            os.rename(oldpath, newpath)\n",
    "        else:\n",
    "            print(f\"Skip {oldpath}                                                    \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rename files in expanded folder\n",
    "filename.expanded.csv => filename.csv\n",
    "\"\"\"\n",
    "src_paths = [os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"chr{i + 1}.expanded\") for i in range(24)]\n",
    "for srcdir in src_paths:\n",
    "    files = os.listdir(srcdir)\n",
    "    for f in files:\n",
    "        oldpath = os.path.join(srcdir, f)\n",
    "        newpath = os.path.join(srcdir, f\"{f.split('.')[0]}.csv\")\n",
    "        os.rename(oldpath, newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate kmer version from sequence.\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_preparation import str_kmer\n",
    "\n",
    "# src_paths = [os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"chr{i + 1}\") for i in range(24)]\n",
    "src_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.stride-512\", f\"chr{i + 1}\") for i in range(24)]\n",
    "# dest_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.kmer\", f\"chr{i + 1}\") for i in range(24)]\n",
    "dest_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.kmer.stride-512\", f\"chr{i + 1}\") for i in range(24)]\n",
    "for srcdir, destdir in zip(src_paths, dest_paths):\n",
    "    files = os.listdir(srcdir)\n",
    "    for f in files:\n",
    "        src = os.path.join(srcdir, f)\n",
    "        dest = os.path.join(destdir, f)\n",
    "        if not os.path.exists(destdir):\n",
    "            os.makedirs(destdir, exist_ok=True)\n",
    "        if os.path.exists(dest):\n",
    "            os.remove(dest)\n",
    "        dest = open(dest, \"x\")\n",
    "        dest.write(\"sequence,label\\n\")\n",
    "        df = pd.read_csv(src)\n",
    "        for i, r in df.iterrows():\n",
    "            sequence = r[\"sequence\"]\n",
    "            label = r[\"label\"]\n",
    "            dest.write(f\"{str_kmer(sequence, 3)},{str_kmer(label, 3)}\\n\")\n",
    "        dest.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chr24 ZFY.csv                                       \r"
     ]
    }
   ],
   "source": [
    "\"\"\"Chunk each gene into 510 token. Since sequence is already in token form, ``kmer`` function cannot be used, had to create another script.\"\"\"\n",
    "import pandas as pd\n",
    "from data_preparation import kmer\n",
    "import os\n",
    "\n",
    "def chunk_kmer_sequence(chunk: str, size: int, stride: int) -> str:\n",
    "    arr = chunk.split(' ')\n",
    "    arr = kmer(arr, size, window_size=stride)\n",
    "    return arr\n",
    "\n",
    "chrs = [f\"chr{i + 1}\" for i in range(24)] # Test one chromosome.\n",
    "chr_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.kmer\", f\"{chr}\") for chr in chrs]\n",
    "dest_paths = [os.path.join(\"data\", \"genome\", \"seqlab.strand-positive.kmer.stride-205\", f\"{chr}\") for chr in chrs]\n",
    "for cp, dp in zip(chr_paths, dest_paths):\n",
    "    genes = os.listdir(cp)\n",
    "    genes = [g for g in genes if \"expanded\" not in g.split('.')]\n",
    "    for gene in genes:\n",
    "        gene_path = os.path.join(cp, gene)\n",
    "        gene_df = pd.read_csv(gene_path)\n",
    "        print(f\"Processing {os.path.basename(cp)} {gene}                    \", end=\"\\r\")\n",
    "        for i, r in gene_df.iterrows():\n",
    "            sequence = r[\"sequence\"]\n",
    "            label = r[\"label\"]\n",
    "            seq_chunks = chunk_kmer_sequence(sequence, 510, 205)\n",
    "            label_chunks = chunk_kmer_sequence(label, 510, 205)    \n",
    "            dest_path = os.path.join(dp, f\"{gene.split('.')[0]}.csv\")\n",
    "            if os.path.exists(dest_path):\n",
    "                os.remove(dest_path)\n",
    "            if not os.path.exists(os.path.dirname(dest_path)):\n",
    "                os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            dest = open(dest_path, \"x\")\n",
    "            dest.write(\"sequence,label\\n\")\n",
    "            for c, l in zip(seq_chunks, label_chunks):\n",
    "                dest.write(f\"{' '.join(c)},{' '.join(l)}\\n\")\n",
    "            dest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split gene_index for training, validation, and testing.\n",
    "\"\"\"\n",
    "import os\n",
    "index_dir = os.path.join(\"index\")\n",
    "gene_index = os.path.join(index_dir, f\"gene_index.csv\")\n",
    "train_index = os.path.join(index_dir, \"gene_train_index.csv\")\n",
    "val_index = os.path.join(index_dir, \"gene_validation_index.csv\")\n",
    "test_index = os.path.join(index_dir, \"gene_test_index.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(gene_index)\n",
    "train_df = df.sample(frac=0.8)\n",
    "test_df = df.drop(train_df.index)\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df = test_df.drop(val_df.index)\n",
    "train_df.to_csv(train_index, index=False)\n",
    "val_df.to_csv(val_index, index=False)\n",
    "test_df.to_csv(test_index, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene sequential labelling.\n",
    "# Create 10% and 25% sample of gene indices.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "index_dir = os.path.join(\"index\")\n",
    "gene_train_index = os.path.join(index_dir, \"gene_train_index.csv\")\n",
    "gene_validation_index = os.path.join(index_dir, \"gene_validation_index.csv\")\n",
    "gene_test_index = os.path.join(index_dir, \"gene_test_index.csv\")\n",
    "\n",
    "gene_train_index_10 = os.path.join(index_dir, \"gene_train_index.10.csv\")\n",
    "gene_validation_index_10 = os.path.join(index_dir, \"gene_validation_index.10.csv\")\n",
    "gene_test_index_10 = os.path.join(index_dir, \"gene_test_index.10.csv\")\n",
    "\n",
    "gene_train_index_25 = os.path.join(index_dir, \"gene_train_index.25.csv\")\n",
    "gene_validation_index_25 = os.path.join(index_dir, \"gene_validation_index.25.csv\")\n",
    "gene_test_index_25 = os.path.join(index_dir, \"gene_test_index.25.csv\")\n",
    "\n",
    "srcs = [gene_train_index, gene_validation_index, gene_test_index]\n",
    "tens = [gene_train_index_10, gene_validation_index_10, gene_test_index_10]\n",
    "quarter = [gene_train_index_25, gene_validation_index_25, gene_test_index_25]\n",
    "\n",
    "for src, t, q in zip(srcs, tens, quarter):\n",
    "    src_df = pd.read_csv(src)\n",
    "    src_10_df = src_df.sample(frac=0.1, random_state=1337)\n",
    "    src_10_df.to_csv(t, index=False)\n",
    "    src_25_df = src_df.sample(frac=0.25, random_state=1337)\n",
    "    src_25_df.to_csv(q, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting sequence length: 100%|██████████| 19235/19235 [06:53<00:00, 46.55it/s]\n",
      "Counting sequence length: 100%|██████████| 15388/15388 [04:54<00:00, 52.30it/s]\n",
      "Counting sequence length: 100%|██████████| 1924/1924 [01:00<00:00, 32.01it/s]\n",
      "Counting sequence length: 100%|██████████| 1923/1923 [00:56<00:00, 34.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Enrich index with gene length.\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "index_dir = os.path.join(\"index\")\n",
    "gene_index = os.path.join(index_dir, \"gene_index.csv\")\n",
    "gene_train_index = os.path.join(index_dir, \"gene_train_index.csv\")\n",
    "gene_validation_index = os.path.join(index_dir, \"gene_validation_index.csv\")\n",
    "gene_test_index = os.path.join(index_dir, \"gene_test_index.csv\")\n",
    "gene_dir = os.path.join(\"data\", \"gene_dir\")\n",
    "\n",
    "for index in [gene_index, gene_train_index, gene_validation_index, gene_test_index]:\n",
    "    df = pd.read_csv(index)\n",
    "    len_sequences = []\n",
    "    for i, r in tqdm(df.iterrows(), total=df.shape[0], desc=\"Counting sequence length\"):\n",
    "        chr_name = r[\"chr\"]\n",
    "        gene_filename = r[\"gene\"]\n",
    "        gene_filepath = os.path.join(gene_dir, chr_name, gene_filename)\n",
    "        gene_df = pd.read_csv(gene_filepath)\n",
    "        length = 0\n",
    "        for i, j in gene_df.iterrows():\n",
    "            length += len(j[\"sequence\"])\n",
    "        len_sequences.append(length)\n",
    "    df[\"length\"] = len_sequences\n",
    "    df.to_csv(index, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_cols = ['chr', 'gene']\n",
    "df_path = os.path.join('workspace', 'sequential-labelling', 'gene_index.csv')\n",
    "_dir = os.path.join('workspace', 'sequential-labelling', 'duplicate genes')\n",
    "os.makedirs(_dir, exist_ok=True)\n",
    "df = pd.read_csv(df_path)\n",
    "train_df = pd.DataFrame(columns=_cols)\n",
    "valid_df = pd.DataFrame(columns=_cols)\n",
    "test_df = pd.DataFrame(columns=_cols)\n",
    "genes_unique = df['gene'].unique()\n",
    "for g in genes_unique:\n",
    "    filtered_df = df[df['gene'] == g]\n",
    "    if filtered_df.shape[0] > 1:\n",
    "        _g = \"{}.csv\".format(g)\n",
    "        filtered_df.to_csv(os.path.join(_dir, _g), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import gff_to_csvs, gff_to_csv\n",
    "from data_dir import (annotated_grch38_gff, annotated_grch38_gff_dir, annotated_grch38_gff_csv)\n",
    "\n",
    "print(annotated_grch38_gff)\n",
    "print(annotated_grch38_gff_csv)\n",
    "print(annotated_grch38_gff_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_dir import chr21_fasta, chr21_index_csv, data_genome_grch38_labels_dir\n",
    "from data_preparation import generate_sequence_labelling\n",
    "import os\n",
    "\n",
    "target_path = os.path.join(data_genome_grch38_labels_dir, 'chr21.csv')\n",
    "print(\"Generate sequential labelling {} => {}: {}\".format(chr21_index_csv, target_path, generate_sequence_labelling(chr21_index_csv, chr21_fasta, target_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_dir import (\n",
    "    chr1_index_csv, chr2_index_csv, chr3_index_csv, chr4_index_csv, chr5_index_csv, chr6_index_csv, chr7_index_csv, chr8_index_csv, chr9_index_csv, chr10_index_csv,\n",
    "    chr11_index_csv, chr12_index_csv, chr13_index_csv, chr14_index_csv, chr15_index_csv, chr16_index_csv, chr17_index_csv, chr18_index_csv, chr19_index_csv, chr20_index_csv,\n",
    "    chr21_index_csv, chr22_index_csv, chr23_index_csv, chr24_index_csv\n",
    ")\n",
    "from data_dir import (\n",
    "    chr1_fasta, chr2_fasta, chr3_fasta, chr4_fasta, chr5_fasta, chr6_fasta, chr7_fasta, chr8_fasta, chr9_fasta, chr10_fasta, \n",
    "\tchr11_fasta, chr12_fasta, chr13_fasta, chr14_fasta, chr15_fasta, chr16_fasta, chr17_fasta, chr18_fasta, chr19_fasta, chr20_fasta, \n",
    "\tchr21_fasta, chr22_fasta, chr23_fasta, chr24_fasta,\n",
    ")\n",
    "chr_fastas = [\n",
    "    chr1_fasta,\n",
    "\t#chr2_fasta, chr3_fasta, chr4_fasta, chr5_fasta, chr6_fasta, chr7_fasta, chr8_fasta, chr9_fasta, chr10_fasta,\n",
    "\t#chr11_fasta, chr12_fasta, chr13_fasta, chr14_fasta, chr15_fasta, chr16_fasta, chr17_fasta, chr18_fasta, chr19_fasta, chr20_fasta,\n",
    "\t#chr21_fasta, chr22_fasta, chr23_fasta, chr24_fasta\n",
    "]\n",
    "from data_dir import labseq_dir, labseq_names\n",
    "from data_preparation import generate_sequence_labelling\n",
    "chr_indices = [\n",
    "    chr1_index_csv, \n",
    "\t#chr2_index_csv, chr3_index_csv, chr4_index_csv, chr5_index_csv, chr6_index_csv, chr7_index_csv, chr8_index_csv, chr9_index_csv, chr10_index_csv,\n",
    "    #chr11_index_csv, chr12_index_csv, chr13_index_csv, chr14_index_csv, chr15_index_csv, chr16_index_csv, chr17_index_csv, chr18_index_csv, chr19_index_csv, chr20_index_csv,\n",
    "    #chr21_index_csv, chr22_index_csv, chr23_index_csv, chr24_index_csv\n",
    "]\n",
    "chr_labseq_path = [os.path.join(labseq_dir, fname) for fname in labseq_names[0:1]]\n",
    "for src, fasta, target in zip(chr_indices, chr_fastas, chr_labseq_path):\n",
    "    print(src, fasta, target)\n",
    "    #print(\"Generating sequential labelling for index {}, from fasta {}, to {}: {}\".format(src, fasta, target, generate_sequence_labelling(src, fasta, target, do_expand=True, expand_size=512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequential_labelling import Label_Dictionary\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def prepare_sequence_from_csv(src_csv, label_dictionary=Label_Dictionary):\n",
    "    \"\"\"\n",
    "    Convert sequence into tokenized DNA sequence and label sequence.\n",
    "    CSV source has columns `sequence` and `label`. \n",
    "    `sequence` contains tokenized DNA sequence and `label` contains sequence of labels.\n",
    "    @param      src_csv (string): path to CSV source.\n",
    "    @param      label_dictionary (dict): dictionary to convert label into number.\n",
    "    @return     sequence, labels\n",
    "    \"\"\"\n",
    "    if not os.path.exists(src_csv):\n",
    "        raise FileNotFoundError(src_csv)\n",
    "    if label_dictionary == None:\n",
    "        raise Exception(\"Argument `label_dictionary` cannot be empty!\")\n",
    "    \n",
    "    df = pd.read_csv(src_csv)\n",
    "    return list(df['sequence']), list(df['label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create bundle from all expanded sequence from all genes from all chromosomes.\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "src_dirs = [os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", f\"chr{i+1}.expanded\") for i in range(24)]\n",
    "bundle_path = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"bundle.csv\")\n",
    "if os.path.exists(bundle_path):\n",
    "    os.remove(bundle_path)\n",
    "bundle = open(bundle_path, \"x\")\n",
    "bundle.write(\"sequence,label\\n\")\n",
    "for srcdir in tqdm(src_dirs, total=24):\n",
    "    files = [os.path.join(srcdir, f) for f in os.listdir(srcdir)]\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        for i, r in df.iterrows():\n",
    "            bundle.write(f\"{r['sequence']},{r['label']}\\n\")\n",
    "bundle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17 May 2022\n",
    "# From non overlapping kmer-ized genes, make bundle.\n",
    "import pandas as pd\n",
    "import os\n",
    "chrs = [f\"chr{i + 1}\" for i in range(24)]\n",
    "srcs = [os.path.join(\"workspace\", \"genlab\", \"seqlab.strand-positive.kmer.stride-510\", chr) for chr in chrs]\n",
    "dest = os.path.join(\"workspace\", \"seqlab\", \"seqlab.strand-positive.kmer.stride-510\", \"bundle.csv\")\n",
    "\n",
    "if os.path.exists(dest):\n",
    "    os.remove(dest)\n",
    "fdest = open(dest, \"x\")\n",
    "fdest.write(\"sequence,label\\n\")\n",
    "for src in srcs:\n",
    "    files = os.listdir(src)\n",
    "    files = [os.path.join(src, f) for f in files]\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        for i,r in df.iterrows():\n",
    "            fdest.write(f\"{r['sequence']},{r['label']}\\n\")\n",
    "\n",
    "\n",
    "fdest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bundling:   0%|          | 0/19235 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\gene_dir_c512_k3\\\\chr1\\\\AADACL3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25112/304082771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mgene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"gene\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mgene_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgene_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mgene_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgene_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgene_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mdest_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{k['sequence']},{k['label']}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenv\\sequence-processing\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\gene_dir_c512_k3\\\\chr1\\\\AADACL3.csv'"
     ]
    }
   ],
   "source": [
    "# Creating bundle from index.\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "gene_dir = os.path.join(\"data\", \"gene_dir_c512_k3\")\n",
    "index_dir = os.path.join(\"index\")\n",
    "#train_index = os.path.join(gene_dir, \"gene_train_index.csv\")\n",
    "#validation_index = os.path.join(gene_dir, \"gene_validation_index.csv\")\n",
    "#test_index = os.path.join(gene_dir, \"gene_test_index.csv\")\n",
    "whole_index = os.path.join(index_dir, \"gene_index.csv\")\n",
    "\n",
    "# Create training bundle from index.\n",
    "# Store file in by_sequence folder.\n",
    "bundle_path = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "#train_bundle = os.path.join(bundle_path, \"gene_train_bundle.csv\")\n",
    "#validation_bundle = os.path.join(bundle_path, \"gene_validation_bundle.csv\")\n",
    "#test_bundle = os.path.join(bundle_path, \"gene_test_bundle.csv\")\n",
    "whole_bundle = os.path.join(bundle_path, \"gene_bundle.csv\")\n",
    "for s, d in zip([whole_index], [whole_bundle]):\n",
    "    df = pd.read_csv(s)\n",
    "    ddirname = os.path.dirname(d)\n",
    "    if not os.path.exists(ddirname):\n",
    "        os.makedirs(ddirname)\n",
    "    if os.path.exists(d):\n",
    "        os.remove(d)\n",
    "    dest_file = open(d, \"x\")\n",
    "    dest_file.write(\"sequence,label\\n\")\n",
    "    for i, r in tqdm(df.iterrows(), total=df.shape[0], desc=\"Bundling\"):\n",
    "        chr = r[\"chr\"]\n",
    "        gene = r[\"gene\"]\n",
    "        gene_path = os.path.join(gene_dir, chr, gene)\n",
    "        gene_df = pd.read_csv(gene_path)\n",
    "        for j, k in gene_df.iterrows():\n",
    "            dest_file.write(f\"{k['sequence']},{k['label']}\\n\")\n",
    "\n",
    "    dest_file.close()\n",
    "\n",
    "# 19235 genes seqlab\n",
    "# 19235 genes seqlab-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split gene_bundle into train, validation, and test set.\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "dirpath = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "gene_bundle_path = os.path.join(dirpath, \"gene_bundle.csv\")\n",
    "gene_train_bundle_path = os.path.join(dirpath, \"gene_train_bundle.csv\")\n",
    "gene_validation_bundle_path = os.path.join(dirpath, \"gene_validation_bundle.csv\")\n",
    "gene_test_bundle_path = os.path.join(dirpath, \"gene_test_bundle.csv\")\n",
    "\n",
    "df = pd.read_csv(gene_bundle_path)\n",
    "train_df = df.sample(frac=0.8, random_state=1337)\n",
    "validation_df = df.drop(train_df.index)\n",
    "test_df = validation_df.sample(frac=0.5, random_state=1337)\n",
    "validation_df = validation_df.drop(test_df.index)\n",
    "train_df.to_csv(gene_train_bundle_path, index=False)\n",
    "validation_df.to_csv(gene_validation_bundle_path, index=False)\n",
    "test_df.to_csv(gene_test_bundle_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dirpath = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "gene_bundle_path = os.path.join(dirpath, \"gene_bundle.csv\")\n",
    "gene_train_bundle_path = os.path.join(dirpath, \"gene_train_bundle.csv\")\n",
    "gene_validation_bundle_path = os.path.join(dirpath, \"gene_validation_bundle.csv\")\n",
    "gene_test_bundle_path = os.path.join(dirpath, \"gene_test_bundle.csv\")\n",
    "\n",
    "gene_train_bundle_10_path = os.path.join(dirpath, \"gene_train_bundle.10.csv\")\n",
    "gene_train_bundle_25_path = os.path.join(dirpath, \"gene_train_bundle.25.csv\")\n",
    "gene_validation_bundle_10_path = os.path.join(dirpath, \"gene_validation_bundle.10.csv\")\n",
    "gene_validation_bundle_25_path = os.path.join(dirpath, \"gene_validation_bundle.25.csv\")\n",
    "gene_test_bundle_10_path =os.path.join(dirpath, \"gene_test_bundle.10.csv\")\n",
    "gene_test_bundle_25_path =os.path.join(dirpath, \"gene_test_bundle.25.csv\")\n",
    "\n",
    "for p, q, r in zip(\n",
    "    [gene_train_bundle_path, gene_validation_bundle_path, gene_test_bundle_path],\n",
    "    [gene_train_bundle_10_path, gene_validation_bundle_10_path, gene_test_bundle_10_path],\n",
    "    [gene_train_bundle_25_path, gene_validation_bundle_25_path, gene_test_bundle_25_path]\n",
    "):\n",
    "    source_df = pd.read_csv(p)\n",
    "    p10_df = source_df.sample(frac=0.1, random_state=1337)\n",
    "    p25_df = source_df.sample(frac=0.25, random_state=1337)\n",
    "    p10_df.to_csv(q, index=False)\n",
    "    p25_df.to_csv(r, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small version of seqlab-3 sequence.\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "fractions = [0.1, 0.25]\n",
    "seqlab_3_dir = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "train_df = pd.read_csv(os.path.join(seqlab_3_dir, \"gene_train_bundle.csv\"))\n",
    "validation_df = pd.read_csv(os.path.join(seqlab_3_dir, \"gene_validation_bundle.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(seqlab_3_dir, \"gene_test_bundle.csv\"))\n",
    "\n",
    "for frac in fractions:\n",
    "    train_df.sample(frac=frac).to_csv(os.path.join(seqlab_3_dir, f\"gene_train_bundle.{frac * 100}.csv\"))\n",
    "    validation_df.sample(frac=frac).to_csv(os.path.join(seqlab_3_dir, f\"gene_validation_bundle.{frac * 100}.csv\"))\n",
    "    test_df.sample(frac=frac).to_csv(os.path.join(seqlab_3_dir, f\"gene_test_bundle.{frac * 100}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing (2022-08-12 09:47:26.822747): 100%|██████████| 1753964/1753964 [13:33<00:00, 2156.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate SPLICE SITES, INTRON, and EXON only bundles.\n",
    "def at_least_one_exists(list, target_list):\n",
    "    # Check if at leats one element of list exists in target_list.\n",
    "    found = False\n",
    "    for elem in list:\n",
    "        if elem in target_list:\n",
    "            found = True\n",
    "    return found\n",
    "\n",
    "def is_intron(label_sequence):\n",
    "    return all([a == \"iii\" for a in label_sequence])\n",
    "\n",
    "def is_exon(label_sequence):\n",
    "    return all([a == \"EEE\" for a in label_sequence])\n",
    "\n",
    "splice_sites = ['iiE', 'iEi', 'Eii', 'iEE', 'EEi', 'EiE']\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "gene_bundle_dirpath = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "gene_bundle = os.path.join(gene_bundle_dirpath, \"gene_bundle.csv\")\n",
    "gene_ss_bundle = os.path.join(gene_bundle_dirpath, \"gene_ss_bundle.csv\")\n",
    "gene_exon_bundle = os.path.join(gene_bundle_dirpath, \"gene_exon_bundle.csv\")\n",
    "gene_intron_bundle = os.path.join(gene_bundle_dirpath, \"gene_intron_bundle.csv\")\n",
    "for p in [gene_bundle]:\n",
    "    df = pd.read_csv(p)\n",
    "    for a in [gene_ss_bundle, gene_exon_bundle, gene_intron_bundle]:\n",
    "        if os.path.exists(a):\n",
    "            os.remove(a)\n",
    "\n",
    "    gene_ss_bundle = open(gene_ss_bundle, \"x\")\n",
    "    gene_exon_bundle = open(gene_exon_bundle, \"x\")\n",
    "    gene_intron_bundle = open(gene_intron_bundle, \"x\")\n",
    "\n",
    "    for a in [gene_ss_bundle, gene_exon_bundle, gene_intron_bundle]:\n",
    "        a.write(\"sequence,label\\n\")\n",
    "\n",
    "    from datetime import datetime\n",
    "    cur_date = datetime.now()\n",
    "    for i, r in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Processing ({cur_date})\"):\n",
    "        arr_labels = r[\"label\"].split(\" \")\n",
    "        if all([a == \"iii\" for a in arr_labels]):\n",
    "            gene_intron_bundle.write(f\"{r['sequence']},{r['label']}\\n\")\n",
    "        elif all([a == \"EEE\" for a in arr_labels]):\n",
    "            gene_exon_bundle.write(f\"{r['sequence']},{r['label']}\\n\")\n",
    "        else:\n",
    "            gene_ss_bundle.write(f\"{r['sequence']},{r['label']}\\n\")\n",
    "\n",
    "\n",
    "    for a in [gene_ss_bundle, gene_intron_bundle, gene_exon_bundle]:\n",
    "        a.close()\n",
    "\n",
    "# Split SPLICE SITES bundle into train, validation, and test set.\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "dirpath = os.path.join(\"workspace\", \"seqlab\", \"seqlab-3\")\n",
    "splice_site_bundle_path = os.path.join(dirpath, \"gene_ss_bundle.csv\")\n",
    "splice_site_train_bundle_path = os.path.join(dirpath, \"gene_ss_train_bundle.csv\")\n",
    "splice_site_validation_bundle_path = os.path.join(dirpath, \"gene_ss_validation_bundle.csv\")\n",
    "splice_site_test_bundle_path = os.path.join(dirpath, \"gene_ss_test_bundle.csv\")\n",
    "\n",
    "df = pd.read_csv(splice_site_bundle_path)\n",
    "train_df = df.sample(frac=0.8, random_state=1337)\n",
    "validation_df = df.drop(train_df.index)\n",
    "test_df = validation_df.sample(frac=0.5, random_state=1337)\n",
    "validation_df = validation_df.drop(test_df.index)\n",
    "train_df.to_csv(splice_site_train_bundle_path, index=False)\n",
    "validation_df.to_csv(splice_site_validation_bundle_path, index=False)\n",
    "test_df.to_csv(splice_site_test_bundle_path, index=False)\n",
    "\n",
    "# 1753964 \n",
    "train_len = train_df.shape[0]\n",
    "validation_len = validation_df.shape[0]\n",
    "test_len = test_df.shape[0]\n",
    "total = train_len + validation_len + test_len\n",
    "print(f\"# Training instance {train_len} {train_len/total}\")\n",
    "print(f\"# Validation instance {validation_len} {validation_len/total}\")\n",
    "print(f\"# Test instance {test_len} {test_len/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = train_df.shape[0]\n",
    "validation_len = validation_df.shape[0]\n",
    "test_len = test_df.shape[0]\n",
    "total = train_len + validation_len + test_len\n",
    "print(f\"# Training instance {train_len} {train_len/total}\")\n",
    "print(f\"# Validation instance {validation_len} {validation_len/total}\")\n",
    "print(f\"# Test instance {test_len} {test_len/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene sequential labelling.\n",
    "# Create 10% and 25% sample of gene indices.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "index_dir = os.path.join(\"index\")\n",
    "gene_train_index = os.path.join(index_dir, \"gene_train_index.csv\")\n",
    "gene_validation_index = os.path.join(index_dir, \"gene_validation_index.csv\")\n",
    "gene_test_index = os.path.join(index_dir, \"gene_test_index.csv\")\n",
    "\n",
    "gene_train_index_10 = os.path.join(index_dir, \"gene_train_index.10.csv\")\n",
    "gene_validation_index_10 = os.path.join(index_dir, \"gene_validation_index.10.csv\")\n",
    "gene_test_index_10 = os.path.join(index_dir, \"gene_test_index.10.csv\")\n",
    "\n",
    "gene_train_index_25 = os.path.join(index_dir, \"gene_train_index.25.csv\")\n",
    "gene_validation_index_25 = os.path.join(index_dir, \"gene_validation_index.25.csv\")\n",
    "gene_test_index_25 = os.path.join(index_dir, \"gene_test_index.25.csv\")\n",
    "\n",
    "srcs = [gene_train_index, gene_validation_index, gene_test_index]\n",
    "tens = [gene_train_index_10, gene_validation_index_10, gene_test_index_10]\n",
    "quarter = [gene_train_index_25, gene_validation_index_25, gene_test_index_25]\n",
    "\n",
    "for src, t, q in zip(srcs, tens, quarter):\n",
    "    src_df = pd.read_csv(src)\n",
    "    src_10_df = src_df.sample(frac=0.1, random_state=1337)\n",
    "    src_10_df.to_csv(t, index=False)\n",
    "    src_25_df = src_df.sample(frac=0.25, random_state=1337)\n",
    "    src_25_df.to_csv(q, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def generate_bundle_with_marker(src_index, target_bundle, gene_dir):\n",
    "    gene_train_index = src_index\n",
    "    gene_train_bundle_csv = target_bundle\n",
    "    if os.path.exists(gene_train_bundle_csv):\n",
    "        os.remove(gene_train_bundle_csv)\n",
    "\n",
    "    target_bundle_dir = os.path.dirname(target_bundle)\n",
    "    os.makedirs(target_bundle_dir, exist_ok=True)\n",
    "\n",
    "    gene_train_bundle = open(gene_train_bundle_csv, \"x\")\n",
    "    gene_train_bundle.write(\"sequence,label,marker\\n\")\n",
    "\n",
    "    df = pd.read_csv(gene_train_index)\n",
    "    marker = True\n",
    "    for i, r in tqdm(df.iterrows(), total=df.shape[0], desc= f\"Processing {os.path.basename(src_index)}\"):\n",
    "        chr_dir = r[\"chr\"]\n",
    "        gene_file = r[\"gene\"]\n",
    "        gene_name = gene_file.split(\".\")[0]\n",
    "        gene_csv = os.path.join(gene_dir, chr_dir, gene_file)\n",
    "        gene_df = pd.read_csv(gene_csv)\n",
    "        for j, k in gene_df.iterrows():\n",
    "            sequence = k[\"sequence\"]\n",
    "            label = k[\"label\"]\n",
    "            gene_train_bundle.write(f\"{sequence},{label},{int(marker)}\\n\")\n",
    "        \n",
    "        marker = not marker\n",
    "\n",
    "    gene_train_bundle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gene_train_index.10.csv: 100%|██████████| 1539/1539 [02:20<00:00, 10.98it/s]\n",
      "Processing gene_train_index.25.csv: 100%|██████████| 3847/3847 [03:28<00:00, 18.42it/s]\n",
      "Processing gene_train_index.csv: 100%|██████████| 15388/15388 [14:23<00:00, 17.83it/s]\n",
      "Processing gene_validation_index.10.csv: 100%|██████████| 192/192 [00:10<00:00, 18.67it/s]\n",
      "Processing gene_validation_index.25.csv: 100%|██████████| 481/481 [00:22<00:00, 21.73it/s]\n",
      "Processing gene_validation_index.csv: 100%|██████████| 1924/1924 [01:46<00:00, 18.13it/s]\n",
      "Processing gene_test_index.10.csv: 100%|██████████| 192/192 [00:12<00:00, 15.86it/s]\n",
      "Processing gene_test_index.25.csv: 100%|██████████| 481/481 [00:23<00:00, 20.22it/s]\n",
      "Processing gene_test_index.csv: 100%|██████████| 1923/1923 [01:38<00:00, 19.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Gene labelling: create bundle with marker that indicates a set of sequence belong to one long sequence.\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "index_dir = os.path.join(\"index\")\n",
    "srcs = [\n",
    "    os.path.join(index_dir, \"gene_train_index.10.csv\"),\n",
    "    os.path.join(index_dir, \"gene_train_index.25.csv\"),\n",
    "    os.path.join(index_dir, \"gene_train_index.csv\"),\n",
    "    os.path.join(index_dir, \"gene_validation_index.10.csv\"),\n",
    "    os.path.join(index_dir, \"gene_validation_index.25.csv\"),\n",
    "    os.path.join(index_dir, \"gene_validation_index.csv\"),\n",
    "    os.path.join(index_dir, \"gene_test_index.10.csv\"),\n",
    "    os.path.join(index_dir, \"gene_test_index.25.csv\"),\n",
    "    os.path.join(index_dir, \"gene_test_index.csv\"),\n",
    "]\n",
    "workspace_dir = os.path.join(\"workspace\", \"genlab\", \"genlab-3\")\n",
    "dests = [\n",
    "    os.path.join(workspace_dir, \"gene_train_index_bundle.10.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_train_index_bundle.25.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_train_index_bundle.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_validation_index_bundle.10.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_validation_index_bundle.25.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_validation_index_bundle.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_test_index_bundle.10.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_test_index_bundle.25.csv\"),\n",
    "    os.path.join(workspace_dir, \"gene_test_index_bundle.csv\"),\n",
    "]\n",
    "# Generate gene bundles based on above.\n",
    "import os\n",
    "\n",
    "gene_dir = os.path.join(\"data\", \"gene_dir_c510_k3\")\n",
    "for a, b in zip(srcs, dests):\n",
    "    generate_bundle_with_marker(a, b, gene_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create gene sequence which contains splice sites at all position.\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils.utils import is_exists_splice_site_in_sequence\n",
    "\n",
    "is_exists_splice_site_in_sequence([\"iii\", \"EEE\", \"EEE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gene sequence which contains splice sites at all position.\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.utils import kmer, str_kmer, is_exists_splice_site_in_sequence\n",
    "\n",
    "def generate_splice_site_all_pos_bundle(source_gene_dir, bundle_dest_dir, chunk_size, kmer_size):\n",
    "    \"\"\"\n",
    "    `source_gene_dir` - contains directories which each corresponds to chromosome.\n",
    "    Genes in chromosome folder is in raw format, not kmerized.\n",
    "    `bundle_dest_dir` - folder where the resulting bundle will be written.\n",
    "    \"\"\"\n",
    "    chr_names = os.listdir(source_gene_dir)\n",
    "    chr_dirs = [os.path.join(source_gene_dir, a) for a in chr_names]\n",
    "    chr_dirs = [a for a in chr_dirs if os.path.isdir(a)]\n",
    "\n",
    "    os.makedirs(bundle_dest_dir, exist_ok=True)\n",
    "    bundle_path = os.path.join(bundle_dest_dir, \"splice_site_all_pos.csv\")\n",
    "    if os.path.exists(bundle_path):\n",
    "        os.remove(bundle_path)\n",
    "    \n",
    "    bundle_file = open(bundle_path, \"x\")\n",
    "    bundle_file.write(\"sequence,label\\n\")\n",
    "\n",
    "    for d in tqdm(chr_dirs, total=len(chr_dirs), desc=\"Processing Chromosome\"):\n",
    "        filenames = os.listdir(d)\n",
    "        filepaths = [os.path.join(d, a) for a in filenames]\n",
    "        filepaths = [a for a in filepaths if os.path.isfile(a)]\n",
    "        \n",
    "        for f in filepaths:\n",
    "            df = pd.read_csv(f)\n",
    "            for i, r in df.iterrows():\n",
    "                sequence = r[\"sequence\"]\n",
    "                label = r[\"label\"]\n",
    "                len_sequence = len(sequence)\n",
    "                for i in range(0, len_sequence - chunk_size, 1):\n",
    "                    sublabel = label[i:i+chunk_size]\n",
    "                    arr_sublabel = kmer(sublabel, kmer_size)\n",
    "                    if is_exists_splice_site_in_sequence(arr_sublabel):\n",
    "                        subsequence = sequence[i:i+chunk_size]\n",
    "                        bundle_file.write(f\"{str_kmer(subsequence, kmer_size)},{' '.join(arr_sublabel)}\\n\")\n",
    "                    \n",
    "    bundle_file.close()                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chromosome: 100%|██████████| 2/2 [08:54<00:00, 267.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create sample index.\n",
    "import os \n",
    "gene_dir_path = os.path.join(\"data\", \"gene_dir_sample\")\n",
    "bundle_dest_dir = os.path.join(\"data\", \"gene_dir_sample\")\n",
    "chunk_size = 512\n",
    "kmer_size = 3\n",
    "generate_splice_site_all_pos_bundle(gene_dir_path, bundle_dest_dir, chunk_size, kmer_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14ae8cb2141f3f34f4e0523006ff2d6cb0f7956c0f094e5497e312072e4d0d3c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('sequence-processing': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bcc05615a70b396b2914747c544672e77157727153b1cb6572b3ac9e1c1c348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
