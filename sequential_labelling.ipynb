{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1, 11], got [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mw:\\Research\\sequence-processing\\sequential_labelling.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=11'>12</a>\u001b[0m pred \u001b[39m=\u001b[39m model(input_ids, attn_mask, token_type_ids)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=12'>13</a>\u001b[0m \u001b[39m# print(pred.shape, label.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=13'>14</a>\u001b[0m \u001b[39m#for p, l in zip(pred, label):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=14'>15</a>\u001b[0m \u001b[39m#    print(p.shape, l.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=15'>16</a>\u001b[0m \u001b[39m#    loss = loss_fn(p, l)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/w%3A/Research/sequence-processing/sequential_labelling.ipynb#ch0000000?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, label)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1150\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=1148'>1149</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=1149'>1150</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=1150'>1151</a>\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/modules/loss.py?line=1151'>1152</a>\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\torch\\nn\\functional.py:2846\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2843'>2844</a>\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2844'>2845</a>\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> <a href='file:///c%3A/.virtualenv/sequence-processing-py39/lib/site-packages/torch/nn/functional.py?line=2845'>2846</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [1, 11], got [1, 512]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.data_generator import _data_generator_seq2seq\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "from sequential_labelling import init_seq2seq_model\n",
    "\n",
    "dataloader = _data_generator_seq2seq()\n",
    "model = init_seq2seq_model(pretrained_3kmer_dir)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# print(model)\n",
    "for step, batch in enumerate(dataloader):\n",
    "    input_ids, attn_mask, token_type_ids, label = tuple(t for t in batch)\n",
    "    pred = model(input_ids, attn_mask, token_type_ids)\n",
    "    # print(pred.shape, label.shape)\n",
    "    #for p, l in zip(pred, label):\n",
    "    #    print(p.shape, l.shape)\n",
    "    #    loss = loss_fn(p, l)\n",
    "    loss = loss_fn(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [\n",
    "    [   # Sentence 0\n",
    "        [0.1, 0.2, 0.3, ], # Token 0\n",
    "        [0.1, 0.2, 0.3, ], # Token 1\n",
    "        [0.1, 0.2, 0.3, ], # Token 2\n",
    "        [0.1, 0.2, 0.3, ], # Token 3\n",
    "        [0.1, 0.2, 0.3, ], # Token 4\n",
    "    ],\n",
    "    [   # Sentence 1\n",
    "        [0.3, 0.4, 0.1, ], # Token 0\n",
    "        [0.2, 0.3, 0.4, ], # Token 1\n",
    "        [0.2, 0.3, 0.4, ], # Token 2\n",
    "        [0.1, 0.2, 0.3, ], # Token 3\n",
    "        [0.4, 0.1, 0.2, ], # Token 4\n",
    "    ],\n",
    "]\n",
    "import torch\n",
    "pred = torch.tensor(pred)\n",
    "pred = torch.nn.Softmax(dim=2)(pred)\n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "\n",
    "label = [\n",
    "    [1, 1, 1, 1, 1], # Label Sentence 0\n",
    "    [0, 0, 0, 0, 0], # Label Sentence 1\n",
    "]\n",
    "label = torch.tensor(label)\n",
    "print(label.shape)\n",
    "\n",
    "fn = torch.nn.CrossEntropyLoss()\n",
    "loss = fn(pred, label)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2231)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "pred = torch.tensor([[0.8]])\n",
    "label = torch.tensor([[1.0]])\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "loss_fn(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, BertModel\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "\n",
    "bertForTokenClassification = BertForTokenClassification.from_pretrained(pretrained_3kmer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/genome/grch38/exon/NC_000024.10.csv']\n",
      "['./data/chr/NC_000024.10.fasta']\n",
      "['./data/genome/labseq/chr24.csv']\n"
     ]
    }
   ],
   "source": [
    "from data_dir import chr24_index_csv, chr24_fasta, labseq_dir, labseq_names\n",
    "chr_indices = [chr24_index_csv]\n",
    "chr_fastas = [chr24_fasta]\n",
    "chr_labseq_path = [\"{}/{}\".format(labseq_dir, fname) for fname in [labseq_names[-1]]]\n",
    "print(chr_indices)\n",
    "print(chr_fastas)\n",
    "print(chr_labseq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index ./data/genome/grch38/exon/NC_000024.10.csv, with fasta ./data/chr/NC_000024.10.fasta, to seq. labelling ./data/genome/labseq/chr24.csv, expanding [5431760/57226904]"
     ]
    }
   ],
   "source": [
    "from data_dir import chr24_index_csv, chr24_fasta, labseq_dir, labseq_names\n",
    "from data_preparation import generate_sequence_labelling\n",
    "chr_indices = [chr24_index_csv]\n",
    "chr_fastas = [chr24_fasta]\n",
    "chr_labseq_path = [\"{}/{}\".format(labseq_dir, fname) for fname in [labseq_names[-1]]]\n",
    "for src, fasta, target in zip(chr_indices, chr_fastas, chr_labseq_path):\n",
    "    print(\"Generating sequential labelling for index {}, from fasta {}, to {}: {}\".format(src, fasta, target, generate_sequence_labelling(src, fasta, target, do_expand=True, expand_size=512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 11]) tensor([0.0415, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0046, 0.0000], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0944, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905,\n",
      "        0.0909, 0.0905], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0000, 0.0000, 0.0045, 0.0002, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1010], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0900, 0.0900, 0.0904, 0.0900, 0.0900, 0.0900, 0.0900, 0.0900, 0.0900,\n",
      "        0.0900, 0.0996], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0000, 0.0178, 0.0000, 0.0312, 0.0000, 0.0000, 0.0000, 0.0352, 0.1106,\n",
      "        0.0142, 0.0000], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0892, 0.0908, 0.0892, 0.0920, 0.0892, 0.0892, 0.0892, 0.0923, 0.0996,\n",
      "        0.0904, 0.0892], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([-0.0000, 0.0000, 0.0000, 0.0000, 0.1084, -0.0000, 0.0000, 0.0000, 0.0193,\n",
      "        0.0000, -0.0000], grad_fn=<SelectBackward0>)\n",
      "torch.Size([1, 512, 11]) tensor([0.0898, 0.0898, 0.0898, 0.0898, 0.1001, 0.0898, 0.0898, 0.0898, 0.0916,\n",
      "        0.0898, 0.0898], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from utils.data_generator import _data_generator_seq2seq\n",
    "from models.seq2seq import DNABERTSeq2Seq\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "dataloader = _data_generator_seq2seq()\n",
    "model = DNABERTSeq2Seq(pretrained_3kmer_dir)\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "    input_ids, attn_mask, token_type_ids, label = tuple(t for t in batch)\n",
    "    pred = model(input_ids, attn_mask, token_type_ids)\n",
    "    # print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998000000000001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [0.0944, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905, 0.0905,\n",
    "        0.0909, 0.0905]\n",
    "sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenv\\sequence-processing-py39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.89it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.84it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from sequential_labelling import DNABERTSeq2Seq, train, init_adamw_optimizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "import os\n",
    "from utils.seq2seq import init_seq2seq_model\n",
    "import json\n",
    "from utils.data_generator import _data_generator_seq2seq\n",
    "\n",
    "dataloader = _data_generator_seq2seq()\n",
    "\n",
    "num_epoch = 10\n",
    "batch_size = 2\n",
    "warmup = 10\n",
    "device = \"cuda\"\n",
    "seq2seq_config = json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq.json\"), \"r\"))\n",
    "model = init_seq2seq_model(seq2seq_config)\n",
    "model.to(device)\n",
    "optimizer = init_adamw_optimizer(model.parameters())\n",
    "training_steps = len(dataloader) * num_epoch\n",
    "optim_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup, num_training_steps=training_steps)\n",
    "log_path = os.path.join(\"logs\", \"seq2seq\", \"19082022\", \"log.t-sample.csv\")\n",
    "save_path = os.path.join(\"result\", \"seq2seq\", \"19082022\", \"t-sample\")\n",
    "model.train()\n",
    "\"\"\"\n",
    "Play with result.\n",
    "\"\"\"\n",
    "trained_model = train(model, optimizer, optim_scheduler, dataloader, num_epoch, batch_size, log_path, save_path, device, remove_old_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNABERTSeq2Seq(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (seq2seq_head): Seq2SeqHead(\n",
      "    (linear): Sequential(\n",
      "      (seq2seq_block-0): Seq2SeqBlock(\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
      "  )\n",
      "  (activation): Softmax(dim=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 0.2000, 0.3000],\n",
      "         [0.1000, 0.2000, 0.7000]],\n",
      "\n",
      "        [[0.5000, 0.2000, 0.3000],\n",
      "         [0.1000, 0.2000, 0.7000]]], requires_grad=True) tensor([[[0.3907, 0.2894, 0.3199],\n",
      "         [0.2546, 0.2814, 0.4640]],\n",
      "\n",
      "        [[0.3907, 0.2894, 0.3199],\n",
      "         [0.2546, 0.2814, 0.4640]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2, 2, 3]) torch.Size([2, 2])\n",
      "1.0038902759552002\n",
      "1.103890299797058\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "activation_function = torch.nn.Softmax(dim=2)\n",
    "pred = torch.tensor([[[0.5, 0.2, 0.3], [0.1, 0.2, 0.7]], [[0.5, 0.2, 0.3], [0.1, 0.2, 0.7]]], requires_grad=True)\n",
    "pred_activated = activation_function(pred)\n",
    "print(pred, pred_activated)\n",
    "labels = torch.tensor([[1, 2], [0, 1]])\n",
    "print(pred.shape, labels.shape)\n",
    "for p, l in zip(pred, labels):\n",
    "    loss = loss_function(p, l)\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample 3\n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "tensor([[0.5046, 0.4954],\n",
      "        [0.5199, 0.4801]], grad_fn=<SoftmaxBackward0>) tensor([0, 1])\n",
      "torch.Size([1, 2]) torch.Size([1])\n",
      "tensor([[0.5440, 0.4560]], grad_fn=<SoftmaxBackward0>) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.data_generator import _data_generator_mtl\n",
    "from multitask_learning import init_model_mtl\n",
    "from data_dir import pretrained_3kmer_dir\n",
    "model = init_model_mtl(pretrained_path=pretrained_3kmer_dir)\n",
    "dataloader = _data_generator_mtl(batch_size=2)\n",
    "loss_function = torch.nn.Softmax(dim=1)\n",
    "for step, batch in enumerate(dataloader):\n",
    "    b_input_ids, b_attn_mask, b_label_prom, b_label_ss, b_label_polya = tuple(t for t in batch)\n",
    "    output = model(b_input_ids, b_attn_mask)\n",
    "    #print(output[\"prom\"], b_label_prom)\n",
    "    print(output[\"ss\"].shape, b_label_ss.shape)\n",
    "    print(output[\"ss\"], b_label_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTSeq2Seq(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seq2seq_head): Seq2SeqHead(\n",
       "    (linear): Sequential(\n",
       "      (seq2seq_block-0): Seq2SeqBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  )\n",
       "  (activation): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.seq2seq import init_seq2seq_model\n",
    "import json\n",
    "import os\n",
    "model = init_seq2seq_model(json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq.json\"), 'r')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTSeq2Seq(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seq2seq_head): Seq2SeqHead(\n",
       "    (linear): Sequential(\n",
       "      (seq2seq_block-0): Seq2SeqBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  )\n",
       "  (activation): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.seq2seq import init_seq2seq_model\n",
    "import json\n",
    "import os\n",
    "model = init_seq2seq_model(json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq_norm.json\"), 'r')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTSeqLab(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seqlab_head): SeqLabHead(\n",
       "    (linear): Sequential(\n",
       "      (seq2seq_block-0): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-1): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-2): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-3): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  )\n",
       "  (activation): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.seqlab import init_seqlab_model\n",
    "import json\n",
    "import os\n",
    "model = init_seqlab_model(json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq_multiple.json\"), 'r')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTSeqLab(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seqlab_head): SeqLabHead(\n",
       "    (linear): Sequential(\n",
       "      (seq2seq_block-0): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-1): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-2): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (seq2seq_block-3): SeqLabBlock(\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  )\n",
       "  (activation): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.seqlab import init_seqlab_model\n",
    "import json\n",
    "import os\n",
    "model = init_seqlab_model(json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq_norm_multiple.json\"), 'r')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNABERTSeqLab(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(69, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seqlab_head): SeqLabHead(\n",
       "    (lstm): LSTM_Block(\n",
       "      (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (seq2seq_block-0): SeqLabBlock(\n",
       "        (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=1536, out_features=11, bias=True)\n",
       "  )\n",
       "  (activation): Softmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.seqlab import init_seqlab_model\n",
    "import json\n",
    "import os\n",
    "model = init_seqlab_model(json.load(open(os.path.join(\"models\", \"config\", \"config_seq2seq_bilstm.json\"), 'r')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chr1: 100%|██████████| 1817/1817 [00:11<00:00, 164.28it/s]\n",
      "Chr2: 100%|██████████| 1333/1333 [00:08<00:00, 165.45it/s]\n",
      "Chr3: 100%|██████████| 1059/1059 [00:11<00:00, 95.77it/s]\n",
      "Chr4: 100%|██████████| 838/838 [00:13<00:00, 62.73it/s]\n",
      "Chr5: 100%|██████████| 926/926 [00:17<00:00, 53.42it/s]\n",
      "Chr6: 100%|██████████| 1071/1071 [00:19<00:00, 55.63it/s] \n",
      "Chr7: 100%|██████████| 994/994 [00:16<00:00, 61.67it/s]\n",
      "Chr8: 100%|██████████| 728/728 [00:13<00:00, 52.21it/s]\n",
      "Chr9: 100%|██████████| 729/729 [00:12<00:00, 56.72it/s]\n",
      "Chr10: 100%|██████████| 793/793 [00:15<00:00, 51.36it/s]\n",
      "Chr11: 100%|██████████| 1061/1061 [00:17<00:00, 59.16it/s] \n",
      "Chr12: 100%|██████████| 906/906 [00:08<00:00, 101.50it/s]\n",
      "Chr13: 100%|██████████| 449/449 [00:03<00:00, 126.93it/s]\n",
      "Chr14: 100%|██████████| 797/797 [00:05<00:00, 151.63it/s]\n",
      "Chr15: 100%|██████████| 673/673 [00:04<00:00, 141.11it/s]\n",
      "Chr16: 100%|██████████| 765/765 [00:05<00:00, 132.20it/s]\n",
      "Chr17: 100%|██████████| 888/888 [00:07<00:00, 116.96it/s]\n",
      "Chr18: 100%|██████████| 351/351 [00:04<00:00, 84.87it/s] \n",
      "Chr19: 100%|██████████| 1035/1035 [00:09<00:00, 107.08it/s]\n",
      "Chr20: 100%|██████████| 529/529 [00:04<00:00, 118.71it/s]\n",
      "Chr21: 100%|██████████| 290/290 [00:02<00:00, 119.33it/s]\n",
      "Chr22: 100%|██████████| 437/437 [00:03<00:00, 124.89it/s]\n",
      "Chr23: 100%|██████████| 667/667 [00:05<00:00, 112.86it/s]\n",
      "Chr24: 100%|██████████| 99/99 [00:00<00:00, 130.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What about merging genes from each chromosome?\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "_cols = [\"chr\",\"id\",\"sequence\",\"label\"]\n",
    "whole_df = pd.DataFrame(columns=_cols)\n",
    "for i in range(24):\n",
    "    chr = f\"chr{i + 1}\"\n",
    "    path = os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", chr)\n",
    "    files = os.listdir(path)\n",
    "    for f in tqdm(files, total=len(files), desc=f\"Chr{i + 1}\"):\n",
    "        fpath = os.path.join(path, f)\n",
    "        fdf = pd.read_csv(fpath)\n",
    "        # for index, row in tqdm(fdf.iterrows(), total=fdf.shape[0], desc=f\"{chr}, {f}\"):\n",
    "        for index, row in fdf.iterrows():\n",
    "            id = f\"{f.split('.')[0]}\"\n",
    "            sequence = row[\"sequence\"]\n",
    "            label = row[\"label\"]\n",
    "            frame = pd.DataFrame([[chr, id, sequence, label]], columns=_cols)\n",
    "            whole_df = pd.concat([whole_df, frame])\n",
    "        #endfor\n",
    "    #endfor\n",
    "#endfor\n",
    "whole_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Randomized all genes.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "all_genes_df = pd.read_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes.csv\"))\n",
    "all_genes_df = all_genes_df.sample(frac=1).reset_index(drop=True)\n",
    "all_genes_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_randomized.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split all genes into three parts.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "all_genes_df = pd.read_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_randomized.csv\"))\n",
    "all_genes_train_df = all_genes_df.sample(frac=0.8)\n",
    "all_genes_val_test_df = all_genes_df.drop(all_genes_train_df.index)\n",
    "all_genes_val_df = all_genes_val_test_df.sample(frac=0.5)\n",
    "all_genes_test_df = all_genes_val_test_df.drop(all_genes_val_df.index)\n",
    "\n",
    "all_genes_train_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_train.csv\"), index=False)\n",
    "all_genes_val_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_validation.csv\"), index=False)\n",
    "all_genes_test_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create small sample for local training.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "all_genes_df = pd.read_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes_randomized.csv\"))\n",
    "all_genes_sample_df = all_genes_df.sample(n=100)\n",
    "all_genes_sample_df.to_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes.sample.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's profile the data.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_genes_df = pd.read_csv(os.path.join(\"data\", \"genome\", \"seqlab.positive.strand\", \"all_genes.csv\"))\n",
    "all_genes_df[\"length\"] = all_genes_df[\"sequence\"].str.len()\n",
    "chrs = list(all_genes_df[\"chr\"].unique())\n",
    "chr_axis = [(i+1) for i in range(24)]\n",
    "min_axis = []\n",
    "max_axis = []\n",
    "for c in chrs:\n",
    "    df = all_genes_df[all_genes_df[\"chr\"] == c]\n",
    "    max_length = df[\"length\"].max()\n",
    "    max_axis.append(max_length)\n",
    "    min_length = df[\"length\"].min()\n",
    "    min_axis.append(min_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels = chrs\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, min_axis, width, label='min')\n",
    "rects2 = ax.bar(x + width/2, max_axis, width, label='max')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Sequence Length')\n",
    "ax.set_title('Sequence Length for Each Chromosome')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473c7453bcb969eece5b07ef8b7f234e7c84010927f6bebce35f0aeb1f8c121e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('sequence-processing-py39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
